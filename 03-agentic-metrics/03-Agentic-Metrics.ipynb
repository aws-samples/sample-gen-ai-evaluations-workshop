{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74e48259-2ee0-499e-af76-7eef988f897a",
   "metadata": {},
   "source": [
    "# Agentic Evaluator\n",
    "In this notebook, we set up a simple chat bot using Strands.  Then, we create an evaluator agent, which can test and correct our chat bot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4fc1c9-f1c9-45ce-a69d-145fb9fefb3b",
   "metadata": {},
   "source": [
    "## 1) Set up dependances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0e1623-9680-424d-9b92-697bf96cc61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Strands Agents\n",
    "!pip install strands-agents strands-agents-tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8171412-67f6-45f6-92dc-7c31175a7f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install googlesearch-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c487d70-91d9-4325-a567-b2cfbbeb2bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands import Agent, tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9d81e3bf-bae2-4b22-8f22-0feef0aed435",
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands.models import BedrockModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45ae3a6d-a673-480a-a575-f432be904e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googlesearch import search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cef3dc10-fcfd-4c61-b377-1e011f69d7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "513a53fa-bb23-4728-8e83-7fd0a8dfa88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b925b66-680e-46aa-8741-69bc25d11a3e",
   "metadata": {},
   "source": [
    "We'll also import a list of city data, to use as our gold standard set.\n",
    "This is from: https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "747957db-3ef0-45d6-a8dc-1ac26283530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3bedea13-fa8c-40f8-8960-f848980fdb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          city state  population  land_area_mi2\n",
      "0  New York[c]    NY   8478072.0          300.5\n",
      "1  Los Angeles    CA   3878704.0          469.5\n",
      "2      Chicago    IL   2721308.0          227.7\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file\n",
    "#this contains the city, state, population, and land area in square miles in 2024.\n",
    "gold_standard_city_pop = pd.read_csv('city_pop.csv')\n",
    "# Clean the dataset once when loading, wikipedia has commas in the numbers.\n",
    "gold_standard_city_pop['population'] = gold_standard_city_pop['population'].astype(str).str.replace(',', '').astype(float)\n",
    "gold_standard_city_pop['land_area_mi2'] = gold_standard_city_pop['land_area_mi2'].astype(str).str.replace(',', '').astype(float)\n",
    "\n",
    "# Show the first 3 rows, as a reference\n",
    "print(gold_standard_city_pop.head(3))  # First 3 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2235ef4e-8971-4a49-8793-de47baadfbbe",
   "metadata": {},
   "source": [
    "Now we'll make a quick checking function.  Our agent will be trying to find population and area, so we'll compare how well it did against this list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "586489e3-7ebc-44e8-93cd-cd28e3946e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_city_guess(city, state, chatbot_response, dataset):\n",
    "    \"\"\"\n",
    "    Evaluate population and area guesses against the gold standard dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    - city: str, city name\n",
    "    - state: str, state abbreviation (e.g., 'NY', 'CA')\n",
    "    - chatbot_response: Strands AgentResult object to be evaluated\n",
    "    - dataset: pandas DataFrame, the gold standard dataset\n",
    "    \n",
    "    Returns:\n",
    "    - dict with percent errors for population and area, and total tokens, execution time, and tool calls.\n",
    "    \n",
    "    Raises:\n",
    "    - ValueError if city/state combination not found\n",
    "    \"\"\"\n",
    "    \n",
    "    # Clean the city name for matching\n",
    "    city_clean = city.strip()\n",
    "\n",
    "    \n",
    "    #use regex to grab the final answer as numbers\n",
    "    final_msg = chatbot_response.message['content'][0]['text']\n",
    "    try:\n",
    "        guessed_pop, guessed_area = int(re.search(r'<pop>(.*?)</pop>', final_msg).group(1)), float(re.search(r'<area>(.*?)</area>', final_msg).group(1))\n",
    "    except:\n",
    "        raise ValueError(f\"XML tags not found in reply\")\n",
    "\n",
    "    \n",
    "    #extract agent loop metrics\n",
    "    total_tokens = chatbot_response.metrics.accumulated_usage['totalTokens']\n",
    "    total_time = sum(chatbot_response.metrics.cycle_durations)\n",
    "    \n",
    "    tool_calls = 0\n",
    "    for t in chatbot_response.metrics.tool_metrics.keys():\n",
    "        tool_calls+= chatbot_response.metrics.tool_metrics[t].call_count\n",
    "\n",
    "    \n",
    "    # Find the city in the dataset\n",
    "    # Use case-insensitive matching and handle potential annotations\n",
    "    mask = (dataset['city'].str.replace(r'\\[.*\\]', '', regex=True).str.strip().str.lower() == city_clean.lower()) & \\\n",
    "           (dataset['state'].str.upper() == state.upper())\n",
    "    \n",
    "    matching_rows = dataset[mask]\n",
    "    \n",
    "    if len(matching_rows) == 0:\n",
    "        raise ValueError(f\"City '{city}' in state '{state}' not found in dataset\")\n",
    "    \n",
    "    if len(matching_rows) > 1:\n",
    "        print(f\"Warning: Multiple matches found for {city}, {state}. Using first match.\")\n",
    "    \n",
    "    # Get the actual values\n",
    "    actual_pop = matching_rows.iloc[0]['population']\n",
    "    actual_area = matching_rows.iloc[0]['land_area_mi2']\n",
    "    \n",
    "    # Calculate percent error: |actual - guess| / actual * 100\n",
    "    pop_error = abs(actual_pop - guessed_pop) / actual_pop * 100\n",
    "    area_error = abs(actual_area - guessed_area) / actual_area * 100\n",
    "    \n",
    "    return {\n",
    "        'city': matching_rows.iloc[0]['city'],\n",
    "        'state': matching_rows.iloc[0]['state'],\n",
    "        'actual_population': actual_pop,\n",
    "        'guessed_population': guessed_pop,\n",
    "        'population_error_percent': round(pop_error, 2),\n",
    "        'actual_area': actual_area,\n",
    "        'guessed_area': guessed_area,\n",
    "        'area_error_percent': round(area_error, 2),\n",
    "        'total_tokens': total_tokens,\n",
    "        'total_time': total_time,\n",
    "        'tool_calls': tool_calls\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb008bc3-7f4b-42db-8f91-feaca25761dc",
   "metadata": {},
   "source": [
    "## 2) Create a simple chat bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebd1355f-4bbc-4527-8260-7ea1df9c8d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def web_search(topic: str) -> str:\n",
    "    \"\"\"Search Google for a given topic.\n",
    "    Return a string listing the top 5 results including the url, title, and description of each result.\n",
    "    \"\"\"\n",
    "    result_string = \"\"\n",
    "    results = search(topic, num_results=5, advanced=True)\n",
    "    for result in results:\n",
    "        result_string += str(result)\n",
    "    return result_string\n",
    "    \n",
    "@tool      \n",
    "def get_page(url: str) -> str:\n",
    "    \"\"\"this function takes a URL and returns the raw text from that page.\n",
    "    it can be used to get more info based on a Google search result listing.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    bs = BeautifulSoup(response.text,'html.parser')\n",
    "    return bs.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6f84c95b-1441-470c-a3d5-ae62c81ccceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botocore.config import Config\n",
    "\n",
    "#A custom config for Bedrock to only allow short connections - for our demo we expect all calls to be fast.\n",
    "#here we turn off retries, and we time out after 20 seconds.\n",
    "quick_config = Config(\n",
    "    connect_timeout=5,\n",
    "    read_timeout=20,\n",
    "    retries={\"max_attempts\": 0}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "fed7801d-e699-4047-b965-1159b71feb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<thinking> \n",
      "To answer the User's request, I will first need to search for the current population of New York City and its area in square miles. After obtaining this information, I will format it according to the User's specifications, including it in XML tags as requested.\n",
      "</thinking>\n",
      "\n",
      "\n",
      "Tool #1: web_search\n",
      "\n",
      "Tool #2: web_search\n",
      "Based on the search results, here are the population and area details for New York City:\n",
      "\n",
      "The population of New York City is approximately 8,478,072 as of 2024.\n",
      "The area of New York City is around 300.46 square miles.\n",
      "\n",
      "Here is the information in the requested XML format:\n",
      "\n",
      "<pop>8478072</pop>\n",
      "<area>300.46</area>"
     ]
    }
   ],
   "source": [
    "#Create the chatbot.  We'll use Nova Micro to optimize for latency, cost, and capacity\n",
    "chatbot_model_name = \"us.amazon.nova-micro-v1:0\"\n",
    "#add custom timeout for the model, to keep the tool from hanging or retrying too much.\n",
    "chatbot_model = BedrockModel(\n",
    "    model_id=chatbot_model_name,\n",
    "    boto_client_config=quick_config    \n",
    ")\n",
    "chatbot = Agent(tools=[web_search,get_page], model=chatbot_model)\n",
    "#Call the chat bot with a simple request.\n",
    "prompt = \"\"\"How many people live in New York, and what's the area of the city in square miles?\n",
    "After you respond, also include your answer in 'pop' and 'area' XML tags, for programatic processing.\n",
    "The values in the XML tags should only be numbers, no words or commas.\"\"\"\n",
    "chatbot_response = chatbot(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b3e632-eb99-4809-8ded-a200936acf78",
   "metadata": {},
   "source": [
    "### Now that we have an answer from one call, let's check the error and other metrics using our eval function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fe12ee73-f649-4a7b-92b6-2e54c695012c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population error: 6.39%\n",
      "Area error: 0.01%\n",
      "Total Tokens: 2425 tokens\n",
      "Total Time: 1.05 seconds\n",
      "Tool Calls: 2\n"
     ]
    }
   ],
   "source": [
    "result = evaluate_city_guess(\"New York\", \"NY\", chatbot_response, gold_standard_city_pop)\n",
    "print(f\"Population error: {result['population_error_percent']}%\")\n",
    "print(f\"Area error: {result['area_error_percent']}%\")\n",
    "print(f\"Total Tokens: {result['total_tokens']} tokens\")\n",
    "print(f\"Total Time: {result['total_time']:.2f} seconds\")\n",
    "print(f\"Tool Calls: {result['tool_calls']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d94b89-e7d2-4da5-b169-0ab8fbe6e57b",
   "metadata": {},
   "source": [
    "Pretty close!  Now let's build an evaluator agent that can run some tests for us using the goldstandard dataset.\n",
    "We'll do this by wraping all of the above in a tool call.  First, let's make it a simple model comparason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c763ea87-45df-46e7-baf6-696900c814c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def eval_model(model_name: str) -> str:\n",
    "    \"\"\"Start an evaluator for a particular model.\n",
    "    model_name is the model endpoint to be evaluated.\n",
    "    Retruns a string containing information about this model.\n",
    "    \"\"\"\n",
    "    #add custom timeout for the model, to keep the tool from hanging or retrying too much.\n",
    "    chatbot_model = BedrockModel(\n",
    "        model_id=model_name,\n",
    "        boto_client_config=quick_config    \n",
    "    )\n",
    "    \n",
    "    chatbot = Agent(tools=[web_search,get_page], model=chatbot_model, callback_handler=None)# callback_handler=None to suppress sub agent print outs\n",
    "    #Call the chat bot with a simple request.\n",
    "    prompt = \"\"\"How many people live in New York, and what's the area of the city in square miles?\n",
    "    After you respond, also include your answer in 'pop' and 'area' XML tags, for programatic processing.\n",
    "    The values in the XML tags should only be numbers, no words or commas.\"\"\"\n",
    "    chatbot_response = chatbot(prompt)\n",
    "    result = evaluate_city_guess(\"New York\", \"NY\", chatbot_response, gold_standard_city_pop)\n",
    "    result_string = \"\"\n",
    "    result_string = result_string + f\"Population error: {result['population_error_percent']}%\" + '\\n'\n",
    "    result_string = result_string + f\"Area error: {result['area_error_percent']}%\" + '\\n'\n",
    "    result_string = result_string + f\"Total Tokens: {result['total_tokens']} tokens\" + '\\n'\n",
    "    result_string = result_string + f\"Total Time: {result['total_time']:.2f} seconds\" + '\\n'\n",
    "    result_string = result_string + f\"Tool Calls: {result['tool_calls']}\"\n",
    "    print (result_string)\n",
    "    return result_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "98cc0b6a-53c6-468e-98b2-47cf75d23678",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_prompt = \"\"\"\n",
    "Use the eval_model tool to evaluate these models:\n",
    "Nova Micro: \"us.amazon.nova-micro-v1:0\",\n",
    "Nova Lite: \"us.amazon.nova-lite-v1:0\",\n",
    "Nova Pro: \"us.amazon.nova-pro-v1:0\",\n",
    "Claude 3 Haiku: \"us.anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "Claude 3 Sonnet: \"us.anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "Provide a table comparason on the results, and include columns for all evaluation data points, including number of tool calls, and the number of times the model failed to evaluate and had to be retried.\n",
    "Do not include the endpoint names in the table, only the model names, to save space.\n",
    "If a model fails to evaluate, you should retry it up to 3 times.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a5f86066-e656-4f05-b55e-0e40407840e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<thinking> To evaluate the specified models using the `eval_model` tool, I will need to call this tool multiple times with different model names. Since each model has a unique endpoint, I will create a list of these endpoints and iterate over them. If a model fails to evaluate, I will retry it up to 3 times before considering it as failed. After collecting the results, I will compile them into a table format as requested.</thinking>\n",
      "\n",
      "\n",
      "Tool #1: eval_model\n",
      "\n",
      "Tool #2: eval_model\n",
      "\n",
      "Tool #3: eval_model\n",
      "\n",
      "Tool #4: eval_model\n",
      "\n",
      "Tool #5: eval_model\n",
      "Population error: 0.0%\n",
      "Area error: 0.01%\n",
      "Total Tokens: 1894 tokens\n",
      "Total Time: 0.99 seconds\n",
      "Tool Calls: 1\n",
      "Population error: 0.0%\n",
      "Area error: 0.01%\n",
      "Total Tokens: 2595 tokens\n",
      "Total Time: 1.16 seconds\n",
      "Tool Calls: 2\n",
      "Population error: 0.0%\n",
      "Area error: 0.01%\n",
      "Total Tokens: 1537 tokens\n",
      "Total Time: 1.29 seconds\n",
      "Tool Calls: 1\n",
      "Population error: 0.0%\n",
      "Area error: 0.01%\n",
      "Total Tokens: 1774 tokens\n",
      "Total Time: 1.40 seconds\n",
      "Tool Calls: 1\n",
      "Population error: 0.0%\n",
      "Area error: 0.17%\n",
      "Total Tokens: 1437 tokens\n",
      "Total Time: 2.99 seconds\n",
      "Tool Calls: 1\n",
      "<thinking> All the models were successfully evaluated without any failures. Now I will compile the results into a table format as requested, excluding the endpoint names and only including the model names.</thinking>\n",
      "\n",
      "Here is the comparison table of the evaluated models:\n",
      "\n",
      "| Model Name      | Population Error | Area Error | Total Tokens | Total Time | Tool Calls | Retries |\n",
      "|-----------------|-----------------|------------|--------------|------------|------------|---------|\n",
      "| Nova Micro      | 0.0%            | 0.01%      | 2595          | 1.16 sec   | 2          | 0       |\n",
      "| Nova Lite       | 0.0%            | 0.01%      | 1894          | 0.99 sec   | 1          | 0       |\n",
      "| Nova Pro        | 0.0%            | 0.01%      | 1774          | 1.40 sec   | 1          | 0       |\n",
      "| Claude 3 Haiku   | 0.0%            | 0.01%      | 1537          | 1.29 sec   | 1          | 0       |\n",
      "| Claude 3 Sonnet  | 0.0%            | 0.17%      | 1437          | 2.99 sec   | 1          | 0       |\n",
      "\n",
      "Each model's evaluation data points are listed including the number of tool calls, the number of times the model failed to evaluate and had to be retried (which is 0 for all models in this case)."
     ]
    }
   ],
   "source": [
    "evaluator = Agent(tools=[eval_model], model=chatbot_model)\n",
    "evaluator_response = evaluator(evaluator_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0933f9-107d-4598-9a9d-06a64ca64826",
   "metadata": {},
   "source": [
    "### Awesome!  Now we have some basic model evals.  You'll note that the agent ran all 5 tests in parallel.\n",
    "### Next, we'll expand our evaluator to be able to check based on more than one data point.  We add the calculator too to assist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346c19e8-5fba-4cbd-831e-2f4ecdf2fdf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca00398-c43e-40a9-9ecd-e84c7806e823",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
