{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d50ad271245244b",
   "metadata": {},
   "source": [
    "# Generating Synthetic Traces for Customer Support Agent  Evaluation\n",
    "\n",
    "## Workshop Overview\n",
    "\n",
    "In this workshop, you'll learn how to systematically generate high-quality synthetic data for evaluating a customer support chatbot. We'll follow a structured approach that moves beyond naive prompt generation to create realistic, diverse customer queries.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this workshop, you will:\n",
    "- Learn how to define evaluation dimensions for your specific use case\n",
    "- Generate diverse dimension combinations using LLMs\n",
    "- Create realistic natural language queries from structured dimensions\n",
    "- Build a curated dataset for LLM evaluation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63bfe3c5bb1cc2f",
   "metadata": {},
   "source": [
    "# Environment Setup\n",
    "\n",
    "## Instructions:\n",
    "1. **Install Required Dependencies**: Run this cell to install the necessary Python packages for the workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77ea13d3-f395-4765-972a-3c6a5bd3bcb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (1.40.13)\n",
      "Requirement already satisfied: pydantic in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (2.11.7)\n",
      "Collecting litellm\n",
      "  Downloading litellm-1.75.9-py3-none-any.whl.metadata (41 kB)\n",
      "Requirement already satisfied: botocore<1.41.0,>=1.40.13 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from boto3) (1.40.13)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from boto3) (0.13.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from pydantic) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from pydantic) (4.12.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from pydantic) (0.4.1)\n",
      "Requirement already satisfied: aiohttp>=3.10 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from litellm) (3.11.11)\n",
      "Collecting click (from litellm)\n",
      "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpx>=0.23.0 (from litellm)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from litellm) (8.6.1)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from litellm) (3.1.5)\n",
      "Collecting jsonschema<5.0.0,>=4.22.0 (from litellm)\n",
      "  Downloading jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting openai>=1.99.5 (from litellm)\n",
      "  Downloading openai-1.100.2-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting python-dotenv>=0.2.0 (from litellm)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from litellm) (0.8.0)\n",
      "Collecting tokenizers (from litellm)\n",
      "  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from aiohttp>=3.10->litellm) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from aiohttp>=3.10->litellm) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from aiohttp>=3.10->litellm) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from aiohttp>=3.10->litellm) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from aiohttp>=3.10->litellm) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from aiohttp>=3.10->litellm) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from aiohttp>=3.10->litellm) (1.18.3)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from botocore<1.41.0,>=1.40.13->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from botocore<1.41.0,>=1.40.13->boto3) (2.3.0)\n",
      "Collecting anyio (from httpx>=0.23.0->litellm)\n",
      "  Downloading anyio-4.10.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from httpx>=0.23.0->litellm) (2024.12.14)\n",
      "Collecting httpcore==1.* (from httpx>=0.23.0->litellm)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: idna in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from httpx>=0.23.0->litellm) (3.10)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.23.0->litellm)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from importlib-metadata>=6.8.0->litellm) (3.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from jinja2<4.0.0,>=3.1.2->litellm) (3.0.2)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema<5.0.0,>=4.22.0->litellm)\n",
      "  Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema<5.0.0,>=4.22.0->litellm)\n",
      "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema<5.0.0,>=4.22.0->litellm)\n",
      "  Downloading rpds_py-0.27.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.99.5->litellm)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai>=1.99.5->litellm)\n",
      "  Downloading jiter-0.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting sniffio (from openai>=1.99.5->litellm)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>4 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from openai>=1.99.5->litellm) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from tiktoken>=0.7.0->litellm) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from tiktoken>=0.7.0->litellm) (2.32.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from tokenizers->litellm) (0.27.1)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (6.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.41.0,>=1.40.13->boto3) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm) (3.4.1)\n",
      "Downloading litellm-1.75.9-py3-none-any.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m180.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
      "Downloading openai-1.100.2-py3-none-any.whl (787 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m787.8/787.8 kB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m161.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading anyio-4.10.0-py3-none-any.whl (107 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\n",
      "Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
      "Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.27.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (386 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: sniffio, rpds-py, python-dotenv, jiter, h11, distro, click, referencing, httpcore, anyio, tokenizers, jsonschema-specifications, httpx, openai, jsonschema, litellm\n",
      "Successfully installed anyio-4.10.0 click-8.2.1 distro-1.9.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 jiter-0.10.0 jsonschema-4.25.1 jsonschema-specifications-2025.4.1 litellm-1.75.9 openai-1.100.2 python-dotenv-1.1.1 referencing-0.36.2 rpds-py-0.27.0 sniffio-1.3.1 tokenizers-0.21.4\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3 pydantic litellm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c532a79c-9a06-46f0-b586-f0c3926222d2",
   "metadata": {},
   "source": [
    "# Import Libraries and Configuration\n",
    "\n",
    "## Instructions:\n",
    "1. **Review the imports**: Notice we're importing tools for:\n",
    "   - AWS Bedrock integration (`boto3`)\n",
    "   - Data validation (`pydantic`)\n",
    "   - LLM calls (`litellm`)\n",
    "   - Parallel processing and progress tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9b3dcd7c903b4d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional, Dict, Any\n",
    "from litellm import completion\n",
    "import time\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "MODEL_NAME=\"bedrock/anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "NUM_TUPLES_TO_GENERATE = 10  # Generate more tuples than needed to ensure diversity\n",
    "NUM_QUERIES_PER_TUPLE = 5    # Generate multiple queries per tuple\n",
    "OUTPUT_CSV_PATH = Path(\"bootstrap_data/synthetic_queries_for_analysis.csv\")\n",
    "MAX_WORKERS = 5  # Number of parallel LLM calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270468a6-001d-47e8-b207-3b311d2d3948",
   "metadata": {},
   "source": [
    "### LLM calls Utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8fc85ffc-c7ad-4c78-aab8-c5245b185a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm(messages: List[Dict[str, str]], response_format: Any) -> Any:\n",
    "    \"\"\"Make a single LLM call with retries.\"\"\"\n",
    "    max_retries = 3\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = completion(\n",
    "                model=MODEL_NAME,\n",
    "                messages=messages,\n",
    "                response_format=response_format\n",
    "            )\n",
    "            return response_format(**json.loads(response.choices[0].message.content))\n",
    "        except Exception as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                raise e\n",
    "            time.sleep(1)  # Wait before retry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc6f8ce-5df3-4ce2-8e64-a081e87b032e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Understanding the Problem\n",
    "\n",
    "## Instructions:\n",
    "1. **Read the objective carefully**: We need ~100 diverse, realistic customer support requests\n",
    "2. **Key insight**: \"Naively generated queries tend to be generic, repetitive, and fail to capture real usage patterns\"\n",
    "3. **Solution**: Use a systematic approach with defined dimensions\n",
    "\n",
    "## Workshop Discussion Points:\n",
    "- Why is synthetic data important when real data isn't available?\n",
    "- What makes a query \"realistic\" vs \"generic\"?\n",
    "- How can we ensure diversity in our generated data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784ceec1-a148-45eb-81ba-7bca4cacb17e",
   "metadata": {},
   "source": [
    "# Define Evaluation Dimensions\n",
    "\n",
    "A dimension is a way to categorize different parts of a user query. Each dimension represents ONE axis of variation. In our example customer service chatbot.\n",
    "\n",
    "Feature: What task or enquiry the user wants to perform e.g order cancelation\n",
    "Persona: What type of client e.g first time buyer, existing buyer\n",
    "scenario: How clear is the intent specified from the user e.g concise or verbose\n",
    "\n",
    "## Instructions:\n",
    "1. **Study each dimension carefully**:\n",
    "   - **Intent**: What the user wants to accomplish\n",
    "   - **Complexity**: How difficult the query is to handle\n",
    "   - **Persona**: What type of user is making the request\n",
    "   - **Language Style**: How the user communicates\n",
    "\n",
    "2. **Critical principle**: \"Choose dimensions that describe where the AI application is likely to fail\"\n",
    "\n",
    "3. **Review the Pydantic models**: Notice how we structure our data for validation\n",
    "\n",
    "## Workshop Activity:\n",
    "What other dimensions might be relevant for your specific use case?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289d28cf-94ca-4f96-ac42-f4cdcfd64694",
   "metadata": {},
   "source": [
    "# Dimension Tuple Generation Function\n",
    "\n",
    "## Instructions:\n",
    "1. **Examine the prompt structure**: Notice how we:\n",
    "   - Provide clear instructions for balanced coverage\n",
    "   - Include realistic constraints (e.g., new customers rarely have returns)\n",
    "   - Request specific numbers of combinations\n",
    "\n",
    "2. **Understand the parallel processing**: We make multiple calls and deduplicate results\n",
    "\n",
    "3. **Run this cell**: It defines the function but doesn't execute it yet\n",
    "\n",
    "## Key Concept:\n",
    "Good prompt engineering includes constraints and examples to guide the LLM toward realistic outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7715d169-b607-4760-9f2e-3fc8affdf797",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Define Pydantic Models for structured Output\n",
    "\n",
    "class DimensionTuple(BaseModel):\n",
    "    intent: str = Field(\n",
    "        description=\"The user's primary goal or task (e.g., product_inquiry, order_status_check, return_request, technical_support, account_management, general_info).\"\n",
    "    )\n",
    "    complexity: str = Field(\n",
    "        description=\"The difficulty and structure of the query (e.g., simple, multi-turn, ambiguous).\"\n",
    "    )\n",
    "    persona: str = Field(\n",
    "        description=\"The type of user based on their behavior or relationship with the store (e.g., new_customer, repeat_customer, frustrated_customer, loyalty_member).\"\n",
    "    )\n",
    "    language_style: str = Field(\n",
    "        description=\"Linguistic characteristics of the query (e.g., formal, informal, contains_slang, includes_typos, verbose, concise).\"\n",
    "    )\n",
    "\n",
    "class DimensionTuples(BaseModel):\n",
    "    tuples: List[DimensionTuple]\n",
    "\n",
    "class DimensionTuplesList(BaseModel):\n",
    "    tuples: List[DimensionTuple]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff6fc3d-7eab-4703-a785-4ed047174054",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6f0b4185-43d6-4152-82e6-ed95aa835da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_key_dimensions(num_tuples_to_generate) -> List[DimensionTuple]:\n",
    "    \"\"\"Generate diverse dimension tuples.\"\"\"\n",
    "    prompt=\"\"\"\\\n",
    "        I am designing a customer support chatbot for a retail company and need to generate a diverse set of synthetic test data to evaluate its performance. I've provided you with the key dimensions that make up a customer's inquiry, along with a list of possible values for each.\n",
    "        \n",
    "        ## Instructions\n",
    "        \n",
    "        Generate {{{num_tuples_to_generate}}} unique combinations of dimension values based on the dimensions provided below.\n",
    "        \n",
    "        * Each combination should represent a distinct customer support scenario.\n",
    "        * Ensure **balanced coverage** across all dimensions; avoid over-representing any single value or combination.\n",
    "        * The generated tuples should be as realistic and varied as possible. For example, a frustrated customer is likely to use informal language and ask a complex question about a return.\n",
    "        * Never generate a tuple where the persona is 'new_customer' and the intent is 'return_request' or 'order_status_check' unless the complexity is multi-turn to simulate a scenario where they are new to this process.\n",
    "        \n",
    "        ## Dimensions\n",
    "        \n",
    "        * **intent**: What kind of inquiry are they making?\n",
    "            * product_inquiry\n",
    "            * order_status_check\n",
    "            * request_for_action_or_service\n",
    "            * return_request\n",
    "            * cancel_order\n",
    "            * technical_support\n",
    "            * account_management\n",
    "            * general_info\n",
    "        * **complexity**: The difficulty and structure of the query.\n",
    "            * simple\n",
    "            * multi-turn\n",
    "            * ambiguous\n",
    "        * **persona**: The type of user making the request\n",
    "            * new_customer\n",
    "            * repeat_customer\n",
    "            * frustrated_customer\n",
    "            * loyalty_member\n",
    "        * **language_style**: The linguistic characteristics of the query\n",
    "            * formal\n",
    "            * informal\n",
    "            * contains_slang\n",
    "            * includes_typos\n",
    "        \n",
    "        Generate {{{num_tuples_to_generate}}} unique dimension tuples.\n",
    "    \"\"\"\n",
    "    final_prompt = prompt.replace(\"{{{num_tuples_to_generate}}}\", str(num_tuples_to_generate))\n",
    "\n",
    "    messages = [{\"role\": \"user\", \"content\": final_prompt}]\n",
    "    \n",
    "    try:\n",
    "        print(\"Generating dimension tuples in parallel...\")\n",
    "        with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "            # Submit five generation tasks using a loop\n",
    "            futures = []\n",
    "            for _ in range(5):\n",
    "                futures.append(executor.submit(call_llm, messages, DimensionTuplesList))\n",
    "            \n",
    "            # Wait for all to complete and collect results\n",
    "            responses = []\n",
    "            for future in futures:\n",
    "                responses.append(future.result())\n",
    "        \n",
    "        # Combine tuples and remove duplicates\n",
    "        all_tuples = []\n",
    "        for response in responses:\n",
    "            all_tuples.extend(response.tuples)\n",
    "        unique_tuples = []\n",
    "        seen = set()\n",
    "        \n",
    "        for tup in all_tuples:\n",
    "            # Convert tuple to a comparable string representation\n",
    "            tuple_str = tup.model_dump_json()\n",
    "            if tuple_str not in seen:\n",
    "                seen.add(tuple_str)\n",
    "                unique_tuples.append(tup)\n",
    "        \n",
    "        print(f\"Generated {len(all_tuples)} total tuples, {len(unique_tuples)} unique\")\n",
    "        return unique_tuples\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating dimension tuples: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d7c614-64c7-452c-bc7a-a6ff8c3aabad",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Generate Dimension Combinations\n",
    "\n",
    "## Instructions:\n",
    "1. **Execute this cell**: It will generate diverse dimension combinations\n",
    "2. **Watch the output**: You should see parallel generation happening\n",
    "3. **Review the results**: Examine the generated tuples for:\n",
    "   - Realistic combinations\n",
    "   - Balanced coverage across dimensions\n",
    "   - Absence of impossible scenarios\n",
    "\n",
    "## Expected Output:\n",
    "- \"Generated X total tuples, Y unique\"\n",
    "- A list of DimensionTuple objects with varied combinations\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3e10d5fb-f489-44f0-aa43-87961f79cae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating dimension tuples in parallel...\n",
      "Generated 25 total tuples, 20 unique\n"
     ]
    }
   ],
   "source": [
    "dimension_tuples = generate_key_dimensions(num_tuples_to_generate=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ed71ff-6233-486c-a72a-5da01615db51",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Review Generated Tuples\n",
    "\n",
    "## Instructions:\n",
    "1. **Examine the output**: Look at the variety of combinations generated\n",
    "2. **Quality check**: Verify that combinations make sense (e.g., frustrated customers with complex queries)\n",
    "3. **Note the balance**: See how different dimensions are represented\n",
    "\n",
    "## Workshop Discussion:\n",
    "- Which combinations seem most realistic?\n",
    "- Are there any combinations that seem problematic?\n",
    "- How does this compare to manually brainstorming scenarios?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9768da13-131d-4208-ade6-c6fa0b526b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DimensionTuple(intent='product_inquiry', complexity='simple', persona='repeat_customer', language_style='formal'),\n",
       " DimensionTuple(intent='request_for_action_or_service', complexity='multi-turn', persona='loyalty_member', language_style='informal'),\n",
       " DimensionTuple(intent='technical_support', complexity='ambiguous', persona='frustrated_customer', language_style='contains_slang'),\n",
       " DimensionTuple(intent='return_request', complexity='multi-turn', persona='repeat_customer', language_style='includes_typos'),\n",
       " DimensionTuple(intent='account_management', complexity='simple', persona='new_customer', language_style='formal'),\n",
       " DimensionTuple(intent='technical_support', complexity='multi-turn', persona='frustrated_customer', language_style='informal'),\n",
       " DimensionTuple(intent='account_management', complexity='ambiguous', persona='loyalty_member', language_style='includes_typos'),\n",
       " DimensionTuple(intent='request_for_action_or_service', complexity='multi-turn', persona='new_customer', language_style='contains_slang'),\n",
       " DimensionTuple(intent='cancel_order', complexity='simple', persona='repeat_customer', language_style='formal'),\n",
       " DimensionTuple(intent='product_inquiry', complexity='simple', persona='new_customer', language_style='formal'),\n",
       " DimensionTuple(intent='return_request', complexity='multi-turn', persona='frustrated_customer', language_style='informal'),\n",
       " DimensionTuple(intent='technical_support', complexity='ambiguous', persona='repeat_customer', language_style='contains_slang'),\n",
       " DimensionTuple(intent='account_management', complexity='multi-turn', persona='loyalty_member', language_style='formal'),\n",
       " DimensionTuple(intent='request_for_action_or_service', complexity='simple', persona='repeat_customer', language_style='includes_typos'),\n",
       " DimensionTuple(intent='account_management', complexity='ambiguous', persona='loyalty_member', language_style='contains_slang'),\n",
       " DimensionTuple(intent='cancel_order', complexity='simple', persona='new_customer', language_style='includes_typos'),\n",
       " DimensionTuple(intent='return_request', complexity='multi-turn', persona='repeat_customer', language_style='informal'),\n",
       " DimensionTuple(intent='technical_support', complexity='ambiguous', persona='loyalty_member', language_style='contains_slang'),\n",
       " DimensionTuple(intent='account_management', complexity='multi-turn', persona='new_customer', language_style='includes_typos'),\n",
       " DimensionTuple(intent='general_info', complexity='simple', persona='repeat_customer', language_style='formal')]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimension_tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cb50b8-983e-4c97-b332-c989264bc25d",
   "metadata": {},
   "source": [
    "# Query Generation Functions\n",
    "\n",
    "## Instructions:\n",
    "1. **Study the prompt template**: Notice how we:\n",
    "   - Inject the dimension tuple into the prompt\n",
    "   - Provide specific formatting instructions\n",
    "   - Include examples of realistic variations\n",
    "   - Request natural, conversational language\n",
    "\n",
    "2. **Understand the parallel processing setup**: We'll generate multiple queries per tuple simultaneously\n",
    "\n",
    "3. **Run this cell below**: This defines the functions but doesn't execute generation yet\n",
    "\n",
    "## Key Concept:\n",
    "Converting structured dimensions to natural language requires careful prompt engineering with examples and constraints.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0e8e945d-937c-4c4f-b5b9-a1f9cfa53182",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueriesList(BaseModel):\n",
    "    queries: list[str]\n",
    "\n",
    "def generate_queries(dimension_tuple: DimensionTuple) -> List[str]:\n",
    "    \"\"\"Generate natural language queries for a given dimension tuple using Bedrock.\"\"\"\n",
    "    \n",
    "    # Use json.dumps for a clean, readable JSON representation in the prompt\n",
    "    dimension_json = json.dumps(dimension_tuple.model_dump(), indent=2)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "            You are tasked with generating natural language queries for an online apparel retailer chatbot. Your goal is to create realistic, varied queries that match specific characteristics. Here's what you need to know:\n",
    "        \n",
    "        First, here is the dimension tuple that defines the characteristics for this set of queries:\n",
    "        <dimension_tuple>\n",
    "        {{DIMENSION_TUPLE}}\n",
    "        </dimension_tuple>\n",
    "        \n",
    "        Now, here are the dimensions for query generation:\n",
    "        <dimension_json>\n",
    "        {{DIMENSION_JSON}}\n",
    "        </dimension_json>\n",
    "        \n",
    "        Follow these instructions to generate the queries:\n",
    "        \n",
    "        1. Generate exactly {{NUM_QUERIES_PER_TUPLE}} unique queries that perfectly match the specified dimensions in the dimension tuple.\n",
    "        \n",
    "        2. Focus on realism: The queries should sound like something a real person would type into a chatbot. They should be natural and conversational.\n",
    "        \n",
    "        3. Incorporate all dimensions: The language and content of each query must naturally reflect all five dimensions (intent, complexity, persona, language_style, and failure_scenario) as specified in the dimension tuple.\n",
    "        \n",
    "        4. Vary the style: Within the specified 'language_style', introduce natural variations such as:\n",
    "           - Common misspellings\n",
    "           - Missing punctuation\n",
    "           - Different capitalization\n",
    "           - Use of emojis\n",
    "           - Text-speak (e.g., 'thx', 'pls', 'gonna')\n",
    "        \n",
    "        5. Be concise and direct: Each query should be to the point and reflect how a real user would interact with a chatbot.\n",
    "        \n",
    "        Here are some examples of realistic variations to guide you:\n",
    "        \n",
    "        - For a \"Frustrated Customer\" with \"Technical Support\" intent and \"Incomplete Info\" scenario:\n",
    "          \"my discount code aint working its stupid\"\n",
    "          \"why is the site crashing\"\n",
    "          \"i need help with the cart but its broken\"\n",
    "        \n",
    "        - For a \"New Customer\" with \"Product Inquiry\" intent, \"Simple\" complexity, and \"Formal\" language style:\n",
    "          \"Could you please tell me about the sizing for the women's jackets?\"\n",
    "          \"Hello, I have a question regarding the material of the new shirt.\"\n",
    "        \n",
    "        Your output should be a simple list of the {{NUM_QUERIES_PER_TUPLE}} generated queries, nothing more. Do not number the queries or add any additional text. Each query should be on a new line.\n",
    "        \n",
    "        <output>\n",
    "        [Insert your {{NUM_QUERIES_PER_TUPLE}} generated queries here, one per line]\n",
    "        </output>\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    try:\n",
    "        # The call to the LLM would be handled here\n",
    "        response = call_llm(messages, QueriesList)\n",
    "        return response.queries\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating queries for tuple: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3687268-114f-4055-ab7e-4b6ad90b788c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Execute Query Generation\n",
    "\n",
    "## Instructions:\n",
    "1. **Run this cell**: It will generate natural language queries for each dimension tuple\n",
    "2. **Monitor progress**: You'll see a progress bar showing query generation\n",
    "3. **Handle rate limits**: The system includes automatic retries for rate limit errors\n",
    "\n",
    "## Expected Behavior:\n",
    "- Progress bar showing generation status\n",
    "- Some rate limit warnings (normal with parallel processing)\n",
    "- Successful generation of multiple queries per tuple\n",
    "\n",
    "## Troubleshooting:\n",
    "Rate limit errors are expected with parallel processing. So we only generating 20 query samples.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0ceacd8f-29ef-4fc3-9ea8-cc28437052cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 5 queries each for 20 dimension tuples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Queries:  30%|███       | 6/20 [00:14<00:39,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Queries:  35%|███▌      | 7/20 [00:16<00:34,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "Error generating queries for tuple: litellm.RateLimitError: BedrockException - {\"message\":\"Too many requests, please wait before trying again.\"}\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Queries:  45%|████▌     | 9/20 [00:18<00:19,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "Error generating queries for tuple: litellm.RateLimitError: BedrockException - {\"message\":\"Too many requests, please wait before trying again.\"}\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Queries:  50%|█████     | 10/20 [00:20<00:18,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "Error generating queries for tuple: litellm.RateLimitError: BedrockException - {\"message\":\"Too many requests, please wait before trying again.\"}\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Queries:  55%|█████▌    | 11/20 [00:21<00:14,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Queries:  60%|██████    | 12/20 [00:21<00:09,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Queries:  65%|██████▌   | 13/20 [00:22<00:07,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Queries:  70%|███████   | 14/20 [00:22<00:04,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "Error generating queries for tuple: litellm.RateLimitError: BedrockException - {\"message\":\"Too many requests, please wait before trying again.\"}\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Queries:  75%|███████▌  | 15/20 [00:23<00:04,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "Error generating queries for tuple: litellm.RateLimitError: BedrockException - {\"message\":\"Too many requests, please wait before trying again.\"}\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Queries:  80%|████████  | 16/20 [00:24<00:03,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "Error generating queries for tuple: litellm.RateLimitError: BedrockException - {\"message\":\"Too many requests, please wait before trying again.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Queries:  85%|████████▌ | 17/20 [00:25<00:02,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "Error generating queries for tuple: litellm.RateLimitError: BedrockException - {\"message\":\"Too many requests, please wait before trying again.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Queries:  90%|█████████ | 18/20 [00:25<00:01,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "Error generating queries for tuple: litellm.RateLimitError: BedrockException - {\"message\":\"Too many requests, please wait before trying again.\"}\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Queries: 100%|██████████| 20/20 [00:37<00:00,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating queries for tuple: 1 validation error for QueriesList\n",
      "queries\n",
      "  Input should be a valid list [type=list_type, input_value='[\\n\"Hey, do you have any... much after washing\"\\n]', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/list_type\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class QueryWithDimensions(BaseModel):\n",
    "    id: str\n",
    "    query: str\n",
    "    dimension_tuple: DimensionTuple\n",
    "    is_realistic_and_kept: int = 1\n",
    "    notes_for_filtering: str = \"\"\n",
    "\n",
    "def generate_queries_parallel(dimension_tuples: List[DimensionTuple]) -> List[QueryWithDimensions]:\n",
    "    \"\"\"Generate queries in parallel for all dimension tuples.\"\"\"\n",
    "    all_queries = []\n",
    "    query_id = 1\n",
    "    \n",
    "    print(f\"Generating {NUM_QUERIES_PER_TUPLE} queries each for {len(dimension_tuples)} dimension tuples...\")\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        # Submit all query generation tasks\n",
    "        future_to_tuple = {\n",
    "            executor.submit(generate_queries_for_tuple, dim_tuple): i \n",
    "            for i, dim_tuple in enumerate(dimension_tuples)\n",
    "        }\n",
    "        \n",
    "        # Process completed generations as they finish\n",
    "        with tqdm(total=len(dimension_tuples), desc=\"Generating Queries\") as pbar:\n",
    "            for future in as_completed(future_to_tuple):\n",
    "                tuple_idx = future_to_tuple[future]\n",
    "                try:\n",
    "                    queries = future.result()\n",
    "                    if queries:\n",
    "                        for query in queries:\n",
    "                            all_queries.append(QueryWithDimensions(\n",
    "                                id=f\"SYN{query_id:03d}\",\n",
    "                                query=query,\n",
    "                                dimension_tuple=dimension_tuples[tuple_idx]\n",
    "                            ))\n",
    "                            query_id += 1\n",
    "                    pbar.update(1)\n",
    "                except Exception as e:\n",
    "                    print(f\"Tuple {tuple_idx + 1} generated an exception: {e}\")\n",
    "                    pbar.update(1)\n",
    "    \n",
    "    return all_queries\n",
    "#### Execute to generate queries by passing tuples generated earlier\n",
    "queries = generate_queries_parallel(dimension_tuples=dimension_tuples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3616b6-3055-45c6-9560-bad7a97fc5ec",
   "metadata": {},
   "source": [
    "# Review Generated Queries\n",
    "\n",
    "## Instructions:\n",
    "1. **Examine the output**: Look at the variety and realism of generated queries\n",
    "2. **Quality assessment**: Check if queries match their dimension specifications:\n",
    "   - Do frustrated customers sound frustrated?\n",
    "   - Are complex queries actually complex?\n",
    "   - Do the language styles match the specifications?\n",
    "\n",
    "3. **Count your results**: Verify you have the expected number of queries\n",
    "\n",
    "## Workshop Discussion:\n",
    "- Which queries seem most realistic?\n",
    "- How do these compare to queries you might write manually?\n",
    "- What patterns do you notice across different dimension combinations?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "bc016ae6-7261-4439-afb0-e89d2e4ca881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[QueryWithDimensions(id='SYN001', query='hi can u help me find some cute new summer outfits?', dimension_tuple=DimensionTuple(intent='technical_support', complexity='ambiguous', persona='frustrated_customer', language_style='contains_slang'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN002', query='what are your current sales on dresses looking for something flowy', dimension_tuple=DimensionTuple(intent='technical_support', complexity='ambiguous', persona='frustrated_customer', language_style='contains_slang'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN003', query='howdy looking for a nice tank top and shorts outfit for vacation', dimension_tuple=DimensionTuple(intent='technical_support', complexity='ambiguous', persona='frustrated_customer', language_style='contains_slang'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN004', query='heyy any recommendations for rompers or jumpsuits very flattering', dimension_tuple=DimensionTuple(intent='technical_support', complexity='ambiguous', persona='frustrated_customer', language_style='contains_slang'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN005', query='need something casual but stylish for warm weather any ideas?', dimension_tuple=DimensionTuple(intent='technical_support', complexity='ambiguous', persona='frustrated_customer', language_style='contains_slang'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN006', query='Can you tell me where you source your cotton from?', dimension_tuple=DimensionTuple(intent='account_management', complexity='simple', persona='new_customer', language_style='formal'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN007', query='Hi, wondering if you have any relaxed fit flannels for men in stock right now', dimension_tuple=DimensionTuple(intent='account_management', complexity='simple', persona='new_customer', language_style='formal'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN008', query=\"What's the return policy like if something doesn't fit right?\", dimension_tuple=DimensionTuple(intent='account_management', complexity='simple', persona='new_customer', language_style='formal'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN009', query='Do your shirts come pre-shrunk or should I order a size up?', dimension_tuple=DimensionTuple(intent='account_management', complexity='simple', persona='new_customer', language_style='formal'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN010', query='Are your garments made with ethical labour practices? thx', dimension_tuple=DimensionTuple(intent='account_management', complexity='simple', persona='new_customer', language_style='formal'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN011', query='whats the difference between mens 32 and 34 jeans', dimension_tuple=DimensionTuple(intent='return_request', complexity='multi-turn', persona='repeat_customer', language_style='includes_typos'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN012', query=\"hey i'm looking for a nice summer dress whats on sale\", dimension_tuple=DimensionTuple(intent='return_request', complexity='multi-turn', persona='repeat_customer', language_style='includes_typos'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN013', query='hi i need some casual slim fit chinos any recommendations', dimension_tuple=DimensionTuple(intent='return_request', complexity='multi-turn', persona='repeat_customer', language_style='includes_typos'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN014', query='sup bro you have stretchy joggers for workin out', dimension_tuple=DimensionTuple(intent='return_request', complexity='multi-turn', persona='repeat_customer', language_style='includes_typos'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN015', query='waddup any discounts on sneakers or running shoes', dimension_tuple=DimensionTuple(intent='return_request', complexity='multi-turn', persona='repeat_customer', language_style='includes_typos'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN016', query='hey i need some new jeans what u got', dimension_tuple=DimensionTuple(intent='request_for_action_or_service', complexity='multi-turn', persona='loyalty_member', language_style='informal'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN017', query='lemme get a zip up hoodie for men pls', dimension_tuple=DimensionTuple(intent='request_for_action_or_service', complexity='multi-turn', persona='loyalty_member', language_style='informal'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN018', query='whats a good flannel for fall', dimension_tuple=DimensionTuple(intent='request_for_action_or_service', complexity='multi-turn', persona='loyalty_member', language_style='informal'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN019', query='yo i need some kicks size 10 mens', dimension_tuple=DimensionTuple(intent='request_for_action_or_service', complexity='multi-turn', persona='loyalty_member', language_style='informal'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN020', query='any athleisure style tops 4 workin out?', dimension_tuple=DimensionTuple(intent='request_for_action_or_service', complexity='multi-turn', persona='loyalty_member', language_style='informal'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN021', query='hey any sizing charts for mens polos?', dimension_tuple=DimensionTuple(intent='account_management', complexity='ambiguous', persona='loyalty_member', language_style='includes_typos'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN022', query='plz help - cant find the info on material 4 sweatshirts thnx', dimension_tuple=DimensionTuple(intent='account_management', complexity='ambiguous', persona='loyalty_member', language_style='includes_typos'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN023', query='yo whats the diff between regular + slim fit chinos', dimension_tuple=DimensionTuple(intent='account_management', complexity='ambiguous', persona='loyalty_member', language_style='includes_typos'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN024', query='hello, what is the return policy? appreciate any details :)', dimension_tuple=DimensionTuple(intent='account_management', complexity='ambiguous', persona='loyalty_member', language_style='includes_typos'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN025', query='what r the available colors 4 basic tees?', dimension_tuple=DimensionTuple(intent='account_management', complexity='ambiguous', persona='loyalty_member', language_style='includes_typos'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN026', query=\"I'm a regular customer looking to order a couple shirts, can you help me find some nice casual tees for men?\", dimension_tuple=DimensionTuple(intent='request_for_action_or_service', complexity='multi-turn', persona='new_customer', language_style='contains_slang'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN027', query='Hey there! Any cool new streetwear hoodies that just dropped? 🔥', dimension_tuple=DimensionTuple(intent='request_for_action_or_service', complexity='multi-turn', persona='new_customer', language_style='contains_slang'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN028', query='I need some advice on which jeans would look best with boots for a night out', dimension_tuple=DimensionTuple(intent='request_for_action_or_service', complexity='multi-turn', persona='new_customer', language_style='contains_slang'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN029', query=\"Yo what's good with the clearance section? Any dope deals on graphic tees or joggers rn?\", dimension_tuple=DimensionTuple(intent='request_for_action_or_service', complexity='multi-turn', persona='new_customer', language_style='contains_slang'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN030', query='Tryna find a nice casual button-up for date night, got any recommendations in navy or burgundy?', dimension_tuple=DimensionTuple(intent='request_for_action_or_service', complexity='multi-turn', persona='new_customer', language_style='contains_slang'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN031', query=\"Hey, can you show me your latest collection of casual t-shirts? I'm looking for something stylish but relaxed.\", dimension_tuple=DimensionTuple(intent='cancel_order', complexity='simple', persona='repeat_customer', language_style='formal'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN032', query='Wassup! Got any cool graphic tees with funny prints on em? Somethin unique and dope.', dimension_tuple=DimensionTuple(intent='cancel_order', complexity='simple', persona='repeat_customer', language_style='formal'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN033', query=\"Hi there, I'd appreciate some help finding a cute summer dress that's lightweight and flowy. I'm going on vacation soon!\", dimension_tuple=DimensionTuple(intent='cancel_order', complexity='simple', persona='repeat_customer', language_style='formal'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN034', query='Any recommendations for a nice polo shirt? Need it for a work event, preferably in a solid color like navy or burgundy.', dimension_tuple=DimensionTuple(intent='cancel_order', complexity='simple', persona='repeat_customer', language_style='formal'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN035', query=\"Yo what new hoodies you guys got? I'm tryna get one with a sick design, like some streetwear vibes ya feel me?\", dimension_tuple=DimensionTuple(intent='cancel_order', complexity='simple', persona='repeat_customer', language_style='formal'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN036', query=\"Where can I find the new summer collection for men's polos?\", dimension_tuple=DimensionTuple(intent='product_inquiry', complexity='simple', persona='repeat_customer', language_style='formal'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN037', query=\"What's the return policy for shoes bought online?\", dimension_tuple=DimensionTuple(intent='product_inquiry', complexity='simple', persona='repeat_customer', language_style='formal'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN038', query='Hey, looking for some stylish yet affordable casual shirts for work, pls help', dimension_tuple=DimensionTuple(intent='product_inquiry', complexity='simple', persona='repeat_customer', language_style='formal'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN039', query='Bro, got any lit streetwear styles for summer?! 🔥', dimension_tuple=DimensionTuple(intent='product_inquiry', complexity='simple', persona='repeat_customer', language_style='formal'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN040', query='I need help finding plus size formal dresses for a wedding', dimension_tuple=DimensionTuple(intent='product_inquiry', complexity='simple', persona='repeat_customer', language_style='formal'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN041', query=\"Hey can you show me your summer collection for men's shorts?\", dimension_tuple=DimensionTuple(intent='product_inquiry', complexity='simple', persona='new_customer', language_style='formal'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN042', query='Sup got any cool graphic tees with like skulls or dragons i kinda like that edgy look lol', dimension_tuple=DimensionTuple(intent='product_inquiry', complexity='simple', persona='new_customer', language_style='formal'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN043', query=\"What's the return policy on dresses if it doesn't fit right gotta look fly for date night ya feel me\", dimension_tuple=DimensionTuple(intent='product_inquiry', complexity='simple', persona='new_customer', language_style='formal'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN044', query='Yo what styles of jeans are trendin right now?', dimension_tuple=DimensionTuple(intent='product_inquiry', complexity='simple', persona='new_customer', language_style='formal'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN045', query=\"Lemme peep the new arrivals for women's tops ima get something cute for the wifey\", dimension_tuple=DimensionTuple(intent='product_inquiry', complexity='simple', persona='new_customer', language_style='formal'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN046', query='Whatchu got for big and tall button up shirts my guy needs something fresh for his job interview', dimension_tuple=DimensionTuple(intent='product_inquiry', complexity='simple', persona='new_customer', language_style='formal'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN047', query=\"Ey can I get some style tips my homeboy wants to dress more street but he's kinda preppy right now ya dig?\", dimension_tuple=DimensionTuple(intent='product_inquiry', complexity='simple', persona='new_customer', language_style='formal'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN048', query='Aight what shoes you got that go with like khakis and a polo my dude goin golfing this weekend lmao', dimension_tuple=DimensionTuple(intent='product_inquiry', complexity='simple', persona='new_customer', language_style='formal'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN049', query='Aye recommend some dope outfits for date night tryna impress this new shorty I been talking to you know what I mean', dimension_tuple=DimensionTuple(intent='product_inquiry', complexity='simple', persona='new_customer', language_style='formal'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN050', query=\"I'm looking for a comfy jumpsuit in a size medium. what do u recommend?\", dimension_tuple=DimensionTuple(intent='technical_support', complexity='multi-turn', persona='frustrated_customer', language_style='informal'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN051', query='any good deals on shoes for summer? preferably sandals or flip flops', dimension_tuple=DimensionTuple(intent='technical_support', complexity='multi-turn', persona='frustrated_customer', language_style='informal'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN052', query='hey can u show me some cute tops for going out. tanks or crop tops would b perfect', dimension_tuple=DimensionTuple(intent='technical_support', complexity='multi-turn', persona='frustrated_customer', language_style='informal'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN053', query='i need new workout leggings, what r ur most compressive but breathable ones?', dimension_tuple=DimensionTuple(intent='technical_support', complexity='multi-turn', persona='frustrated_customer', language_style='informal'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN054', query='hi i want sumthing cute 2 wear 2 a music festival this weekend. any boho maxi dresses or rompers?', dimension_tuple=DimensionTuple(intent='technical_support', complexity='multi-turn', persona='frustrated_customer', language_style='informal'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN055', query='I need help finding a cute dress for a wedding. Something flowy and boho, you know?', dimension_tuple=DimensionTuple(intent='return_request', complexity='multi-turn', persona='repeat_customer', language_style='informal'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN056', query=\"Looking for a gift for my husband's birthday. He loves button down shirts but I'm not sure what size or style to get\", dimension_tuple=DimensionTuple(intent='return_request', complexity='multi-turn', persona='repeat_customer', language_style='informal'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN057', query='Hey! Browsing for some new leggings to wear to yoga. Would love recs on your most popular solid color or printed pairs', dimension_tuple=DimensionTuple(intent='return_request', complexity='multi-turn', persona='repeat_customer', language_style='informal'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN058', query=\"So I ordered these awesome boyfriend jeans but they're too tight in the waist. Can I exchange for a bigger size?\", dimension_tuple=DimensionTuple(intent='return_request', complexity='multi-turn', persona='repeat_customer', language_style='informal'), is_realistic_and_kept=1, notes_for_filtering=''),\n",
       " QueryWithDimensions(id='SYN059', query=\"Just a quick q - what's the difference between your regular and premium denim? Worth splurging for the premium?\", dimension_tuple=DimensionTuple(intent='return_request', complexity='multi-turn', persona='repeat_customer', language_style='informal'), is_realistic_and_kept=1, notes_for_filtering='')]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91fbb68-7eb9-4aff-b2df-d2f8ee758e0c",
   "metadata": {},
   "source": [
    "## Save Queries to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c38c249c-22c3-49d2-8751-1b597bbb2ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 59 queries to bootstrap_data/synthetic_queries_for_analysis.csv\n"
     ]
    }
   ],
   "source": [
    "def save_queries_to_csv(queries: List[QueryWithDimensions]):\n",
    "    \"\"\"Save generated queries to CSV using pandas.\"\"\"\n",
    "    import pandas as pd\n",
    "    if not queries:\n",
    "        print(\"No queries to save.\")\n",
    "        return\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame([\n",
    "        {\n",
    "            'id': q.id,\n",
    "            'query': q.query,\n",
    "            'dimension_tuple_json': q.dimension_tuple.model_dump_json(),\n",
    "            'is_realistic_and_kept': q.is_realistic_and_kept,\n",
    "            'notes_for_filtering': q.notes_for_filtering\n",
    "        }\n",
    "        for q in queries\n",
    "    ])\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(OUTPUT_CSV_PATH, index=False)\n",
    "    print(f\"Saved {len(queries)} queries to {OUTPUT_CSV_PATH}\")\n",
    "\n",
    "save_queries_to_csv(queries=queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0ad0c4-354a-4c57-acbe-bf73d4975d7a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Next Steps (Beyond This Workshop)\n",
    "\n",
    "After completing this workshop, you would typically:\n",
    "\n",
    "1. **Manual Curation**: Review and filter the generated queries\n",
    "2. **SME Review**: Have domain experts validate the realistic scenarios\n",
    "3. **Dataset Expansion**: Generate additional queries to reach your target size (~100)\n",
    "4. **Quality Scoring**: Add human ratings for query realism and difficulty\n",
    "5. **Response Generation**: Use your customer support system to generate responses\n",
    "6. **Evaluation Setup**: Create scoring functions to evaluate response \n",
    "\n",
    "\n",
    "# Key Takeaways\n",
    "\n",
    "1. **Systematic > Ad-hoc**: Structured dimension-based generation produces better data than simple prompting\n",
    "2. **Dimensions Matter**: Choose dimensions based on where your system is likely to fail\n",
    "3. **Parallel Processing**: Use concurrent API calls to speed up generation (with rate limit handling)\n",
    "4. **Quality Control**: Always include human review in your synthetic data pipeline\n",
    "5. **Iterative Improvement**: Refine your dimensions and prompts based on output quality\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4acb9d-e246-42c9-9b0b-dbf2497f95e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytoch_3_12_5",
   "language": "python",
   "name": "conda_pytoch_3_12_5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
