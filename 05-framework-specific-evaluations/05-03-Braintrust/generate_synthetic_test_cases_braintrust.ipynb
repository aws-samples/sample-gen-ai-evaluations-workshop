{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26059313-4e61-46a5-b9b4-9ede333453e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: braintrust in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (0.2.4)\n",
      "Requirement already satisfied: autoevals in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (0.0.129)\n",
      "Requirement already satisfied: pydantic in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (2.11.7)\n",
      "Requirement already satisfied: GitPython in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from braintrust) (3.1.45)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from braintrust) (2.32.5)\n",
      "Requirement already satisfied: chevron in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from braintrust) (0.14.0)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from braintrust) (4.67.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.2.0 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from braintrust) (1.2.2)\n",
      "Requirement already satisfied: python-dotenv in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from braintrust) (1.1.1)\n",
      "Requirement already satisfied: sseclient-py in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from braintrust) (1.8.0)\n",
      "Requirement already satisfied: python-slugify in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from braintrust) (8.0.4)\n",
      "Requirement already satisfied: typing_extensions>=4.1.0 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from braintrust) (4.14.1)\n",
      "Requirement already satisfied: polyleven in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from autoevals) (0.9.0)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from autoevals) (6.0.2)\n",
      "Requirement already satisfied: braintrust_core==0.0.59 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from autoevals) (0.0.59)\n",
      "Requirement already satisfied: jsonschema in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from autoevals) (4.25.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from pydantic) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from pydantic) (0.4.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from GitPython->braintrust) (4.0.12)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from jsonschema->autoevals) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from jsonschema->autoevals) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from jsonschema->autoevals) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from jsonschema->autoevals) (0.27.0)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from python-slugify->braintrust) (1.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from requests->braintrust) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from requests->braintrust) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from requests->braintrust) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from requests->braintrust) (2025.8.3)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/ec2-user/anaconda3/envs/pytoch_3_12_5/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->GitPython->braintrust) (5.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install braintrust autoevals pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c8316a-d583-4e57-814c-78029e06d2cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f86e263-dccd-44cc-a9be-b93e52aa2960",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import braintrust as bt\n",
    "from braintrust import wrap_litellm\n",
    "from litellm import completion\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional, Dict, Any\n",
    "from datetime import datetime\n",
    "import json\n",
    "load_dotenv(override=True)\n",
    "MODEL_NAME=\"bedrock/anthropic.claude-3-sonnet-20240229-v1:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38d3ec80-bad9-4442-bfb7-5323f131265f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BT_PROJECT_NAME = \"customer-service-agent-eval\"\n",
    "MAX_WORKERS = 5\n",
    "\n",
    "bt_project = bt.projects.create(name=BT_PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcff42da-3cba-4fc4-93b4-2dc8677fdaa0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Understanding the Problem\n",
    "\n",
    "## Instructions:\n",
    "1. **Read the objective carefully**: We need ~100 diverse, realistic customer support requests\n",
    "2. **Key insight**: \"Naively generated queries tend to be generic, repetitive, and fail to capture real usage patterns\"\n",
    "3. **Solution**: Use a systematic approach with defined dimensions\n",
    "\n",
    "## Workshop Discussion Points:\n",
    "- Why is synthetic data important when real data isn't available?\n",
    "- What makes a query \"realistic\" vs \"generic\"?\n",
    "- How can we ensure diversity in our generated data?\n",
    "\n",
    "# Define Evaluation Dimensions\n",
    "\n",
    "A dimension is a way to categorize different parts of a user query. Each dimension represents ONE axis of variation. In our example customer service chatbot.\n",
    "\n",
    "Feature: What task or enquiry the user wants to perform e.g order cancelation\n",
    "Persona: What type of client e.g first time buyer, existing buyer\n",
    "scenario: How clear is the intent specified from the user e.g concise or verbose\n",
    "\n",
    "## Instructions:\n",
    "1. **Study each dimension carefully**:\n",
    "   - **Intent**: What the user wants to accomplish\n",
    "   - **Complexity**: How difficult the query is to handle\n",
    "   - **Persona**: What type of user is making the request\n",
    "   - **Language Style**: How the user communicates\n",
    "\n",
    "2. **Critical principle**: \"Choose dimensions that describe where the AI application is likely to fail\"\n",
    "\n",
    "3. **Review the Pydantic models**: Notice how we structure our data for validation\n",
    "\n",
    "## Workshop Activity:\n",
    "What other dimensions might be relevant for your specific use case?\n",
    "\n",
    "# Dimension Tuple Generation Function\n",
    "\n",
    "## Instructions:\n",
    "1. **Examine the prompt structure**: Notice how we:\n",
    "   - Provide clear instructions for balanced coverage\n",
    "   - Include realistic constraints (e.g., new customers rarely have returns)\n",
    "   - Request specific numbers of combinations\n",
    "\n",
    "2. **Understand the parallel processing**: We make multiple calls and deduplicate results\n",
    "\n",
    "3. **Run this cell**: It defines the function but doesn't execute it yet\n",
    "\n",
    "## Key Concept:\n",
    "Good prompt engineering includes constraints and examples to guide the LLM toward realistic outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ffacc38-b649-47b4-81f9-35b7f9cea728",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Define Pydantic Models for structured Output\n",
    "\n",
    "class DimensionTuple(BaseModel):\n",
    "    intent: str = Field(\n",
    "        description=\"The user's primary goal or task (e.g., product_inquiry, order_status_check, return_request, technical_support, account_management, general_info).\"\n",
    "    )\n",
    "    complexity: str = Field(\n",
    "        description=\"The difficulty and structure of the query (e.g., simple, multi-turn, ambiguous).\"\n",
    "    )\n",
    "    persona: str = Field(\n",
    "        description=\"The type of user based on their behavior or relationship with the store (e.g., new_customer, repeat_customer, frustrated_customer, loyalty_member).\"\n",
    "    )\n",
    "    language_style: str = Field(\n",
    "        description=\"Linguistic characteristics of the query (e.g., formal, informal, contains_slang, includes_typos, verbose, concise).\"\n",
    "    )\n",
    "\n",
    "class DimensionTuples(BaseModel):\n",
    "    tuples: List[DimensionTuple]\n",
    "\n",
    "class DimensionTuplesList(BaseModel):\n",
    "    tuples: List[DimensionTuple]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c30dedae-3335-4e87-b802-974bc4a69e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "TUPLES_GEN_PROMPT=\"\"\"\\\n",
    "        I am designing a customer support chatbot for a retail company and need to generate a diverse set of synthetic test data to evaluate its performance. I've provided you with the key dimensions that make up a customer's inquiry, along with a list of possible values for each.\n",
    "        \n",
    "        ## Instructions\n",
    "        \n",
    "        Generate {{{num_tuples_to_generate}}} unique combinations of dimension values based on the dimensions provided below.\n",
    "        \n",
    "        * Each combination should represent a distinct customer support scenario.\n",
    "        * Ensure **balanced coverage** across all dimensions; avoid over-representing any single value or combination.\n",
    "        * The generated tuples should be as realistic and varied as possible. For example, a frustrated customer is likely to use informal language and ask a complex question about a return.\n",
    "        * Never generate a tuple where the persona is 'new_customer' and the intent is 'return_request' or 'order_status_check' unless the complexity is multi-turn to simulate a scenario where they are new to this process.\n",
    "        \n",
    "        ## Dimensions\n",
    "        \n",
    "        * **intent**: What kind of inquiry are they making?\n",
    "            * product_inquiry\n",
    "            * order_status_check\n",
    "            * request_for_action_or_service\n",
    "            * return_request\n",
    "            * cancel_order\n",
    "            * technical_support\n",
    "            * account_management\n",
    "            * general_info\n",
    "        * **complexity**: The difficulty and structure of the query.\n",
    "            * simple\n",
    "            * multi-turn\n",
    "            * ambiguous\n",
    "        * **persona**: The type of user making the request\n",
    "            * new_customer\n",
    "            * repeat_customer\n",
    "            * frustrated_customer\n",
    "            * loyalty_member\n",
    "        * **language_style**: The linguistic characteristics of the query\n",
    "            * formal\n",
    "            * informal\n",
    "            * contains_slang\n",
    "            * includes_typos\n",
    "        \n",
    "        Generate {{{num_tuples_to_generate}}} unique dimension tuples.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6415a394-2034-49ef-b824-a24061c12fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_tuples_prompt():\n",
    "    try:\n",
    "        # Try to load existing prompt\n",
    "        prompt = bt.load_prompt(project=BT_PROJECT_NAME, slug=\"dimension-tuples-gen-prompt\")\n",
    "        # Validate it works\n",
    "        prompt.build(num_tuples_to_generate=20)\n",
    "        return prompt\n",
    "    except Exception:\n",
    "        # Create new prompt if loading/building fails\n",
    "        bt_project.prompts.create(\n",
    "            name=\"DimensionTuplesGenPrompt\",\n",
    "            slug=\"dimension-tuples-gen-prompt\", \n",
    "            description=\"Prompt for generating dimension tuples\",\n",
    "            model=\"claude-4-sonnet-20250514\",\n",
    "            messages=[{\"role\": \"user\", \"content\": TUPLES_GEN_PROMPT}],\n",
    "            if_exists=\"replace\",\n",
    "        )\n",
    "        bt_project.publish()\n",
    "        return bt.load_prompt(project=BT_PROJECT_NAME, slug=\"dimension-tuples-gen-prompt\")\n",
    "\n",
    "tuples_gen_prompt = get_or_create_tuples_prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a7780d8-f634-4866-ba51-11c09aa148c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch existing prompts\n",
    "tuples_gen_prompt = bt.load_prompt(project=BT_PROJECT_NAME, slug=\"dimension-tuples-gen-prompt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2e22c5d-9c5f-4319-ae43-2bfa42aeadc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<braintrust.logger.Prompt at 0x7ffb89e2a450>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuples_gen_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02acf1f0-6aed-4e44-b863-872dcf3c6e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': \"        I am designing a customer support chatbot for a retail company and need to generate a diverse set of synthetic test data to evaluate its performance. I've provided you with the key dimensions that make up a customer's inquiry, along with a list of possible values for each.\\n        \\n        ## Instructions\\n        \\n        Generate 20 unique combinations of dimension values based on the dimensions provided below.\\n        \\n        * Each combination should represent a distinct customer support scenario.\\n        * Ensure **balanced coverage** across all dimensions; avoid over-representing any single value or combination.\\n        * The generated tuples should be as realistic and varied as possible. For example, a frustrated customer is likely to use informal language and ask a complex question about a return.\\n        * Never generate a tuple where the persona is 'new_customer' and the intent is 'return_request' or 'order_status_check' unless the complexity is multi-turn to simulate a scenario where they are new to this process.\\n        \\n        ## Dimensions\\n        \\n        * **intent**: What kind of inquiry are they making?\\n            * product_inquiry\\n            * order_status_check\\n            * request_for_action_or_service\\n            * return_request\\n            * cancel_order\\n            * technical_support\\n            * account_management\\n            * general_info\\n        * **complexity**: The difficulty and structure of the query.\\n            * simple\\n            * multi-turn\\n            * ambiguous\\n        * **persona**: The type of user making the request\\n            * new_customer\\n            * repeat_customer\\n            * frustrated_customer\\n            * loyalty_member\\n        * **language_style**: The linguistic characteristics of the query\\n            * formal\\n            * informal\\n            * contains_slang\\n            * includes_typos\\n        \\n        Generate 20 unique dimension tuples.\\n    \", 'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "_p = tuples_gen_prompt.build(num_tuples_to_generate=20)\n",
    "print(_p[\"messages\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283d3775-a1e4-435b-8dda-8770f10a1c68",
   "metadata": {},
   "source": [
    "![title](images/braintrust_playgrounds.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdb6d2a-ceba-40bd-8307-c6ef90b7f4a6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Generate Dimension Combinations\n",
    "\n",
    "## Instructions:\n",
    "1. **Execute this cell**: It will generate diverse dimension combinations\n",
    "2. **Watch the output**: You should see parallel generation happening\n",
    "3. **Review the results**: Examine the generated tuples for:\n",
    "   - Realistic combinations\n",
    "   - Balanced coverage across dimensions\n",
    "   - Absence of impossible scenarios\n",
    "\n",
    "## Expected Output:\n",
    "- \"Generated X total tuples, Y unique\"\n",
    "- A list of DimensionTuple objects with varied combinations\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9237d302-1aff-4df0-a188-e94b8b973856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synth_data_dimension_tuples(num_tuples: int = 20, model_kwargs: dict = {}):\n",
    "    \"\"\"Generate a list of dimension tuples based on the provided prompt.\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "    prompt = tuples_gen_prompt.build(num_tuples_to_generate=num_tuples)\n",
    "    rsp = completion(\n",
    "        model=\"bedrock/anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "        messages=prompt[\"messages\"],\n",
    "        response_format=DimensionTuples,\n",
    "        **model_kwargs,\n",
    "    )\n",
    "    \n",
    "    # Parse JSON content and validate with Pydantic\n",
    "    content = rsp.choices[0].message.content\n",
    "    tuples_dict = json.loads(content)\n",
    "    tuples_list: DimensionTuples = DimensionTuples(**tuples_dict)\n",
    "    \n",
    "    unique_tuples = []\n",
    "    seen = set()\n",
    "    \n",
    "    for tup in tuples_list.tuples:\n",
    "        tuple_str = tup.model_dump_json()\n",
    "        if tuple_str in seen:\n",
    "            continue\n",
    "        seen.add(tuple_str)\n",
    "        unique_tuples.append(tup)\n",
    "    \n",
    "    bt_experiment = bt.init(project=BT_PROJECT_NAME, experiment=f\"synth_tuples_it_{timestamp}\")\n",
    "    for uniq_tup in unique_tuples:\n",
    "        with bt_experiment.start_span(name=\"generate_dimension_tuples\") as span:\n",
    "            span.log(input=prompt[\"messages\"], output=uniq_tup, metadata=dict(model_kwargs=model_kwargs))\n",
    "    \n",
    "    summary = bt_experiment.summarize(summarize_scores=False)\n",
    "    return summary, tuples_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d19c964-b4c9-4f29-825c-0df6cdaca21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_data=generate_synth_data_dimension_tuples(num_tuples=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39701754-6282-4dc8-bf0e-97f9653b559f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ExperimentSummary(project_name='customer-service-agent-eval', project_id='8a70e092-c540-4db6-bb9d-2fa3da5d1e2e', experiment_id='99ba88b1-58d5-4c8f-848e-1d899253bb29', experiment_name='synth_tuples_it_20250906_1933', project_url='https://www.braintrust.dev/app/aiopsdream/p/customer-service-agent-eval', experiment_url='https://www.braintrust.dev/app/aiopsdream/p/customer-service-agent-eval/experiments/synth_tuples_it_20250906_1933', comparison_experiment_name=None, scores={}, metrics={}),\n",
       " DimensionTuples(tuples=[DimensionTuple(intent='product_inquiry', complexity='simple', persona='new_customer', language_style='formal'), DimensionTuple(intent='order_status_check', complexity='multi-turn', persona='repeat_customer', language_style='informal'), DimensionTuple(intent='return_request', complexity='ambiguous', persona='frustrated_customer', language_style='contains_slang'), DimensionTuple(intent='technical_support', complexity='simple', persona='loyalty_member', language_style='formal'), DimensionTuple(intent='account_management', complexity='multi-turn', persona='repeat_customer', language_style='includes_typos'), DimensionTuple(intent='general_info', complexity='simple', persona='new_customer', language_style='informal'), DimensionTuple(intent='cancel_order', complexity='ambiguous', persona='frustrated_customer', language_style='contains_slang'), DimensionTuple(intent='request_for_action_or_service', complexity='multi-turn', persona='loyalty_member', language_style='formal'), DimensionTuple(intent='product_inquiry', complexity='ambiguous', persona='repeat_customer', language_style='informal'), DimensionTuple(intent='order_status_check', complexity='multi-turn', persona='new_customer', language_style='formal'), DimensionTuple(intent='return_request', complexity='simple', persona='repeat_customer', language_style='includes_typos'), DimensionTuple(intent='technical_support', complexity='ambiguous', persona='frustrated_customer', language_style='contains_slang'), DimensionTuple(intent='account_management', complexity='simple', persona='loyalty_member', language_style='formal'), DimensionTuple(intent='general_info', complexity='multi-turn', persona='repeat_customer', language_style='informal'), DimensionTuple(intent='cancel_order', complexity='simple', persona='new_customer', language_style='formal'), DimensionTuple(intent='request_for_action_or_service', complexity='ambiguous', persona='frustrated_customer', language_style='contains_slang'), DimensionTuple(intent='product_inquiry', complexity='multi-turn', persona='loyalty_member', language_style='includes_typos'), DimensionTuple(intent='order_status_check', complexity='simple', persona='repeat_customer', language_style='formal'), DimensionTuple(intent='return_request', complexity='multi-turn', persona='loyalty_member', language_style='informal'), DimensionTuple(intent='technical_support', complexity='simple', persona='new_customer', language_style='formal')]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b077f0dc-336d-4608-a66b-54dd165312ea",
   "metadata": {},
   "source": [
    "### Configuring Human Review\n",
    "To set up human review, define the scores you want to collect in your project's Configuration tab. In our example the score name is \"dimension_human_review\"\n",
    "\n",
    "![title](images/create_human_review.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa00c605-ee4d-4ed5-a9ac-8699bec0539f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Review Generated Tuples\n",
    "\n",
    "## Instructions:\n",
    "1. **Examine the output**: Look at the variety of combinations generated\n",
    "2. **Quality check**: Verify that combinations make sense (e.g., frustrated customers with complex queries)\n",
    " 3. **Note the balance**: See how different dimensions are represented\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92832793-ee46-42e5-9e49-b2eee9a82173",
   "metadata": {},
   "source": [
    "![title](images/dimension_human_review.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b333b6f-92e5-481c-9c93-f4e3c357ebb1",
   "metadata": {},
   "source": [
    "## Workshop Discussion:\n",
    "- Which combinations seem most realistic?\n",
    "- Are there any combinations that seem problematic?\n",
    "- How does this compare to manually brainstorming scenarios?\n",
    "\n",
    "## Key Takeaways\n",
    "- We use braintrust.init to manually create a new experiment.\n",
    "- Remove invalid dimensions with human review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff175a6d-52bd-44a4-99b0-33e28a84e988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-acUtIyX6RQDIQHPHpWJl86cYPnEVVtDHJ519oQ8c1qLqO2AA\n"
     ]
    }
   ],
   "source": [
    "print(os.getenv('BRAINTRUST_API_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355cfe7d-52ed-406e-a73a-57b3fb5d5f13",
   "metadata": {},
   "source": [
    "### Using BTQL we select high quality dimension queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1fe41775-962b-4f2b-8d17-165bf9035d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'complexity': 'simple',\n",
       "  'intent': 'technical_support',\n",
       "  'language_style': 'formal',\n",
       "  'persona': 'new_customer'},\n",
       " {'complexity': 'multi-turn',\n",
       "  'intent': 'return_request',\n",
       "  'language_style': 'informal',\n",
       "  'persona': 'loyalty_member'}]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from textwrap import dedent\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "def get_valid_dimension_tuples():\n",
    "    # Configuration variables\n",
    "    experiment_id = \"99ba88b1-58d5-4c8f-848e-1d899253bb29\" ###Get this id from the expreridents console \n",
    "    bearer_token = os.getenv('BRAINTRUST_API_KEY')\n",
    "    \n",
    "    cursor = None\n",
    "    while True:\n",
    "        url = \"https://api.braintrust.dev/btql\"\n",
    "        payload = json.dumps({\n",
    "          \"query\": f\"select: * | from: experiment('{experiment_id}') filter: scores.\\\"dimension_human_review\\\" = 1\"\n",
    "            })\n",
    "        headers = {\n",
    "          'Authorization': f'Bearer {bearer_token}',\n",
    "          'Content-Type': 'application/json'}\n",
    "        response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "        response.raise_for_status()\n",
    "        response_json = response.json()\n",
    "        data = response_json.get(\"data\", [])\n",
    "        cursor = response_json.get(\"cursor\")\n",
    "        return [row[\"output\"] for row in data]\n",
    "\n",
    "valid_dim_tuples = get_valid_dimension_tuples()\n",
    "print(len(valid_dim_tuples))\n",
    "valid_dim_tuples[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2123c02-bbae-4d13-a0a4-98c79e266e0a",
   "metadata": {},
   "source": [
    "# Query Generation Functions\n",
    "\n",
    "## Instructions:\n",
    "1. **Study the prompt template**: Notice how we:\n",
    "   - Inject the dimension tuple into the prompt\n",
    "   - Provide specific formatting instructions\n",
    "   - Include examples of realistic variations\n",
    "   - Request natural, conversational language\n",
    "\n",
    "2. **Understand the parallel processing setup**: We'll generate multiple queries per tuple simultaneously\n",
    "\n",
    "3. **Run this cell below**: This defines the functions but doesn't execute generation yet\n",
    "\n",
    "## Key Concept:\n",
    "Converting structured dimensions to natural language requires careful prompt engineering with examples and constraints.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7d2d0464-cf3e-4943-9cbb-f788bf59a199",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYNTH_DATA_GEN_PROMPT=\"\"\"\\\n",
    "You are an AI assistant tasked with generating natural language queries for an online apparel retailer chatbot. Your goal is to create realistic, varied queries that match specific characteristics. Here's what you need to do:\n",
    "\n",
    "First, here is the dimension tuple that defines the characteristics for this set of queries:\n",
    "<dimension_json>\n",
    "{{{dimension_tuple_json}}}\n",
    "</dimension_json>\n",
    "        \n",
    "Follow these instructions to generate the queries:\n",
    "        \n",
    "1. Generate exactly {{{num_of_unique_queries_per_dimension}}} unique queries that perfectly match the specified dimensions in the dimension tuple.        \n",
    "2. Focus on realism: The queries should sound like something a real person would type into a chatbot. They should be natural and conversational.        \n",
    "3. Incorporate all dimensions: The language and content of each query must naturally reflect all five dimensions (intent, complexity, persona, language_style, and failure_scenario) as specified in the dimension tuple.        \n",
    "4. Vary the style: Within the specified 'language_style', introduce natural variations such as:\n",
    "           - Common misspellings\n",
    "           - Missing punctuation\n",
    "           - Different capitalization\n",
    "           - Use of emojis\n",
    "           - Text-speak (e.g., 'thx', 'pls', 'gonna')\n",
    "        \n",
    "5. Be concise and direct: Each query should be to the point and reflect how a real user would interact with a chatbot.\n",
    "        \n",
    "Here are some examples of realistic variations to guide you:\n",
    "    - For a \"Frustrated Customer\" with \"Technical Support\" intent and \"Incomplete Info\" scenario:\n",
    "          \"my discount code aint working its stupid\"\n",
    "          \"why is the site crashing\"\n",
    "          \"i need help with the cart but its broken\"\n",
    "        \n",
    "    - For a \"New Customer\" with \"Product Inquiry\" intent, \"Simple\" complexity, and \"Formal\" language style:\n",
    "          \"Could you please tell me about the sizing for the women's jackets?\"\n",
    "          \"Hello, I have a question regarding the material of the new shirt.\"\n",
    "        \n",
    "        \n",
    "Generate {{{num_queries_to_generate}}} unique queries,varying the text style naturally.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e4480a2a-6dcd-4bb3-80a9-715d9776cb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an AI assistant tasked with generating natural language queries for an online apparel retailer chatbot. Your goal is to create realistic, varied queries that match specific characteristics. Here's what you need to do:\n",
      "\n",
      "First, here is the dimension tuple that defines the characteristics for this set of queries:\n",
      "<dimension_json>\n",
      "[\n",
      "  {\n",
      "    \"complexity\": \"simple\",\n",
      "    \"intent\": \"technical_support\",\n",
      "    \"language_style\": \"formal\",\n",
      "    \"persona\": \"new_customer\"\n",
      "  },\n",
      "  {\n",
      "    \"complexity\": \"multi-turn\",\n",
      "    \"intent\": \"return_request\",\n",
      "    \"language_style\": \"informal\",\n",
      "    \"persona\": \"loyalty_member\"\n",
      "  },\n",
      "  {\n",
      "    \"complexity\": \"simple\",\n",
      "    \"intent\": \"order_status_check\",\n",
      "    \"language_style\": \"formal\",\n",
      "    \"persona\": \"repeat_customer\"\n",
      "  },\n",
      "  {\n",
      "    \"complexity\": \"multi-turn\",\n",
      "    \"intent\": \"product_inquiry\",\n",
      "    \"language_style\": \"includes_typos\",\n",
      "    \"persona\": \"loyalty_member\"\n",
      "  }\n",
      "]\n",
      "</dimension_json>\n",
      "        \n",
      "Follow these instructions to generate the queries:\n",
      "        \n",
      "1. Generate exactly 2 unique queries that perfectly match the specified dimensions in the dimension tuple.        \n",
      "2. Focus on realism: The queries should sound like something a real person would type into a chatbot. They should be natural and conversational.        \n",
      "3. Incorporate all dimensions: The language and content of each query must naturally reflect all five dimensions (intent, complexity, persona, language_style, and failure_scenario) as specified in the dimension tuple.        \n",
      "4. Vary the style: Within the specified 'language_style', introduce natural variations such as:\n",
      "           - Common misspellings\n",
      "           - Missing punctuation\n",
      "           - Different capitalization\n",
      "           - Use of emojis\n",
      "           - Text-speak (e.g., 'thx', 'pls', 'gonna')\n",
      "        \n",
      "5. Be concise and direct: Each query should be to the point and reflect how a real user would interact with a chatbot.\n",
      "        \n",
      "Here are some examples of realistic variations to guide you:\n",
      "    - For a \"Frustrated Customer\" with \"Technical Support\" intent and \"Incomplete Info\" scenario:\n",
      "          \"my discount code aint working its stupid\"\n",
      "          \"why is the site crashing\"\n",
      "          \"i need help with the cart but its broken\"\n",
      "        \n",
      "    - For a \"New Customer\" with \"Product Inquiry\" intent, \"Simple\" complexity, and \"Formal\" language style:\n",
      "          \"Could you please tell me about the sizing for the women's jackets?\"\n",
      "          \"Hello, I have a question regarding the material of the new shirt.\"\n",
      "        \n",
      "        \n",
      "Generate 4 unique queries,varying the text style naturally.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "     (\n",
    "         SYNTH_DATA_GEN_PROMPT.replace(\"{{{num_queries_to_generate}}}\", \"4\")\n",
    "         .replace(\"{{{dimension_tuple_json}}}\", json.dumps(valid_dim_tuples[:4], indent=2))\n",
    "         .replace(\"{{{num_of_unique_queries_per_dimension}}}\", \"2\")\n",
    "     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "62e23f94-8980-4923-bd86-9654cefb59b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_query_gen_prompt = bt.load_prompt(project=BT_PROJECT_NAME, slug=\"synth-query-gen-prompt\")\n",
    "try:\n",
    "    synth_query_gen_prompt.prompt\n",
    "except Exception as e:\n",
    "    bt_syth_query_gen_prompt = bt_project.prompts.create(\n",
    "        name=\"synthetic_query_prompts\",\n",
    "        slug=\"synth-query-gen-prompt\",\n",
    "        description=\"Prompt for generating synthetic queries\",\n",
    "        model=\"claude-4-sonnet-20250514\",\n",
    "        messages=[{\"role\": \"user\", \"content\": SYNTH_DATA_GEN_PROMPT}],\n",
    "        if_exists=\"replace\",\n",
    "    )\n",
    "\n",
    "    bt_project.publish()\n",
    "    synth_query_gen_prompt = bt.load_prompt(project=BT_PROJECT_NAME, slug=\"synth-query-gen-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8d703839-6f5a-4f6a-b169-cac22efe24ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryList(BaseModel):\n",
    "    queries: list[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8c03ac97-2de6-4a92-a24a-1fb8746184de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synth_queries(num_queries: int = 10, model_kwargs: dict = {}) -> dict:\n",
    "    random_dim_tuples = random.sample(valid_dim_tuples, min(num_queries, len(valid_dim_tuples)))\n",
    "\n",
    "    prompt = synth_query_gen_prompt.build(\n",
    "        num_queries_to_generate=num_queries,\n",
    "        num_of_unique_queries_per_dimension=num_queries*2,\n",
    "        dimension_tuple_json=json.dumps(random_dim_tuples, indent=2),\n",
    "    )\n",
    "\n",
    "    rsp = completion(\n",
    "        model=\"bedrock/anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "        messages=prompt[\"messages\"],\n",
    "        response_format=QueryList,\n",
    "        **model_kwargs,\n",
    "    )\n",
    "\n",
    "    query_string: QueryList = rsp.choices[0].message.content\n",
    "\n",
    "    query_dict = json.loads(query_string)\n",
    "    query_list: QueryList = QueryList(**query_dict)\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"prompt\": prompt[\"messages\"][0]['content'],\n",
    "        \"sampled_dim_tuples\": random_dim_tuples,\n",
    "        \"synth_queries\": query_list.queries\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "84d28f15-1405-4c62-a7c1-8071753af9a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'You are an AI assistant tasked with generating natural language queries for an online apparel retailer chatbot. Your goal is to create realistic, varied queries that match specific characteristics. Here\\'s what you need to do:\\n\\nFirst, here is the dimension tuple that defines the characteristics for this set of queries:\\n<dimension_json>\\n[\\n  {\\n    \"complexity\": \"multi-turn\",\\n    \"intent\": \"return_request\",\\n    \"language_style\": \"informal\",\\n    \"persona\": \"loyalty_member\"\\n  },\\n  {\\n    \"complexity\": \"simple\",\\n    \"intent\": \"cancel_order\",\\n    \"language_style\": \"formal\",\\n    \"persona\": \"new_customer\"\\n  }\\n]\\n</dimension_json>\\n        \\nFollow these instructions to generate the queries:\\n        \\n1. Generate exactly 2 unique queries that perfectly match the specified dimensions in the dimension tuple.        \\n2. Focus on realism: The queries should sound like something a real person would type into a chatbot. They should be natural and conversational.        \\n3. Incorporate all dimensions: The language and content of each query must naturally reflect all five dimensions (intent, complexity, persona, language_style, and failure_scenario) as specified in the dimension tuple.        \\n4. Vary the style: Within the specified \\'language_style\\', introduce natural variations such as:\\n           - Common misspellings\\n           - Missing punctuation\\n           - Different capitalization\\n           - Use of emojis\\n           - Text-speak (e.g., \\'thx\\', \\'pls\\', \\'gonna\\')\\n        \\n5. Be concise and direct: Each query should be to the point and reflect how a real user would interact with a chatbot.\\n        \\nHere are some examples of realistic variations to guide you:\\n    - For a \"Frustrated Customer\" with \"Technical Support\" intent and \"Incomplete Info\" scenario:\\n          \"my discount code aint working its stupid\"\\n          \"why is the site crashing\"\\n          \"i need help with the cart but its broken\"\\n        \\n    - For a \"New Customer\" with \"Product Inquiry\" intent, \"Simple\" complexity, and \"Formal\" language style:\\n          \"Could you please tell me about the sizing for the women\\'s jackets?\"\\n          \"Hello, I have a question regarding the material of the new shirt.\"\\n        \\n        \\nGenerate 2 unique queries,varying the text style naturally.\\n',\n",
       " 'sampled_dim_tuples': [{'complexity': 'multi-turn',\n",
       "   'intent': 'return_request',\n",
       "   'language_style': 'informal',\n",
       "   'persona': 'loyalty_member'},\n",
       "  {'complexity': 'simple',\n",
       "   'intent': 'cancel_order',\n",
       "   'language_style': 'formal',\n",
       "   'persona': 'new_customer'}],\n",
       " 'synth_queries': ['heyy i need to return the pants i got last week they dont fit right, whats the process for that as a rewards member?',\n",
       "  'Good morning, I would like to cancel the order I placed yesterday for a shirt. Could you please provide instructions on how to proceed?']}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_synth_queries(num_queries=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "474de28f-1143-445a-ab15-ef6c0ec90aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(generate_synth_queries(num_queries=2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "bb5d733f-904a-4594-af50-1533a6458912",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add to braintrust\n",
    "\n",
    "def add_to_braintrust_experiment(num_queries: int = 2,):\n",
    "    \"\"\"Add to Braintrust experiments\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "    all_queries = generate_synth_queries(num_queries=num_queries)\n",
    "    bt_experiment = bt.init(project=BT_PROJECT_NAME, experiment=f\"add_queries_it_{timestamp}\")\n",
    "    query_id = 1\n",
    "\n",
    "    for query_item in all_queries[\"synth_queries\"]:\n",
    "        qid = f\"{timestamp}_{query_id:03d}\"\n",
    "        query_id += 1\n",
    "        with bt_experiment.start_span(name=\"add_query\") as span:\n",
    "            span.log(\n",
    "                input=all_queries[\"prompt\"],\n",
    "                output=query_item,\n",
    "                metadata={\n",
    "                    \"id\": qid,\n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "feb5e8ec-5164-453b-b11d-f258c39899f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_to_braintrust_experiment(num_queries=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f45a8f6-2df8-44a1-af88-5b244d28012a",
   "metadata": {},
   "source": [
    "### Remove invalid queries (human/SME review)\n",
    "\n",
    "![title](images/huma_rewiew_queries.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2510a278-cf17-4d08-9f34-dd922529f451",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytoch_3_12_5",
   "language": "python",
   "name": "conda_pytoch_3_12_5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
