{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05-04: AgentCore Runtime Evaluations\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates how to deploy a Strands-based AI agent to **AgentCore Runtime** and evaluate its performance using the native **AgentCore Evaluations** API with built-in evaluators.\n",
    "\n",
    "### What is AgentCore Runtime?\n",
    "\n",
    "**AgentCore Runtime** is an AWS managed service for deploying and running AI agents with built-in observability. It provides:\n",
    "\n",
    "- **Managed Infrastructure**: Deploy agents without managing servers or containers directly\n",
    "- **Built-in Observability**: Automatic logging of agent execution traces to CloudWatch\n",
    "- **Scalable Invocation**: Invoke agents via API with session management\n",
    "- **Easy Deployment**: Use the `bedrock-agentcore-starter-toolkit` for streamlined deployment workflows\n",
    "\n",
    "### What is AgentCore Evaluations?\n",
    "\n",
    "**AgentCore Evaluations** is an AWS service that provides the `evaluate()` API for assessing agent performance using built-in evaluators. Key features include:\n",
    "\n",
    "- **Built-in Evaluators**: Pre-configured evaluators like `Builtin.Helpfulness` and `Builtin.ToolSelectionAccuracy`\n",
    "- **Session Span Analysis**: Evaluate agent behavior based on execution traces from CloudWatch logs\n",
    "- **Objective Scoring**: Get numeric scores, labels, and detailed explanations for each evaluation\n",
    "- **Token Usage Tracking**: Monitor the cost of running evaluations\n",
    "\n",
    "### Why Use AgentCore Runtime + Evaluations?\n",
    "\n",
    "This combination provides an end-to-end workflow for deploying and assessing AI agents:\n",
    "\n",
    "1. **Deploy Once, Evaluate Continuously**: Deploy your agent to a managed runtime and run evaluations against real execution traces\n",
    "2. **Production-Ready Observability**: Leverage CloudWatch integration for comprehensive logging\n",
    "3. **Standardized Evaluation**: Use AWS-provided evaluators for consistent, objective assessment\n",
    "4. **Iterative Improvement**: Use evaluation results to identify areas for agent improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What You'll Learn\n",
    "\n",
    "In this module, you will learn how to:\n",
    "\n",
    "1. **Create a Strands Agent**: Build a city search agent using the `strands-agents` framework with web search capabilities\n",
    "\n",
    "2. **Deploy to AgentCore Runtime**: Use the `bedrock-agentcore-starter-toolkit` to deploy your agent to AWS managed infrastructure\n",
    "\n",
    "3. **Invoke the Deployed Agent**: Call your agent via the `invoke_agent_runtime` API with session management\n",
    "\n",
    "4. **Retrieve Session Spans**: Extract execution traces from CloudWatch logs for evaluation\n",
    "\n",
    "5. **Run AgentCore Evaluations**: Use the `evaluate()` API with built-in evaluators:\n",
    "   - `Builtin.Helpfulness` - Assess response quality and usefulness\n",
    "   - `Builtin.ToolSelectionAccuracy` - Evaluate whether the agent used appropriate tools\n",
    "\n",
    "6. **Analyze Evaluation Results**: Interpret scores, labels, and explanations to understand agent performance\n",
    "\n",
    "7. **Clean Up Resources**: Properly destroy deployed agents to avoid unnecessary AWS charges\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "Before running this notebook, ensure you have:\n",
    "\n",
    "- AWS credentials configured with appropriate permissions for Bedrock, AgentCore, and CloudWatch\n",
    "- Access to Amazon Bedrock foundation models (Nova Micro)\n",
    "- Python 3.9+ environment\n",
    "\n",
    "### Module Workflow\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  1. Create      ‚îÇ     ‚îÇ  2. Deploy to   ‚îÇ     ‚îÇ  3. Invoke      ‚îÇ\n",
    "‚îÇ  Strands Agent  ‚îÇ ‚îÄ‚îÄ‚ñ∂ ‚îÇ  AgentCore      ‚îÇ ‚îÄ‚îÄ‚ñ∂ ‚îÇ  Agent          ‚îÇ\n",
    "‚îÇ                 ‚îÇ     ‚îÇ  Runtime        ‚îÇ     ‚îÇ                 ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                                                        ‚îÇ\n",
    "                                                        ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  6. Analyze     ‚îÇ     ‚îÇ  5. Run         ‚îÇ     ‚îÇ  4. Retrieve    ‚îÇ\n",
    "‚îÇ  Results        ‚îÇ ‚óÄ‚îÄ‚îÄ ‚îÇ  Evaluations    ‚îÇ ‚óÄ‚îÄ‚îÄ ‚îÇ  Session Spans  ‚îÇ\n",
    "‚îÇ                 ‚îÇ     ‚îÇ                 ‚îÇ     ‚îÇ  from CloudWatch‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Dependencies Installation\n",
    "\n",
    "First, we'll install all the required packages for this workshop module. This includes:\n",
    "\n",
    "- **strands-agents** and **strands-agents-tools**: Framework for building AI agents with tool capabilities\n",
    "- **bedrock-agentcore** and **bedrock-agentcore-starter-toolkit**: AWS packages for AgentCore Runtime deployment and Evaluations API\n",
    "- **ddgs**: DuckDuckGo search library for web search functionality\n",
    "- **boto3**: AWS SDK for Python\n",
    "- **pandas**: Data manipulation library for handling test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "# Using -q flag for quiet output to reduce notebook clutter\n",
    "\n",
    "%pip install -q strands-agents strands-agents-tools\n",
    "%pip install -q bedrock-agentcore bedrock-agentcore-starter-toolkit\n",
    "%pip install -q ddgs\n",
    "%pip install -q boto3 pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Strands agents framework\n",
    "from strands import Agent, tool\n",
    "from strands.models.bedrock import BedrockModel\n",
    "\n",
    "# AgentCore packages\n",
    "from bedrock_agentcore.runtime import BedrockAgentCoreApp\n",
    "from bedrock_agentcore_starter_toolkit import Runtime\n",
    "\n",
    "# DuckDuckGo search\n",
    "from ddgs import DDGS\n",
    "\n",
    "# Web page fetching\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# AWS and data handling\n",
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "# Additional standard library imports we'll need\n",
    "import json\n",
    "import uuid\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: City Search Agent Creation\n",
    "\n",
    "In this section, we'll create a city search agent that can answer questions about city populations and areas. The agent uses:\n",
    "\n",
    "- **Web Search Tool**: A custom tool using DuckDuckGo to search for current information\n",
    "- **Get Page Tool**: A tool to fetch and parse web page content for detailed information\n",
    "- **BedrockModel**: Amazon Nova Micro for optimized latency and cost\n",
    "- **System Prompt**: Instructions for the agent to act as a tour guide with structured XML output\n",
    "\n",
    "### Tool Definitions\n",
    "\n",
    "We'll start by defining the `web_search` and `get_page` tools using the `@tool` decorator from Strands. The `web_search` tool queries DuckDuckGo and returns the top 5 search results, while `get_page` fetches and extracts text content from URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool name: web_search\n",
      "Tool description: Search DuckDuckGo for information about a topic.\n",
      "\n",
      "Returns:\n",
      "    String containing top 5 search results with titles, URLs, and snippets\n",
      "\n",
      "Tool name: get_page\n",
      "Tool description: Fetch and return the raw text content from a URL.\n",
      "\n",
      "Returns:\n",
      "    String containing the text content of the web page\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def web_search(topic: str) -> str:\n",
    "    \"\"\"\n",
    "    Search DuckDuckGo for information about a topic.\n",
    "    \n",
    "    Args:\n",
    "        topic: Search query string\n",
    "    \n",
    "    Returns:\n",
    "        String containing top 5 search results with titles, URLs, and snippets\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use DuckDuckGo search to find information\n",
    "        results = DDGS().text(topic, max_results=5)\n",
    "        \n",
    "        if not results:\n",
    "            return \"No search results found\"\n",
    "        \n",
    "        # Format results as a readable string\n",
    "        result_string = \"\"\n",
    "        for i, result in enumerate(results):\n",
    "            title = result.get('title', 'No title')\n",
    "            url = result.get('href', 'No URL')\n",
    "            snippet = result.get('body', 'No description')\n",
    "            result_string += f\"Result {i+1}: {title}\\nURL: {url}\\nSnippet: {snippet}\\n\\n\"\n",
    "        \n",
    "        return result_string\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Search error: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def get_page(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Fetch and return the raw text content from a URL.\n",
    "    \n",
    "    Args:\n",
    "        url: The URL to fetch content from\n",
    "    \n",
    "    Returns:\n",
    "        String containing the text content of the web page\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        bs = BeautifulSoup(response.text, 'html.parser')\n",
    "        return bs.text\n",
    "    except Exception as e:\n",
    "        return f\"Error fetching page: {str(e)}\"\n",
    "\n",
    "# Verify the tools are defined correctly\n",
    "print(f\"Tool name: {web_search.tool_name}\")\n",
    "print(f\"Tool description: {web_search.tool_spec.get('description', 'No description')}\")\n",
    "\n",
    "print(f\"\\nTool name: {get_page.tool_name}\")\n",
    "print(f\"Tool description: {get_page.tool_spec.get('description', 'No description')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Configuration\n",
    "\n",
    "Next, we configure the BedrockModel with Amazon Nova Micro. We choose Nova Micro for this workshop because:\n",
    "\n",
    "- **Optimized Latency**: Nova Micro provides fast response times, ideal for interactive agent workflows\n",
    "- **Cost Efficiency**: Lower cost per token compared to larger models, suitable for evaluation scenarios with multiple invocations\n",
    "- **Sufficient Capability**: Handles city search queries effectively while keeping costs manageable\n",
    "\n",
    "We also configure timeout settings to ensure reliable API calls during evaluation runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botocore.config import Config\n",
    "\n",
    "# Configure timeout settings for Bedrock API calls\n",
    "# These settings ensure reliable operation during evaluation scenarios:\n",
    "# - connect_timeout: Maximum time to establish connection (5 seconds)\n",
    "# - read_timeout: Maximum time to wait for response (60 seconds for agent reasoning)\n",
    "# - retries: Single retry attempt to handle transient failures\n",
    "bedrock_config = Config(\n",
    "    connect_timeout=5,\n",
    "    read_timeout=60,\n",
    "    retries={\"max_attempts\": 1}\n",
    ")\n",
    "\n",
    "# Configure BedrockModel with Amazon Nova Micro\n",
    "# Model choice rationale:\n",
    "# - us.amazon.nova-micro-v1:0 provides optimized latency and cost for agent workflows\n",
    "# - Suitable for city search queries that require web search tool usage\n",
    "# - Cross-region inference prefix (us.) enables automatic region routing\n",
    "model_id = \"us.amazon.nova-micro-v1:0\"\n",
    "\n",
    "city_search_model = BedrockModel(\n",
    "    model_id=model_id,\n",
    "    boto_client_config=bedrock_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Creation with System Prompt\n",
    "\n",
    "Now we create the City Search Agent by combining:\n",
    "\n",
    "1. **System Prompt**: Instructions that define the agent's persona and behavior\n",
    "   - Acts as a helpful tour guide\n",
    "   - Uses tools to retrieve current data\n",
    "   - Outputs structured XML tags for programmatic parsing\n",
    "\n",
    "2. **Tools**: The `web_search` tool for retrieving city information\n",
    "\n",
    "3. **Model**: The BedrockModel configured with Amazon Nova Micro\n",
    "\n",
    "#### XML Output Format\n",
    "\n",
    "The agent is instructed to output responses with specific XML tags:\n",
    "- `<response>`: Human-friendly response with context and fun facts\n",
    "- `<pop>`: Population value (numbers only, no commas)\n",
    "- `<area>`: Area value in square miles (numbers only)\n",
    "\n",
    "This structured output format enables programmatic parsing of the agent's responses for evaluation and downstream processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì City Search Agent created successfully!\n",
      "\n",
      "Agent Configuration:\n",
      "  Model: us.amazon.nova-micro-v1:0\n",
      "  Tools: ['web_search', 'get_page']\n",
      "  System prompt length: 743 characters\n",
      "\n",
      "Expected output format:\n",
      "  <response>Human-friendly response with fun facts</response>\n",
      "  <pop>numeric_population</pop>\n",
      "  <area>numeric_area</area>\n"
     ]
    }
   ],
   "source": [
    "# Define the system prompt for the City Search Agent\n",
    "# This prompt establishes:\n",
    "# 1. Tour guide persona - friendly, informative responses\n",
    "# 2. Tool usage requirement - always use tools for current data\n",
    "# 3. XML output format - structured tags for programmatic parsing\n",
    "\n",
    "system_prompt = '''You are a helpful tour guide. Customers may ask you about the population and size of cities.\n",
    "You should use tools to retrieve all data, to make sure it is as current as possible.\n",
    "Please put your human friendly response in 'response' XML tags, and then follow with your data results in 'pop' and 'area' XML tags, for programatic processing.\n",
    "The values in the 'pop' and 'area' XML tags should only be numbers, no words or commas.\n",
    "You may also include a fun fact about the city in question.\n",
    "For example, your response to \"what is the population and size of Somewhereland?\" might be:\n",
    "<response>Somewhereland is a great place to get a hot dog. It has a population of 3000 people, and is 100 square miles.</response>\n",
    "<pop>3000</pop><area>100</area>\n",
    "'''\n",
    "\n",
    "# Create the City Search Agent\n",
    "# Combining the system prompt, tools, and BedrockModel\n",
    "city_search_agent = Agent(\n",
    "    system_prompt=system_prompt,\n",
    "    tools=[web_search, get_page],\n",
    "    model=city_search_model\n",
    ")\n",
    "\n",
    "print(\"‚úì City Search Agent created successfully!\")\n",
    "print(\"\\nAgent Configuration:\")\n",
    "print(f\"  Model: {model_id}\")\n",
    "print(f\"  Tools: ['web_search', 'get_page']\")\n",
    "print(f\"  System prompt length: {len(system_prompt)} characters\")\n",
    "print(\"\\nExpected output format:\")\n",
    "print(\"  <response>Human-friendly response with fun facts</response>\")\n",
    "print(\"  <pop>numeric_population</pop>\")\n",
    "print(\"  <area>numeric_area</area>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Agent Invocation\n",
    "\n",
    "Before deploying to AgentCore Runtime, let's verify that our agent works correctly by testing it with a sample city query.\n",
    "\n",
    "This test invocation will:\n",
    "1. Send a query asking about Seattle, WA's population and area\n",
    "2. Display the full response from the agent\n",
    "3. Show the XML tags (`<response>`, `<pop>`, `<area>`) in the output\n",
    "\n",
    "A successful test confirms that:\n",
    "- The agent can use the `web_search` tool to retrieve information\n",
    "- The response includes the expected XML tag structure\n",
    "- The model is properly configured and accessible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing City Search Agent...\n",
      "Query: What is the population and area of Seattle, WA?\n",
      "\n",
      "============================================================\n",
      "Agent Response:\n",
      "============================================================\n",
      "\n",
      "<thinking> To provide the population and area of Seattle, WA, I will use the web_search tool to find reliable sources of information. The search query will be \"Seattle WA population and area\". After obtaining the results, I will extract the relevant data from the top sources.</thinking>\n",
      "\n",
      "Tool #1: web_search\n",
      "<response>Seattle, WA is a vibrant city with a lot to offer. As of the most recent data from 2020, the population of Seattle is 740,600. The city covers an area of approximately 217 square miles. It's interesting to note that Seattle is known for its coffee culture, and it's the birthplace of Starbucks!</response>\n",
      "<pop>740600</pop><area>217</area><response>Seattle, WA is a vibrant city with a lot to offer. As of the most recent data from 2020, the population of Seattle is 740,600. The city covers an area of approximately 217 square miles. It's interesting to note that Seattle is known for its coffee culture, and it's the birthplace of Starbucks!</response>\n",
      "<pop>740600</pop><area>217</area>\n",
      "\n",
      "\n",
      "============================================================\n",
      "Test Complete!\n",
      "============================================================\n",
      "\n",
      "XML Tag Verification:\n",
      "  ‚úì <response> tag found\n",
      "  ‚úì <pop> tag found\n",
      "  ‚úì <area> tag found\n",
      "\n",
      "‚úì Agent test passed! All expected XML tags are present.\n"
     ]
    }
   ],
   "source": [
    "# Test the City Search Agent with a sample query\n",
    "# This verifies the agent works correctly before deployment to AgentCore Runtime\n",
    "\n",
    "# Sample query about Seattle, WA\n",
    "test_query = \"What is the population and area of Seattle, WA?\"\n",
    "\n",
    "print(\"Testing City Search Agent...\")\n",
    "print(f\"Query: {test_query}\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Agent Response:\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Invoke the agent with the test query\n",
    "test_response = city_search_agent(test_query)\n",
    "\n",
    "# Display the full response\n",
    "print(test_response)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Test Complete!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Verify XML tags are present in the response\n",
    "response_str = str(test_response)\n",
    "xml_tags_present = {\n",
    "    \"<response>\": \"<response>\" in response_str,\n",
    "    \"<pop>\": \"<pop>\" in response_str,\n",
    "    \"<area>\": \"<area>\" in response_str\n",
    "}\n",
    "\n",
    "print(\"\\nXML Tag Verification:\")\n",
    "for tag, present in xml_tags_present.items():\n",
    "    status = \"‚úì\" if present else \"‚úó\"\n",
    "    print(f\"  {status} {tag} tag {'found' if present else 'NOT found'}\")\n",
    "\n",
    "if all(xml_tags_present.values()):\n",
    "    print(\"\\n‚úì Agent test passed! All expected XML tags are present.\")\n",
    "else:\n",
    "    print(\"\\n‚ö† Warning: Some expected XML tags are missing from the response.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: AgentCore Runtime Deployment\n",
    "\n",
    "Now that we've verified our City Search Agent works correctly, we'll deploy it to **AgentCore Runtime**. This deployment process involves:\n",
    "\n",
    "1. **Create Agent File**: Write a Python file (`citysearch.py`) that wraps our agent with `BedrockAgentCoreApp` integration\n",
    "2. **Configure Deployment**: Use the `bedrock-agentcore-starter-toolkit` to set up deployment configuration\n",
    "3. **Launch to Runtime**: Deploy the containerized agent to AgentCore Runtime\n",
    "4. **Verify Deployment**: Confirm the agent is ready and test invocation via the API\n",
    "\n",
    "### Why Deploy to AgentCore Runtime?\n",
    "\n",
    "Deploying to AgentCore Runtime provides several benefits:\n",
    "\n",
    "- **Managed Infrastructure**: No need to manage servers, containers, or scaling\n",
    "- **Built-in Observability**: Automatic logging of all agent interactions to CloudWatch\n",
    "- **Session Management**: Track conversations across multiple invocations\n",
    "- **Evaluation Integration**: Session spans can be used directly with AgentCore Evaluations API\n",
    "\n",
    "### Agent File Structure\n",
    "\n",
    "The `citysearch.py` file follows the AgentCore Runtime pattern:\n",
    "\n",
    "```python\n",
    "from bedrock_agentcore.runtime import BedrockAgentCoreApp\n",
    "\n",
    "app = BedrockAgentCoreApp()\n",
    "\n",
    "@app.entrypoint\n",
    "def invoke(payload):\n",
    "    # Process the request and return response\n",
    "    pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()\n",
    "```\n",
    "\n",
    "This pattern enables AgentCore Runtime to:\n",
    "- Receive incoming requests via the `invoke` function\n",
    "- Automatically instrument the agent for observability\n",
    "- Manage the agent lifecycle in a containerized environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./citysearch.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./citysearch.py\n",
    "# City Search Agent for AgentCore Runtime Deployment\n",
    "# This file creates a deployable agent using BedrockAgentCoreApp\n",
    "#\n",
    "# The agent:\n",
    "# - Uses DuckDuckGo web search to find city information\n",
    "# - Can fetch and parse web pages for detailed information\n",
    "# - Returns responses with XML tags for programmatic parsing\n",
    "# - Is configured for AgentCore Runtime with the @app.entrypoint decorator\n",
    "\n",
    "from botocore.config import Config\n",
    "from ddgs import DDGS\n",
    "from strands import Agent, tool\n",
    "from strands.models import BedrockModel\n",
    "from bedrock_agentcore.runtime import BedrockAgentCoreApp\n",
    "from boto3.session import Session\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Get the current AWS region from the boto session\n",
    "boto_session = Session()\n",
    "region = boto_session.region_name\n",
    "\n",
    "# Configure timeout settings for Bedrock API calls\n",
    "# - connect_timeout: 5 seconds to establish connection\n",
    "# - read_timeout: 20 seconds for response (optimized for fast queries)\n",
    "# - retries: Disabled to fail fast and avoid hanging\n",
    "quick_config = Config(\n",
    "    connect_timeout=5,\n",
    "    read_timeout=20,\n",
    "    retries={\"max_attempts\": 0}\n",
    ")\n",
    "\n",
    "\n",
    "@tool\n",
    "def web_search(topic: str) -> str:\n",
    "    \"\"\"\n",
    "    Search DuckDuckGo for information about a topic.\n",
    "    \n",
    "    Args:\n",
    "        topic: Search query string\n",
    "    \n",
    "    Returns:\n",
    "        String containing top 5 search results with titles, URLs, and snippets\n",
    "    \"\"\"\n",
    "    try:\n",
    "        results = DDGS().text(topic, region=region, max_results=5)\n",
    "        return results if results else \"No results found.\"\n",
    "    except Exception as e:\n",
    "        return f\"Search error: {str(e)}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_page(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Fetch and return the raw text content from a URL.\n",
    "    \n",
    "    Args:\n",
    "        url: The URL to fetch content from\n",
    "    \n",
    "    Returns:\n",
    "        String containing the text content of the web page\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        bs = BeautifulSoup(response.text, 'html.parser')\n",
    "        return bs.text\n",
    "    except Exception as e:\n",
    "        return f\"Error fetching page: {str(e)}\"\n",
    "\n",
    "\n",
    "# Configure BedrockModel with Amazon Nova Micro\n",
    "# Nova Micro is chosen for optimized latency and cost in agent workflows\n",
    "chatbot_model_name = \"us.amazon.nova-micro-v1:0\"\n",
    "chatbot_model = BedrockModel(\n",
    "    model_id=chatbot_model_name,\n",
    "    boto_client_config=quick_config\n",
    ")\n",
    "\n",
    "# Define the system prompt for the City Search Agent\n",
    "# This establishes the tour guide persona and XML output format\n",
    "system_prompt = '''You are a helpful tour guide. Customers may ask you about the population and size of cities.\n",
    "You should use tools to retrieve all data, to make sure it is as current as possible.\n",
    "Please put your human friendly response in 'response' XML tags, and then follow with your data results in 'pop' and 'area' XML tags, for programatic processing.\n",
    "The values in the 'pop' and 'area' XML tags should only be numbers, no words or commas.\n",
    "You may also include a fun fact about the city in question.\n",
    "For example, your response to \"what is the population and size of Somewhereland?\" might be:\n",
    "<response>Somewhereland is a great place to get a hot dog. It has a population of 3000 people, and is 100 square miles.</response>\n",
    "<pop>3000</pop><area>100</area>\n",
    "'''\n",
    "\n",
    "# Create the City Search Agent with web_search and get_page tools\n",
    "chatbot = Agent(\n",
    "    system_prompt=system_prompt,\n",
    "    tools=[web_search, get_page],\n",
    "    model=chatbot_model\n",
    ")\n",
    "\n",
    "# Initialize the AgentCore Runtime App\n",
    "# This enables deployment to AgentCore Runtime with built-in observability\n",
    "app = BedrockAgentCoreApp()\n",
    "\n",
    "\n",
    "@app.entrypoint\n",
    "def invoke(payload):\n",
    "    \"\"\"\n",
    "    AgentCore Runtime entrypoint function.\n",
    "    \n",
    "    This function is called by AgentCore Runtime when the agent receives a request.\n",
    "    It extracts the prompt from the payload, invokes the agent, and returns the response.\n",
    "    \n",
    "    Args:\n",
    "        payload: Dictionary containing 'prompt' key with user query\n",
    "    \n",
    "    Returns:\n",
    "        Agent response string with XML tags for parsing\n",
    "    \"\"\"\n",
    "    user_input = payload.get(\"prompt\", \"\")\n",
    "    \n",
    "    # Invoke the agent with the user's query\n",
    "    response = chatbot(user_input)\n",
    "    \n",
    "    # Extract and return the text content from the response\n",
    "    return response.message[\"content\"][0][\"text\"]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the AgentCore Runtime app\n",
    "    # This starts the agent server when running locally or in a container\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì citysearch.py created successfully!\n",
      "  File size: 4309 bytes\n",
      "  Location: /Users/justmul/Desktop/evals/sample-gen-ai-evaluations-workshop/05-framework-specific-evaluations/05-04-AgentCore-Runtime-Evals/citysearch.py\n"
     ]
    }
   ],
   "source": [
    "# Verify the citysearch.py file was created successfully\n",
    "import os\n",
    "\n",
    "agent_file = \"./citysearch.py\"\n",
    "\n",
    "if os.path.exists(agent_file):\n",
    "    file_size = os.path.getsize(agent_file)\n",
    "    print(f\"‚úì citysearch.py created successfully!\")\n",
    "    print(f\"  File size: {file_size} bytes\")\n",
    "    print(f\"  Location: {os.path.abspath(agent_file)}\")\n",
    "\n",
    "else:\n",
    "    print(f\"‚úó Error: {agent_file} was not created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure AgentCore Runtime Deployment\n",
    "\n",
    "Now we'll configure the deployment using the `bedrock-agentcore-starter-toolkit`. The `Runtime.configure()` method sets up all the necessary AWS resources and configuration for deploying our agent.\n",
    "\n",
    "#### Configuration Parameters\n",
    "\n",
    "| Parameter | Description |\n",
    "|-----------|-------------|\n",
    "| `entrypoint` | The Python file containing the agent code with `@app.entrypoint` decorator |\n",
    "| `auto_create_execution_role` | Automatically create an IAM execution role for the agent |\n",
    "| `auto_create_ecr` | Automatically create an ECR repository for the container image |\n",
    "| `requirements_file` | Path to the requirements.txt file with dependencies |\n",
    "| `region` | AWS region for deployment |\n",
    "| `agent_name` | Name identifier for the deployed agent |\n",
    "\n",
    "#### What Happens During Configuration\n",
    "\n",
    "The `configure()` method:\n",
    "1. Parses the entrypoint file to identify the `BedrockAgentCoreApp` configuration\n",
    "2. Creates a `.bedrock_agentcore.yaml` configuration file\n",
    "3. Generates a `Dockerfile` for containerizing the agent\n",
    "4. Creates a `.dockerignore` file to exclude unnecessary files\n",
    "5. Sets up IAM roles and ECR repository references (if auto-create is enabled)\n",
    "\n",
    "After configuration, we'll be ready to launch the agent to AgentCore Runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrypoint parsed: file=/Users/justmul/Desktop/evals/sample-gen-ai-evaluations-workshop/05-framework-specific-evaluations/05-04-AgentCore-Runtime-Evals/citysearch.py, bedrock_agentcore_name=citysearch\n",
      "Memory disabled - agent will be stateless\n",
      "Configuring BedrockAgentCore agent: citysearch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring AgentCore Runtime deployment...\n",
      "  Agent name: citysearch\n",
      "  Region: us-east-1\n",
      "  Entrypoint: citysearch.py\n",
      "  Requirements: requirements.txt\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "üí° <span style=\"color: #008080; text-decoration-color: #008080\">No container engine found </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080\">Docker/Finch/Podman not installed</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "üí° \u001b[36mNo container engine found \u001b[0m\u001b[1;36m(\u001b[0m\u001b[36mDocker/Finch/Podman not installed\u001b[0m\u001b[1;36m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">‚úì</span> Default deployment uses CodeBuild <span style=\"font-weight: bold\">(</span>no container engine needed<span style=\"font-weight: bold\">)</span>, For local builds, install Docker, Finch, or \n",
       "Podman\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m‚úì\u001b[0m Default deployment uses CodeBuild \u001b[1m(\u001b[0mno container engine needed\u001b[1m)\u001b[0m, For local builds, install Docker, Finch, or \n",
       "Podman\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Memory disabled\n",
      "Network mode: PUBLIC\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">üìÑ Generated Dockerfile: \n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">/Users/justmul/Desktop/evals/sample-gen-ai-evaluations-workshop/05-framework-specific-evaluations/05-04-AgentCore-R</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">untime-Evals/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">Dockerfile</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "üìÑ Generated Dockerfile: \n",
       "\u001b[35m/Users/justmul/Desktop/evals/sample-gen-ai-evaluations-workshop/05-framework-specific-evaluations/05-04-AgentCore-R\u001b[0m\n",
       "\u001b[35muntime-Evals/\u001b[0m\u001b[95mDockerfile\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generated .dockerignore: /Users/justmul/Desktop/evals/sample-gen-ai-evaluations-workshop/05-framework-specific-evaluations/05-04-AgentCore-Runtime-Evals/.dockerignore\n",
      "Setting 'citysearch' as default agent\n",
      "Bedrock AgentCore configured: /Users/justmul/Desktop/evals/sample-gen-ai-evaluations-workshop/05-framework-specific-evaluations/05-04-AgentCore-Runtime-Evals/.bedrock_agentcore.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Configuration Summary\n",
      "============================================================\n",
      "\n",
      "‚úì Configuration completed successfully!\n",
      "\n",
      "Generated files:\n",
      "  - Config file: /Users/justmul/Desktop/evals/sample-gen-ai-evaluations-workshop/05-framework-specific-evaluations/05-04-AgentCore-Runtime-Evals/.bedrock_agentcore.yaml\n",
      "  - Dockerfile: /Users/justmul/Desktop/evals/sample-gen-ai-evaluations-workshop/05-framework-specific-evaluations/05-04-AgentCore-Runtime-Evals/Dockerfile\n",
      "  - Docker ignore: /Users/justmul/Desktop/evals/sample-gen-ai-evaluations-workshop/05-framework-specific-evaluations/05-04-AgentCore-Runtime-Evals/.dockerignore\n",
      "\n",
      "Deployment settings:\n",
      "  - Runtime: None\n",
      "  - Region: us-east-1\n",
      "  - Account ID: 616455080294\n",
      "  - Auto-create ECR: True\n",
      "\n",
      "The agent is now configured and ready for launch!\n",
      "\n",
      "============================================================\n",
      "Full Configuration Response:\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ConfigureResult(config_path=PosixPath('/Users/justmul/Desktop/evals/sample-gen-ai-evaluations-workshop/05-framework-specific-evaluations/05-04-AgentCore-Runtime-Evals/.bedrock_agentcore.yaml'), dockerfile_path=PosixPath('/Users/justmul/Desktop/evals/sample-gen-ai-evaluations-workshop/05-framework-specific-evaluations/05-04-AgentCore-Runtime-Evals/Dockerfile'), dockerignore_path=PosixPath('/Users/justmul/Desktop/evals/sample-gen-ai-evaluations-workshop/05-framework-specific-evaluations/05-04-AgentCore-Runtime-Evals/.dockerignore'), runtime='None', runtime_type=None, region='us-east-1', account_id='616455080294', execution_role=None, ecr_repository=None, auto_create_ecr=True, s3_path=None, auto_create_s3=False, memory_id=None, network_mode='PUBLIC', network_subnets=None, network_security_groups=None, network_vpc_id=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure AgentCore Runtime deployment\n",
    "# This sets up all necessary AWS resources and configuration files\n",
    "\n",
    "from bedrock_agentcore_starter_toolkit import Runtime\n",
    "from boto3.session import Session\n",
    "\n",
    "# Get the current AWS region from the boto session\n",
    "boto_session = Session()\n",
    "region = boto_session.region_name\n",
    "\n",
    "# Define the agent name for deployment\n",
    "# This name will be used to identify the agent in AgentCore Runtime\n",
    "agent_name = \"citysearch\"\n",
    "\n",
    "# Create a Runtime instance for managing the deployment\n",
    "agentcore_runtime = Runtime()\n",
    "\n",
    "# Configure the deployment with all required parameters\n",
    "print(f\"Configuring AgentCore Runtime deployment...\")\n",
    "print(f\"  Agent name: {agent_name}\")\n",
    "print(f\"  Region: {region}\")\n",
    "print(f\"  Entrypoint: citysearch.py\")\n",
    "print(f\"  Requirements: requirements.txt\")\n",
    "print()\n",
    "\n",
    "configure_response = agentcore_runtime.configure(\n",
    "    entrypoint=\"citysearch.py\",\n",
    "    auto_create_execution_role=True,\n",
    "    auto_create_ecr=True,\n",
    "    requirements_file=\"requirements.txt\",\n",
    "    region=region,\n",
    "    agent_name=agent_name\n",
    ")\n",
    "\n",
    "# Display the configuration result\n",
    "print(\"=\"*60)\n",
    "print(\"Configuration Summary\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n‚úì Configuration completed successfully!\")\n",
    "print(f\"\\nGenerated files:\")\n",
    "print(f\"  - Config file: {configure_response.config_path}\")\n",
    "print(f\"  - Dockerfile: {configure_response.dockerfile_path}\")\n",
    "print(f\"  - Docker ignore: {configure_response.dockerignore_path}\")\n",
    "print(f\"\\nDeployment settings:\")\n",
    "print(f\"  - Runtime: {configure_response.runtime}\")\n",
    "print(f\"  - Region: {configure_response.region}\")\n",
    "print(f\"  - Account ID: {configure_response.account_id}\")\n",
    "print(f\"  - Auto-create ECR: {configure_response.auto_create_ecr}\")\n",
    "print(f\"\\nThe agent is now configured and ready for launch!\")\n",
    "\n",
    "# Display the full configuration response for reference\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Full Configuration Response:\")\n",
    "print(\"=\"*60)\n",
    "configure_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch Agent to AgentCore Runtime\n",
    "\n",
    "Now that the agent is configured, we'll launch it to AgentCore Runtime. The `runtime.launch()` method performs the following steps:\n",
    "\n",
    "1. **Build Container**: Publishes the Docker image to ECR using CodeBuild (ARM64 architecture)\n",
    "2. **Create/Update Agent**: Registers or updates the agent in AgentCore Runtime\n",
    "3. **Deploy Endpoint**: Creates a runtime endpoint for invoking the agent\n",
    "\n",
    "#### Launch Parameters\n",
    "\n",
    "| Parameter | Description |\n",
    "|-----------|-------------|\n",
    "| `auto_update_on_conflict` | If `True`, automatically updates the agent if it already exists. If `False`, raises an error on conflict. |\n",
    "\n",
    "#### What to Expect\n",
    "\n",
    "The launch process typically takes **2-5 minutes** and includes:\n",
    "- CodeBuild phases: QUEUED ‚Üí PROVISIONING ‚Üí DOWNLOAD_SOURCE ‚Üí BUILD ‚Üí POST_BUILD ‚Üí FINALIZING ‚Üí COMPLETED\n",
    "- Agent deployment to AgentCore Runtime\n",
    "- Endpoint creation and readiness polling\n",
    "\n",
    "After launch completes, we'll store the **agent ARN** for use in subsequent evaluation steps. The agent ARN is required for:\n",
    "- Invoking the agent via the `invoke_agent_runtime` API\n",
    "- Constructing the CloudWatch log group name for span retrieval\n",
    "- Running AgentCore Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üöÄ Launching Bedrock AgentCore (cloud mode - RECOMMENDED)...\n",
      "   ‚Ä¢ Deploy Python code directly to runtime\n",
      "   ‚Ä¢ No Docker required (DEFAULT behavior)\n",
      "   ‚Ä¢ Production-ready deployment\n",
      "\n",
      "üí° Deployment options:\n",
      "   ‚Ä¢ runtime.launch()                ‚Üí Cloud (current)\n",
      "   ‚Ä¢ runtime.launch(local=True)      ‚Üí Local development\n",
      "Memory disabled - skipping memory creation\n",
      "Starting CodeBuild ARM64 deployment for agent 'citysearch' to account 616455080294 (us-east-1)\n",
      "Generated image tag: 20260129-174942-080\n",
      "Setting up AWS resources (ECR repository, execution roles)...\n",
      "Getting or creating ECR repository for agent: citysearch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching agent to AgentCore Runtime...\n",
      "This process typically takes 2-5 minutes.\n",
      "\n",
      "============================================================\n",
      "Launch Progress:\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ECR repository available: 616455080294.dkr.ecr.us-east-1.amazonaws.com/bedrock-agentcore-citysearch\n",
      "Getting or creating execution role for agent: citysearch\n",
      "Using AWS region: us-east-1, account ID: 616455080294\n",
      "Role name: AmazonBedrockAgentCoreSDKRuntime-us-east-1-672e22fb7a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Reusing existing ECR repository: 616455080294.dkr.ecr.us-east-1.amazonaws.com/bedrock-agentcore-citysearch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "‚úÖ Reusing existing execution role: arn:aws:iam::616455080294:role/AmazonBedrockAgentCoreSDKRuntime-us-east-1-672e22fb7a\n",
      "Execution role available: arn:aws:iam::616455080294:role/AmazonBedrockAgentCoreSDKRuntime-us-east-1-672e22fb7a\n",
      "Preparing CodeBuild project and uploading source...\n",
      "Getting or creating CodeBuild execution role for agent: citysearch\n",
      "Role name: AmazonBedrockAgentCoreSDKCodeBuild-us-east-1-672e22fb7a\n",
      "Reusing existing CodeBuild execution role: arn:aws:iam::616455080294:role/AmazonBedrockAgentCoreSDKCodeBuild-us-east-1-672e22fb7a\n",
      "Using dockerignore.template with 47 patterns for zip filtering\n",
      "Uploaded source to S3: citysearch/source.zip\n",
      "Updated CodeBuild project: bedrock-agentcore-citysearch-builder\n",
      "Starting CodeBuild build (this may take several minutes)...\n",
      "Starting CodeBuild monitoring...\n",
      "üîÑ QUEUED started (total: 0s)\n",
      "‚úÖ QUEUED completed in 1.1s\n",
      "üîÑ PROVISIONING started (total: 1s)\n",
      "‚úÖ PROVISIONING completed in 10.1s\n",
      "üîÑ DOWNLOAD_SOURCE started (total: 11s)\n",
      "‚úÖ DOWNLOAD_SOURCE completed in 1.1s\n",
      "üîÑ BUILD started (total: 12s)\n",
      "‚úÖ BUILD completed in 20.2s\n",
      "üîÑ POST_BUILD started (total: 33s)\n",
      "‚úÖ POST_BUILD completed in 15.7s\n",
      "üîÑ COMPLETED started (total: 48s)\n",
      "‚úÖ COMPLETED completed in 1.1s\n",
      "üéâ CodeBuild completed successfully in 0m 49s\n",
      "CodeBuild completed successfully\n",
      "CodeBuild project configuration saved\n",
      "Deploying to Bedrock AgentCore...\n",
      "Agent created/updated: arn:aws:bedrock-agentcore:us-east-1:616455080294:runtime/citysearch-U6S1xN3zuf\n",
      "Observability is enabled, configuring observability components...\n",
      "CloudWatch Logs resource policy already configured\n",
      "X-Ray trace destination already configured\n",
      "X-Ray indexing rule already configured\n",
      "Transaction Search already fully configured\n",
      "ObservabilityDeliveryManager initialized for region: us-east-1, account: 616455080294\n",
      "‚úÖ Logs auto-created by AWS for runtime/citysearch-U6S1xN3zuf\n",
      "‚úÖ Traces delivery enabled for runtime/citysearch-U6S1xN3zuf\n",
      "Observability enabled for runtime/citysearch-U6S1xN3zuf - logs: True, traces: True\n",
      "‚úÖ X-Ray traces delivery enabled for agent citysearch-U6S1xN3zuf\n",
      "üîç GenAI Observability Dashboard:\n",
      "   https://console.aws.amazon.com/cloudwatch/home?region=us-east-1#gen-ai-observability/agent-core\n",
      "Polling for endpoint to be ready...\n",
      "Agent endpoint: arn:aws:bedrock-agentcore:us-east-1:616455080294:runtime/citysearch-U6S1xN3zuf/runtime-endpoint/DEFAULT\n",
      "Deployment completed successfully - Agent: arn:aws:bedrock-agentcore:us-east-1:616455080294:runtime/citysearch-U6S1xN3zuf\n",
      "Built with CodeBuild: bedrock-agentcore-citysearch-builder:4f403444-d5c8-4806-97d6-aafa7899ddcd\n",
      "Deployed to cloud: arn:aws:bedrock-agentcore:us-east-1:616455080294:runtime/citysearch-U6S1xN3zuf\n",
      "ECR image: 616455080294.dkr.ecr.us-east-1.amazonaws.com/bedrock-agentcore-citysearch:20260129-174942-080\n",
      "üîç Agent logs available at:\n",
      "   /aws/bedrock-agentcore/runtimes/citysearch-U6S1xN3zuf-DEFAULT --log-stream-name-prefix \"2026/01/29/\\[runtime-logs]\"\n",
      "   /aws/bedrock-agentcore/runtimes/citysearch-U6S1xN3zuf-DEFAULT --log-stream-names \"otel-rt-logs\"\n",
      "üí° Tail logs with: aws logs tail /aws/bedrock-agentcore/runtimes/citysearch-U6S1xN3zuf-DEFAULT --log-stream-name-prefix \"2026/01/29/\\[runtime-logs]\" --follow\n",
      "üí° Or view recent logs: aws logs tail /aws/bedrock-agentcore/runtimes/citysearch-U6S1xN3zuf-DEFAULT --log-stream-name-prefix \"2026/01/29/\\[runtime-logs]\" --since 1h\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Launch Complete!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Launch the agent to AgentCore Runtime\n",
    "# This step builds the container, deploys to AgentCore, and creates the endpoint\n",
    "#\n",
    "# auto_update_on_conflict=True ensures that if the agent already exists,\n",
    "# it will be updated with the new configuration rather than raising an error\n",
    "\n",
    "print(\"Launching agent to AgentCore Runtime...\")\n",
    "print(\"This process typically takes 2-5 minutes.\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Launch Progress:\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Launch the agent with auto_update_on_conflict=True\n",
    "# This will update the agent if it already exists\n",
    "launch_result = agentcore_runtime.launch(auto_update_on_conflict=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Launch Complete!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent ARN Extracted and Stored\n",
      "============================================================\n",
      "\n",
      "‚úì Agent ARN: arn:aws:bedrock-agentcore:us-east-1:616455080294:runtime/citysearch-U6S1xN3zuf\n",
      "Stored 'citysearch_agent_arn' (str)\n",
      "\n",
      "‚úì Agent ARN stored as 'citysearch_agent_arn' for use in subsequent cells\n",
      "\n",
      "============================================================\n",
      "Full Launch Result:\n",
      "============================================================\n",
      "\n",
      "Agent ARN: arn:aws:bedrock-agentcore:us-east-1:616455080294:runtime/citysearch-U6S1xN3zuf\n",
      "Endpoint ARN: N/A\n",
      "ECR Image: N/A\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LaunchResult(mode='codebuild', tag='bedrock_agentcore-citysearch:None', env_vars=None, port=None, runtime=None, ecr_uri='616455080294.dkr.ecr.us-east-1.amazonaws.com/bedrock-agentcore-citysearch:20260129-174942-080', agent_id='citysearch-U6S1xN3zuf', agent_arn='arn:aws:bedrock-agentcore:us-east-1:616455080294:runtime/citysearch-U6S1xN3zuf', codebuild_id='bedrock-agentcore-citysearch-builder:4f403444-d5c8-4806-97d6-aafa7899ddcd', build_output=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract and store the agent ARN for later use\n",
    "# The agent ARN is required for:\n",
    "# - Invoking the agent via invoke_agent_runtime API\n",
    "# - Constructing CloudWatch log group names\n",
    "# - Running AgentCore Evaluations\n",
    "\n",
    "# Extract the agent ARN from the launch result\n",
    "agent_arn = launch_result.agent_arn\n",
    "\n",
    "print(\"Agent ARN Extracted and Stored\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n‚úì Agent ARN: {agent_arn}\")\n",
    "\n",
    "# Store the agent ARN using IPython's %store magic\n",
    "# This persists the variable across notebook sessions\n",
    "citysearch_agent_arn = agent_arn\n",
    "%store citysearch_agent_arn\n",
    "\n",
    "print(f\"\\n‚úì Agent ARN stored as 'citysearch_agent_arn' for use in subsequent cells\")\n",
    "\n",
    "# Display the full launch result for reference\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Full Launch Result:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nAgent ARN: {launch_result.agent_arn}\")\n",
    "print(f\"Endpoint ARN: {getattr(launch_result, 'endpoint_arn', 'N/A')}\")\n",
    "print(f\"ECR Image: {getattr(launch_result, 'ecr_image', 'N/A')}\")\n",
    "\n",
    "# Display the launch result object\n",
    "launch_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE!  If you need to delete the local configuration, and start over from scratch, run this cell.\n",
    "# This can happen if you deploy an agent then delete it, and the above cell is still trying to update the deleted agent.\n",
    "# This is needed because in the configuration cell, we create local configuration files which are used by the launch cell.\n",
    "if False:\n",
    "    import os\n",
    "\n",
    "    # Remove the config file so launch creates a new agent instead of updating\n",
    "    config_files = ['.bedrock_agentcore.yaml', 'Dockerfile', '.dockerignore']\n",
    "    for f in config_files:\n",
    "        if os.path.exists(f):\n",
    "            os.remove(f)\n",
    "            print(f\"Deleted {f}\")\n",
    "        else:\n",
    "            print(f\"{f} not found\")\n",
    "\n",
    "    print(\"\\nNow re-run the configure() and launch() cells\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Agent Status\n",
    "\n",
    "After launching the agent, we need to verify that it has reached the **READY** status before we can invoke it. The agent goes through several states during deployment:\n",
    "\n",
    "| Status | Description |\n",
    "|--------|-------------|\n",
    "| `CREATING` | Agent is being created and deployed |\n",
    "| `UPDATING` | Agent is being updated with new configuration |\n",
    "| `READY` | Agent is ready to receive invocations |\n",
    "| `CREATE_FAILED` | Agent creation failed |\n",
    "| `UPDATE_FAILED` | Agent update failed |\n",
    "| `DELETE_FAILED` | Agent deletion failed |\n",
    "\n",
    "This cell polls the agent status every 10 seconds until it reaches a terminal state (READY or a failure state). A timeout of 5 minutes is enforced to prevent indefinite waiting.\n",
    "\n",
    "**Note**: The agent must be in READY status before proceeding to the invocation and evaluation steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying Agent Status\n",
      "============================================================\n",
      "Polling interval: 10 seconds\n",
      "Timeout: 300 seconds (5 minutes)\n",
      "\n",
      "Polling agent status...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieved Bedrock AgentCore status for: citysearch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0s] Current status: READY\n",
      "\n",
      "============================================================\n",
      "Status Verification Complete\n",
      "============================================================\n",
      "\n",
      "‚úì Agent is READY!\n",
      "  Total wait time: 0 seconds\n",
      "\n",
      "The agent is now ready to receive invocations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'READY'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify agent status is READY before proceeding\n",
    "# This cell polls the agent status until it reaches a terminal state\n",
    "#\n",
    "# Terminal states:\n",
    "# - READY: Agent is ready for invocations\n",
    "# - CREATE_FAILED, UPDATE_FAILED, DELETE_FAILED: Deployment failed\n",
    "#\n",
    "# Timeout: 5 minutes (300 seconds) to prevent indefinite waiting\n",
    "\n",
    "import time\n",
    "\n",
    "# Configuration for status polling\n",
    "POLL_INTERVAL_SECONDS = 10  # Time between status checks\n",
    "TIMEOUT_SECONDS = 300       # Maximum wait time (5 minutes)\n",
    "\n",
    "# Terminal states that indicate deployment is complete (success or failure)\n",
    "TERMINAL_STATES = ['READY', 'CREATE_FAILED', 'DELETE_FAILED', 'UPDATE_FAILED']\n",
    "\n",
    "print(\"Verifying Agent Status\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Polling interval: {POLL_INTERVAL_SECONDS} seconds\")\n",
    "print(f\"Timeout: {TIMEOUT_SECONDS} seconds ({TIMEOUT_SECONDS // 60} minutes)\")\n",
    "print(\"\\nPolling agent status...\\n\")\n",
    "\n",
    "# Track elapsed time for timeout\n",
    "start_time = time.time()\n",
    "elapsed_time = 0\n",
    "\n",
    "# Get initial status\n",
    "status_response = agentcore_runtime.status()\n",
    "status = status_response.endpoint['status']\n",
    "print(f\"[{elapsed_time:3d}s] Current status: {status}\")\n",
    "\n",
    "# Poll until terminal state or timeout\n",
    "while status not in TERMINAL_STATES:\n",
    "    # Check for timeout\n",
    "    elapsed_time = int(time.time() - start_time)\n",
    "    if elapsed_time >= TIMEOUT_SECONDS:\n",
    "        print(f\"\\n\" + \"=\"*60)\n",
    "        print(\"‚ö† TIMEOUT: Agent did not reach READY status within 5 minutes\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"\\nLast known status: {status}\")\n",
    "        print(f\"Elapsed time: {elapsed_time} seconds\")\n",
    "        print(\"\\nPossible actions:\")\n",
    "        print(\"  1. Wait longer and re-run this cell to check status again\")\n",
    "        print(\"  2. Check AWS Console for AgentCore Runtime deployment status\")\n",
    "        print(\"  3. Review CloudWatch logs for any deployment errors\")\n",
    "        break\n",
    "    \n",
    "    # Wait before next poll\n",
    "    time.sleep(POLL_INTERVAL_SECONDS)\n",
    "    \n",
    "    # Get updated status\n",
    "    status_response = agentcore_runtime.status()\n",
    "    status = status_response.endpoint['status']\n",
    "    elapsed_time = int(time.time() - start_time)\n",
    "    print(f\"[{elapsed_time:3d}s] Current status: {status}\")\n",
    "\n",
    "# Display final result\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Status Verification Complete\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if status == 'READY':\n",
    "    print(f\"\\n‚úì Agent is READY!\")\n",
    "    print(f\"  Total wait time: {elapsed_time} seconds\")\n",
    "    print(f\"\\nThe agent is now ready to receive invocations.\")\n",
    "elif status in ['CREATE_FAILED', 'UPDATE_FAILED', 'DELETE_FAILED']:\n",
    "    print(f\"\\n‚úó Deployment FAILED with status: {status}\")\n",
    "    print(f\"  Total wait time: {elapsed_time} seconds\")\n",
    "    print(f\"\\nPlease check CloudWatch logs for error details.\")\n",
    "    print(f\"You may need to fix the issue and re-run the launch cell.\")\n",
    "else:\n",
    "    print(f\"\\n‚ö† Status check ended with status: {status}\")\n",
    "    print(f\"  This may indicate a timeout or unexpected state.\")\n",
    "\n",
    "# Display the final status\n",
    "status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Invocation via invoke_agent_runtime API\n",
    "\n",
    "Now that the agent is deployed and in READY status, we'll demonstrate a test invocation using the `invoke_agent_runtime` API. This API allows you to:\n",
    "\n",
    "- **Invoke the deployed agent**: Send queries to your agent running on AgentCore Runtime\n",
    "- **Manage sessions**: Use unique session IDs to track conversations and generate trace data\n",
    "- **Receive responses**: Get the agent's response as a streaming body that can be parsed\n",
    "\n",
    "#### API Parameters\n",
    "\n",
    "| Parameter | Description |\n",
    "|-----------|-------------|\n",
    "| `agentRuntimeArn` | The ARN of the deployed agent (obtained from launch result) |\n",
    "| `runtimeSessionId` | A unique session identifier (must be 33+ characters) |\n",
    "| `payload` | JSON-encoded payload containing the prompt |\n",
    "| `qualifier` | Optional qualifier (default: \"DEFAULT\") |\n",
    "\n",
    "#### Session ID Requirements\n",
    "\n",
    "The `runtimeSessionId` must be at least 33 characters long. We use a UUID-based format (`eval-session-{uuid}`) which ensures:\n",
    "- Uniqueness across invocations\n",
    "- Sufficient length (typically 49 characters)\n",
    "- Easy identification in CloudWatch logs\n",
    "\n",
    "This test invocation confirms that the deployment was successful and the agent can respond to queries via the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Invocation via invoke_agent_runtime API\n",
      "============================================================\n",
      "\n",
      "Agent ARN: arn:aws:bedrock-agentcore:us-east-1:616455080294:runtime/citysearch-U6S1xN3zuf\n",
      "Session ID: eval-session-29186765-44c7-4fab-ba3b-6ba32c2aa8cc\n",
      "Session ID length: 49 characters (minimum: 33)\n",
      "\n",
      "Query: What is the population and area of Chicago, IL?\n",
      "\n",
      "============================================================\n",
      "Invoking agent...\n",
      "============================================================\n",
      "\n",
      "Agent Response:\n",
      "------------------------------------------------------------\n",
      "<thinking> After reviewing the search results, I found several sources that\n",
      "discuss Chicago's population, including projections and official data. The most\n",
      "reliable source for the current population and area of Chicago is the City of\n",
      "Chicago's official press release. Based on the latest data, Chicago has an\n",
      "approximate population of 2.7 million people and covers an area of about 227.6\n",
      "square miles. Here's the information I found:</thinking>  <response>Chicago is a\n",
      "vibrant city with a rich history and diverse culture. As of the most recent\n",
      "estimates, the population of Chicago is approximately 2.7 million people, making\n",
      "it the third largest city in the United States. The city spans an area of about\n",
      "227.6 square miles, making it not only populous but also quite expansive.\n",
      "Chicago is known for its iconic architecture, deep-dish pizza, and vibrant\n",
      "cultural scene, including world-class museums and theaters.</response>\n",
      "<pop>2700000</pop><area>227.6</area>\n",
      "\n",
      "============================================================\n",
      "Test Invocation Complete!\n",
      "============================================================\n",
      "\n",
      "Response Metadata:\n",
      "  HTTP Status Code: 200\n",
      "  Request ID: 38f97a7e-694e-4233-800e-1ffb07d1aacc\n",
      "  Runtime Session ID: eval-session-29186765-44c7-4fab-ba3b-6ba32c2aa8cc\n",
      "  Trace ID: Root=1-697b9e32-5db6edb7120fa26d5101d122;Parent=02a6f1c0d480545f;Sampled=1;Self=1-697b9e32-26fb2c310edf77d335e7ce19\n",
      "\n",
      "XML Tag Verification:\n",
      "  ‚úì <response> tag found\n",
      "  ‚úì <pop> tag found\n",
      "  ‚úì <area> tag found\n",
      "\n",
      "‚úì Deployment test PASSED! Agent is responding correctly via API.\n",
      "\n",
      "The agent is successfully deployed and responding to API invocations!\n"
     ]
    }
   ],
   "source": [
    "# Test invocation via invoke_agent_runtime API\n",
    "# This demonstrates successful deployment by invoking the agent through the API\n",
    "#\n",
    "# The invoke_agent_runtime API:\n",
    "# - Sends a query to the deployed agent\n",
    "# - Returns a streaming response body\n",
    "# - Generates trace data in CloudWatch for later evaluation\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "import uuid\n",
    "import textwrap\n",
    "\n",
    "# Create a boto3 client for bedrock-agentcore\n",
    "# This client provides access to the invoke_agent_runtime API\n",
    "agentcore_client = boto3.client('bedrock-agentcore', region_name=region)\n",
    "\n",
    "# Generate a unique session ID (must be 33+ characters)\n",
    "# Format: eval-session-{uuid} ensures uniqueness and sufficient length\n",
    "test_session_id = f\"eval-session-{uuid.uuid4()}\"\n",
    "\n",
    "# Prepare the test query payload\n",
    "# The payload must be JSON-encoded with a 'prompt' key\n",
    "test_query = \"What is the population and area of Chicago, IL?\"\n",
    "payload = json.dumps({\"prompt\": test_query})\n",
    "\n",
    "print(\"Test Invocation via invoke_agent_runtime API\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nAgent ARN: {citysearch_agent_arn}\")\n",
    "print(f\"Session ID: {test_session_id}\")\n",
    "print(f\"Session ID length: {len(test_session_id)} characters (minimum: 33)\")\n",
    "print(f\"\\nQuery: {test_query}\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Invoking agent...\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Invoke the deployed agent using the invoke_agent_runtime API\n",
    "response = agentcore_client.invoke_agent_runtime(\n",
    "    agentRuntimeArn=citysearch_agent_arn,\n",
    "    runtimeSessionId=test_session_id,\n",
    "    payload=payload,\n",
    "    qualifier=\"DEFAULT\"\n",
    ")\n",
    "\n",
    "# Read and parse the response\n",
    "# The response body is a streaming object that needs to be read\n",
    "response_body = response['response'].read()\n",
    "response_data = json.loads(response_body)\n",
    "\n",
    "# Display the response\n",
    "print(\"Agent Response:\")\n",
    "print(\"-\"*60)\n",
    "if isinstance(response_data, str):\n",
    "    # Response is a string, wrap it for readability\n",
    "    wrapped = textwrap.fill(response_data, width=80)\n",
    "    print(wrapped)\n",
    "else:\n",
    "    # Response is a dict/object, pretty print it\n",
    "    formatted = json.dumps(response_data, indent=2)\n",
    "    print(formatted)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Test Invocation Complete!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Display response metadata\n",
    "print(f\"\\nResponse Metadata:\")\n",
    "print(f\"  HTTP Status Code: {response['ResponseMetadata']['HTTPStatusCode']}\")\n",
    "print(f\"  Request ID: {response['ResponseMetadata']['RequestId']}\")\n",
    "print(f\"  Runtime Session ID: {response.get('runtimeSessionId', 'N/A')}\")\n",
    "print(f\"  Trace ID: {response.get('traceId', 'N/A')}\")\n",
    "\n",
    "# Verify XML tags are present in the response\n",
    "response_str = str(response_data)\n",
    "xml_tags_present = {\n",
    "    \"<response>\": \"<response>\" in response_str,\n",
    "    \"<pop>\": \"<pop>\" in response_str,\n",
    "    \"<area>\": \"<area>\" in response_str\n",
    "}\n",
    "\n",
    "print(\"\\nXML Tag Verification:\")\n",
    "for tag, present in xml_tags_present.items():\n",
    "    status_icon = \"‚úì\" if present else \"‚úó\"\n",
    "    print(f\"  {status_icon} {tag} tag {'found' if present else 'NOT found'}\")\n",
    "\n",
    "if all(xml_tags_present.values()):\n",
    "    print(\"\\n‚úì Deployment test PASSED! Agent is responding correctly via API.\")\n",
    "else:\n",
    "    print(\"\\n‚ö† Warning: Some expected XML tags are missing from the response.\")\n",
    "\n",
    "print(\"\\nThe agent is successfully deployed and responding to API invocations!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Agent Invocation for Trace Generation\n",
    "\n",
    "Now that our agent is deployed and verified, we'll invoke it multiple times to generate trace data for evaluation. This section covers:\n",
    "\n",
    "1. **Load Test Cases**: Read city data from `city_pop.csv` containing city, state, population, and area information\n",
    "2. **Data Cleaning**: Remove Wikipedia footnotes (like `[c]`, `[d]`) from city names\n",
    "3. **Generate Session IDs**: Create unique session identifiers for each invocation\n",
    "4. **Execute Invocations**: Call the deployed agent for each test case\n",
    "5. **Wait for Logs**: Allow time for CloudWatch log propagation\n",
    "\n",
    "### Why Multiple Invocations?\n",
    "\n",
    "Running multiple invocations with different test cases allows us to:\n",
    "\n",
    "- **Generate Diverse Traces**: Capture agent behavior across different queries\n",
    "- **Enable Statistical Analysis**: Calculate average scores across multiple evaluations\n",
    "- **Test Consistency**: Verify the agent performs reliably across different inputs\n",
    "- **Build Evaluation Dataset**: Create a representative sample for AgentCore Evaluations\n",
    "\n",
    "### Test Case Data\n",
    "\n",
    "The `city_pop.csv` file contains real city data with the following columns:\n",
    "\n",
    "| Column | Description | Example |\n",
    "|--------|-------------|--------|\n",
    "| `city` | City name (may include Wikipedia footnotes) | \"New York[c]\" |\n",
    "| `state` | State abbreviation | \"NY\" |\n",
    "| `population` | City population | \"8,478,072\" |\n",
    "| `land_area_mi2` | Land area in square miles | \"300.5\" |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test cases from city_pop.csv...\n",
      "============================================================\n",
      "\n",
      "Total cities in dataset: 346\n",
      "Columns: ['city', 'state', 'population', 'land_area_mi2']\n",
      "\n",
      "============================================================\n",
      "Raw Data (before cleaning):\n",
      "============================================================\n",
      "          city state population land_area_mi2\n",
      "0  New York[c]    NY  8,478,072         300.5\n",
      "1  Los Angeles    CA  3,878,704         469.5\n",
      "2      Chicago    IL  2,721,308         227.7\n",
      "3      Houston    TX  2,390,125         640.4\n",
      "4      Phoenix    AZ  1,673,164           518\n",
      "\n",
      "============================================================\n",
      "Test Cases (first 5 cities, cleaned):\n",
      "============================================================\n",
      "       City State  Population Area (sq mi)\n",
      "   New York    NY     8478072        300.5\n",
      "Los Angeles    CA     3878704        469.5\n",
      "    Chicago    IL     2721308        227.7\n",
      "    Houston    TX     2390125        640.4\n",
      "    Phoenix    AZ     1673164          518\n",
      "\n",
      "============================================================\n",
      "Data Cleaning Summary:\n",
      "============================================================\n",
      "  ‚úì Cleaned: 'New York[c]' ‚Üí 'New York'\n",
      "  - No change: 'Los Angeles'\n",
      "  - No change: 'Chicago'\n",
      "  - No change: 'Houston'\n",
      "  - No change: 'Phoenix'\n",
      "\n",
      "‚úì Loaded 5 test cases successfully!\n",
      "\n",
      "These cities will be used to invoke the agent and generate traces for evaluation.\n"
     ]
    }
   ],
   "source": [
    "# Load test cases from city_pop.csv\n",
    "# This cell loads city data and prepares it for agent invocation\n",
    "#\n",
    "# Data cleaning steps:\n",
    "# 1. Load the CSV file using pandas\n",
    "# 2. Remove Wikipedia footnotes (e.g., [c], [d], [e]) from city names\n",
    "# 3. Convert population strings to integers (remove commas)\n",
    "# 4. Select the first 5 cities as test cases\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the city population data from CSV\n",
    "csv_path = \"city_pop.csv\"\n",
    "print(f\"Loading test cases from {csv_path}...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Read the CSV file\n",
    "city_df = pd.read_csv(csv_path)\n",
    "\n",
    "print(f\"\\nTotal cities in dataset: {len(city_df)}\")\n",
    "print(f\"Columns: {list(city_df.columns)}\")\n",
    "\n",
    "# Display raw data before cleaning (first 5 rows)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Raw Data (before cleaning):\")\n",
    "print(\"=\"*60)\n",
    "print(city_df.head())\n",
    "\n",
    "# Clean the data: Remove Wikipedia footnotes from city names\n",
    "# Footnotes appear as [letter] at the end of city names, e.g., \"New York[c]\"\n",
    "# Pattern: \\[\\w+\\] matches [c], [d], [e], etc.\n",
    "def clean_city_name(city_name):\n",
    "    \"\"\"Remove Wikipedia footnotes like [c], [d] from city names.\"\"\"\n",
    "    return re.sub(r'\\[\\w+\\]', '', city_name).strip()\n",
    "\n",
    "# Apply cleaning to the city column\n",
    "city_df['city_clean'] = city_df['city'].apply(clean_city_name)\n",
    "\n",
    "# Convert population to integer (remove commas and quotes)\n",
    "def parse_population(pop_str):\n",
    "    \"\"\"Convert population string to integer, handling commas and quotes.\"\"\"\n",
    "    if isinstance(pop_str, str):\n",
    "        # Remove commas and quotes\n",
    "        clean_str = pop_str.replace(',', '').replace('\"', '')\n",
    "        return int(clean_str)\n",
    "    return int(pop_str)\n",
    "\n",
    "city_df['population_int'] = city_df['population'].apply(parse_population)\n",
    "\n",
    "# Select the first 5 cities as test cases\n",
    "NUM_TEST_CASES = 5\n",
    "test_cases_df = city_df.head(NUM_TEST_CASES).copy()\n",
    "\n",
    "# Create a clean display DataFrame with relevant columns\n",
    "display_df = test_cases_df[['city_clean', 'state', 'population_int', 'land_area_mi2']].copy()\n",
    "display_df.columns = ['City', 'State', 'Population', 'Area (sq mi)']\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"Test Cases (first {NUM_TEST_CASES} cities, cleaned):\")\n",
    "print(\"=\"*60)\n",
    "print(display_df.to_string(index=False))\n",
    "\n",
    "# Show which cities had footnotes removed\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Data Cleaning Summary:\")\n",
    "print(\"=\"*60)\n",
    "for idx, row in test_cases_df.iterrows():\n",
    "    original = row['city']\n",
    "    cleaned = row['city_clean']\n",
    "    if original != cleaned:\n",
    "        print(f\"  ‚úì Cleaned: '{original}' ‚Üí '{cleaned}'\")\n",
    "    else:\n",
    "        print(f\"  - No change: '{original}'\")\n",
    "\n",
    "print(f\"\\n‚úì Loaded {NUM_TEST_CASES} test cases successfully!\")\n",
    "print(f\"\\nThese cities will be used to invoke the agent and generate traces for evaluation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Unique Session IDs\n",
    "\n",
    "Before invoking the agent for each test case, we need to generate unique session IDs. Session IDs are critical for:\n",
    "\n",
    "- **Trace Identification**: Each invocation's trace data is tagged with its session ID in CloudWatch\n",
    "- **Span Retrieval**: We use session IDs to filter and retrieve specific execution spans\n",
    "- **Evaluation Correlation**: Session IDs link invocations to their evaluation results\n",
    "\n",
    "#### Session ID Requirements\n",
    "\n",
    "AgentCore Runtime requires session IDs to be **at least 33 characters** long. Our format `eval-session-{uuid}` ensures:\n",
    "\n",
    "| Component | Length | Example |\n",
    "|-----------|--------|--------|\n",
    "| Prefix | 13 chars | `eval-session-` |\n",
    "| UUID | 36 chars | `550e8400-e29b-41d4-a716-446655440000` |\n",
    "| **Total** | **49 chars** | `eval-session-550e8400-e29b-41d4-a716-446655440000` |\n",
    "\n",
    "#### Why UUID?\n",
    "\n",
    "Using UUID (Universally Unique Identifier) for session IDs provides:\n",
    "\n",
    "- **Guaranteed Uniqueness**: UUIDs are designed to be globally unique\n",
    "- **No Coordination Required**: Can generate IDs independently without checking for collisions\n",
    "- **Standard Format**: Well-understood format that's easy to parse and log\n",
    "- **Sufficient Entropy**: 128 bits of randomness prevents accidental collisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Unique Session IDs\n",
      "============================================================\n",
      "\n",
      "Format: eval-session-{uuid}\n",
      "Minimum required length: 33 characters\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "1. New York, NY\n",
      "   Session ID: eval-session-5c8d51fb-d526-4d68-b531-f2af5d3c2331\n",
      "   Length: 49 characters ‚úì\n",
      "\n",
      "2. Los Angeles, CA\n",
      "   Session ID: eval-session-968acf9f-cc68-472c-b889-0b97dc5baacc\n",
      "   Length: 49 characters ‚úì\n",
      "\n",
      "3. Chicago, IL\n",
      "   Session ID: eval-session-37bd25d6-30dc-4aa2-9528-4a1fa4a9f845\n",
      "   Length: 49 characters ‚úì\n",
      "\n",
      "4. Houston, TX\n",
      "   Session ID: eval-session-900c5e48-9b66-42be-b87f-25041888489a\n",
      "   Length: 49 characters ‚úì\n",
      "\n",
      "5. Phoenix, AZ\n",
      "   Session ID: eval-session-efb4e1d8-227a-4630-b0cc-be893fa5d06a\n",
      "   Length: 49 characters ‚úì\n",
      "\n",
      "============================================================\n",
      "Session ID Generation Summary\n",
      "============================================================\n",
      "\n",
      "‚úì Generated 5 unique session IDs\n",
      "‚úì All session IDs meet minimum length requirement (33+ chars)\n",
      "‚úì Session IDs stored in 'session_ids' dict and 'session_id_list' for retrieval\n",
      "‚úì All session IDs are unique (no duplicates)\n",
      "‚úì All session IDs are 33+ characters\n",
      "\n",
      "============================================================\n",
      "Session IDs Dictionary (for later retrieval):\n",
      "============================================================\n",
      "  'New York, NY': 'eval-session-5c8d51fb-d526-4d68-b531-f2af5d3c2331'\n",
      "  'Los Angeles, CA': 'eval-session-968acf9f-cc68-472c-b889-0b97dc5baacc'\n",
      "  'Chicago, IL': 'eval-session-37bd25d6-30dc-4aa2-9528-4a1fa4a9f845'\n",
      "  'Houston, TX': 'eval-session-900c5e48-9b66-42be-b87f-25041888489a'\n",
      "  'Phoenix, AZ': 'eval-session-efb4e1d8-227a-4630-b0cc-be893fa5d06a'\n"
     ]
    }
   ],
   "source": [
    "# Generate unique session IDs for each test case\n",
    "# Session IDs are used to:\n",
    "# 1. Track each invocation in CloudWatch logs\n",
    "# 2. Retrieve session spans for evaluation\n",
    "# 3. Correlate invocations with evaluation results\n",
    "#\n",
    "# Format: eval-session-{uuid}\n",
    "# - Prefix 'eval-session-' identifies evaluation invocations\n",
    "# - UUID ensures uniqueness (36 chars)\n",
    "# - Total length: 49 characters (exceeds 33 char minimum)\n",
    "\n",
    "import uuid\n",
    "\n",
    "# Minimum session ID length required by AgentCore Runtime\n",
    "MIN_SESSION_ID_LENGTH = 33\n",
    "\n",
    "# Generate a unique session ID for each test case\n",
    "# Store in a dictionary mapping city name to session ID for easy retrieval\n",
    "session_ids = {}\n",
    "\n",
    "# Also store as a list for ordered access\n",
    "session_id_list = []\n",
    "\n",
    "print(\"Generating Unique Session IDs\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nFormat: eval-session-{{uuid}}\")\n",
    "print(f\"Minimum required length: {MIN_SESSION_ID_LENGTH} characters\")\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "\n",
    "for idx, row in test_cases_df.iterrows():\n",
    "    city = row['city_clean']\n",
    "    state = row['state']\n",
    "    \n",
    "    # Generate a unique session ID using UUID\n",
    "    session_id = f\"eval-session-{uuid.uuid4()}\"\n",
    "    \n",
    "    # Store the session ID in both dictionary and list\n",
    "    city_key = f\"{city}, {state}\"\n",
    "    session_ids[city_key] = session_id\n",
    "    session_id_list.append({\n",
    "        'city': city,\n",
    "        'state': state,\n",
    "        'city_key': city_key,\n",
    "        'session_id': session_id\n",
    "    })\n",
    "    \n",
    "    # Display the generated session ID\n",
    "    print(f\"\\n{idx + 1}. {city_key}\")\n",
    "    print(f\"   Session ID: {session_id}\")\n",
    "    print(f\"   Length: {len(session_id)} characters ‚úì\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Session ID Generation Summary\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n‚úì Generated {len(session_ids)} unique session IDs\")\n",
    "print(f\"‚úì All session IDs meet minimum length requirement ({MIN_SESSION_ID_LENGTH}+ chars)\")\n",
    "print(f\"‚úì Session IDs stored in 'session_ids' dict and 'session_id_list' for retrieval\")\n",
    "\n",
    "# Verify all session IDs are unique\n",
    "unique_ids = set(session_ids.values())\n",
    "if len(unique_ids) == len(session_ids):\n",
    "    print(f\"‚úì All session IDs are unique (no duplicates)\")\n",
    "else:\n",
    "    print(f\"‚ö† Warning: Found duplicate session IDs!\")\n",
    "\n",
    "# Verify all session IDs meet minimum length\n",
    "all_valid_length = all(len(sid) >= MIN_SESSION_ID_LENGTH for sid in session_ids.values())\n",
    "if all_valid_length:\n",
    "    print(f\"‚úì All session IDs are {MIN_SESSION_ID_LENGTH}+ characters\")\n",
    "else:\n",
    "    print(f\"‚ö† Warning: Some session IDs are too short!\")\n",
    "\n",
    "# Display the session IDs dictionary for reference\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Session IDs Dictionary (for later retrieval):\")\n",
    "print(\"=\"*60)\n",
    "for city_key, sid in session_ids.items():\n",
    "    print(f\"  '{city_key}': '{sid}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke Agent for Each Test Case\n",
    "\n",
    "Now we'll invoke the deployed agent for each test case to generate trace data for evaluation. This cell:\n",
    "\n",
    "1. **Loops through test cases**: Iterates over each city in our test dataset\n",
    "2. **Generates queries**: Creates a standardized query asking about population and area\n",
    "3. **Invokes the agent**: Calls `invoke_agent_runtime` API with the unique session ID\n",
    "4. **Captures responses**: Stores the agent's response for each test case\n",
    "5. **Displays progress**: Shows real-time progress and results\n",
    "\n",
    "#### Query Format\n",
    "\n",
    "Each query follows the format:\n",
    "```\n",
    "What is the population and area of {city}, {state}?\n",
    "```\n",
    "\n",
    "This standardized format ensures consistent agent behavior and enables meaningful evaluation comparisons.\n",
    "\n",
    "#### Response Storage\n",
    "\n",
    "Responses are stored in a dictionary (`agent_responses`) mapping city keys to their responses. This data structure enables:\n",
    "\n",
    "- Easy lookup of responses by city\n",
    "- Correlation with session IDs for span retrieval\n",
    "- Analysis of response patterns across test cases\n",
    "\n",
    "#### Error Handling\n",
    "\n",
    "The invocation loop includes error handling to:\n",
    "- Continue processing remaining test cases if one fails\n",
    "- Log errors for debugging\n",
    "- Track which invocations succeeded vs failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invoking Agent for Each Test Case\n",
      "============================================================\n",
      "\n",
      "Total test cases: 5\n",
      "Agent ARN: arn:aws:bedrock-agentcore:us-east-1:616455080294:runtime/citysearch-U6S1xN3zuf\n",
      "\n",
      "============================================================\n",
      "\n",
      "[1/5] New York, NY\n",
      "------------------------------------------------------------\n",
      "Query: What is the population and area of New York, NY?\n",
      "Session ID: eval-session-5c8d51fb-d526-4d68-b531-f2af5d3c2331\n",
      "\n",
      "Invoking agent...\n",
      "\n",
      "‚úì Response received (latency: 3.34s)\n",
      "\n",
      "Response preview:\n",
      "<thinking>I have retrieved several sources with data about the\n",
      "population and area of New York, NY. I will now extract the most\n",
      "recent and reliable information from these sources to provide an\n",
      "accurate response.</thinking>  <response>New York City, often referred\n",
      "to simply as New York or NYC, is a vibrant and diverse metropolis. As\n",
      "of the most recent estimates, the city's population is approximately\n",
      "8.48 million people, while the area spans about 302.6 square miles. A\n",
      "fun fact about New York Cit...\n",
      "\n",
      "XML Tags: <response>=True, <pop>=True, <area>=True\n",
      "\n",
      "[2/5] Los Angeles, CA\n",
      "------------------------------------------------------------\n",
      "Query: What is the population and area of Los Angeles, CA?\n",
      "Session ID: eval-session-968acf9f-cc68-472c-b889-0b97dc5baacc\n",
      "\n",
      "Invoking agent...\n",
      "\n",
      "‚úì Response received (latency: 3.66s)\n",
      "\n",
      "Response preview:\n",
      "<thinking> I found several reliable sources providing information\n",
      "about the population and area of Los Angeles, CA. I will extract the\n",
      "most recent and accurate data from these sources. According to the\n",
      "U.S. Census Bureau and Wikipedia, the population of Los Angeles is\n",
      "around 3.9 million. The area of the city is approximately 503 square\n",
      "miles. Additionally, it is a fun fact that Los Angeles is home to\n",
      "Hollywood, the epicenter of the American entertainment\n",
      "industry.</thinking> <response>Los Angele...\n",
      "\n",
      "XML Tags: <response>=True, <pop>=True, <area>=True\n",
      "\n",
      "[3/5] Chicago, IL\n",
      "------------------------------------------------------------\n",
      "Query: What is the population and area of Chicago, IL?\n",
      "Session ID: eval-session-37bd25d6-30dc-4aa2-9528-4a1fa4a9f845\n",
      "\n",
      "Invoking agent...\n",
      "\n",
      "‚úì Response received (latency: 4.63s)\n",
      "\n",
      "Response preview:\n",
      "<thinking>It seems that I encountered an access issue when trying to\n",
      "fetch the data from the U.S. Census Bureau and Wikipedia pages. Given\n",
      "these errors, I will now try to use the information provided in the\n",
      "search results to estimate the population and area of Chicago. I will\n",
      "rely on the most recent statistics available.</thinking>\n",
      "<response>Chicago is a vibrant city with a rich history and diverse\n",
      "culture. According to the latest information available, Chicago has a\n",
      "population of over 2.7 mil...\n",
      "\n",
      "XML Tags: <response>=True, <pop>=True, <area>=True\n",
      "\n",
      "[4/5] Houston, TX\n",
      "------------------------------------------------------------\n",
      "Query: What is the population and area of Houston, TX?\n",
      "Session ID: eval-session-900c5e48-9b66-42be-b87f-25041888489a\n",
      "\n",
      "Invoking agent...\n",
      "\n",
      "‚úì Response received (latency: 3.59s)\n",
      "\n",
      "Response preview:\n",
      "<thinking> I found several reliable sources that provide population\n",
      "and area data for Houston, TX. The U.S. Census Bureau QuickFacts and\n",
      "the City of Houston's Planning and Development Department's\n",
      "demographic data are both trustworthy sources. I will extract the\n",
      "population and area information from these sources and present it in a\n",
      "human-friendly response along with a fun fact about the\n",
      "city.</thinking>  <response>Houston, TX is a vibrant city with a rich\n",
      "cultural scene. In 2023, the population ...\n",
      "\n",
      "XML Tags: <response>=True, <pop>=True, <area>=True\n",
      "\n",
      "[5/5] Phoenix, AZ\n",
      "------------------------------------------------------------\n",
      "Query: What is the population and area of Phoenix, AZ?\n",
      "Session ID: eval-session-efb4e1d8-227a-4630-b0cc-be893fa5d06a\n",
      "\n",
      "Invoking agent...\n",
      "\n",
      "‚úì Response received (latency: 7.54s)\n",
      "\n",
      "Response preview:\n",
      "<thinking>It appears that I'm still encountering issues while trying\n",
      "to fetch the pages from the sources. Since I cannot retrieve the data\n",
      "directly from the web, I will use the information I have from the\n",
      "search results to provide an answer based on the most recent and\n",
      "reliable data available. The last reliable source I found mentioned\n",
      "that Phoenix is the largest city in Arizona by population. According\n",
      "to the most recent data available, Phoenix has a population of around\n",
      "1.6 million people and ...\n",
      "\n",
      "XML Tags: <response>=True, <pop>=True, <area>=True\n",
      "\n",
      "============================================================\n",
      "Invocation Summary\n",
      "============================================================\n",
      "\n",
      "Total test cases: 5\n",
      "Successful invocations: 5\n",
      "Failed invocations: 0\n",
      "Average latency: 4.55 seconds\n",
      "\n",
      "============================================================\n",
      "Results by Test Case\n",
      "============================================================\n",
      "\n",
      "‚úì New York, NY\n",
      "   Session ID: eval-session-5c8d51fb-d526-4d68-b531-f2af5d3c2331\n",
      "   Latency: 3.34s\n",
      "\n",
      "‚úì Los Angeles, CA\n",
      "   Session ID: eval-session-968acf9f-cc68-472c-b889-0b97dc5baacc\n",
      "   Latency: 3.66s\n",
      "\n",
      "‚úì Chicago, IL\n",
      "   Session ID: eval-session-37bd25d6-30dc-4aa2-9528-4a1fa4a9f845\n",
      "   Latency: 4.63s\n",
      "\n",
      "‚úì Houston, TX\n",
      "   Session ID: eval-session-900c5e48-9b66-42be-b87f-25041888489a\n",
      "   Latency: 3.59s\n",
      "\n",
      "‚úì Phoenix, AZ\n",
      "   Session ID: eval-session-efb4e1d8-227a-4630-b0cc-be893fa5d06a\n",
      "   Latency: 7.54s\n",
      "\n",
      "‚úì All 5 invocations completed successfully!\n",
      "\n",
      "Agent responses are stored in 'agent_responses' dictionary.\n",
      "Session IDs are stored in 'session_ids' dictionary for span retrieval.\n"
     ]
    }
   ],
   "source": [
    "# Invoke the agent for each test case\n",
    "# This cell loops through all test cases, invokes the agent, and captures responses\n",
    "#\n",
    "# For each test case:\n",
    "# 1. Generate a query asking about population and area\n",
    "# 2. Invoke the agent using invoke_agent_runtime API\n",
    "# 3. Capture and store the response\n",
    "# 4. Display progress and results\n",
    "\n",
    "import json\n",
    "import time\n",
    "import textwrap\n",
    "\n",
    "# Dictionary to store agent responses for each test case\n",
    "# Key: city_key (e.g., \"New York, NY\")\n",
    "# Value: dict with query, response, session_id, and metadata\n",
    "agent_responses = {}\n",
    "\n",
    "# Track invocation statistics\n",
    "successful_invocations = 0\n",
    "failed_invocations = 0\n",
    "\n",
    "print(\"Invoking Agent for Each Test Case\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTotal test cases: {len(session_id_list)}\")\n",
    "print(f\"Agent ARN: {citysearch_agent_arn}\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Loop through each test case and invoke the agent\n",
    "for i, test_case in enumerate(session_id_list):\n",
    "    city = test_case['city']\n",
    "    state = test_case['state']\n",
    "    city_key = test_case['city_key']\n",
    "    session_id = test_case['session_id']\n",
    "    \n",
    "    # Generate the query for this test case\n",
    "    query = f\"What is the population and area of {city}, {state}?\"\n",
    "    \n",
    "    print(f\"\\n[{i + 1}/{len(session_id_list)}] {city_key}\")\n",
    "    print(\"-\"*60)\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Session ID: {session_id}\")\n",
    "    print(\"\\nInvoking agent...\")\n",
    "    \n",
    "    try:\n",
    "        # Prepare the payload\n",
    "        payload = json.dumps({\"prompt\": query})\n",
    "        \n",
    "        # Record start time for latency tracking\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Invoke the agent using invoke_agent_runtime API\n",
    "        response = agentcore_client.invoke_agent_runtime(\n",
    "            agentRuntimeArn=citysearch_agent_arn,\n",
    "            runtimeSessionId=session_id,\n",
    "            payload=payload,\n",
    "            qualifier=\"DEFAULT\"\n",
    "        )\n",
    "        \n",
    "        # Calculate latency\n",
    "        latency = time.time() - start_time\n",
    "        \n",
    "        # Read and parse the response\n",
    "        response_body = response['response'].read()\n",
    "        response_data = json.loads(response_body)\n",
    "        \n",
    "        # Store the response with metadata\n",
    "        agent_responses[city_key] = {\n",
    "            'query': query,\n",
    "            'response': response_data,\n",
    "            'session_id': session_id,\n",
    "            'trace_id': response.get('traceId', 'N/A'),\n",
    "            'latency_seconds': latency,\n",
    "            'status': 'success'\n",
    "        }\n",
    "        \n",
    "        successful_invocations += 1\n",
    "        \n",
    "        # Display the response (truncated for readability)\n",
    "        response_str = str(response_data)\n",
    "        if len(response_str) > 500:\n",
    "            display_response = response_str[:500] + \"...\"\n",
    "        else:\n",
    "            display_response = response_str\n",
    "        \n",
    "        print(f\"\\n‚úì Response received (latency: {latency:.2f}s)\")\n",
    "        print(f\"\\nResponse preview:\")\n",
    "        wrapped = textwrap.fill(display_response, width=70)\n",
    "        print(wrapped)\n",
    "        \n",
    "        # Check for XML tags in response\n",
    "        has_response_tag = \"<response>\" in response_str\n",
    "        has_pop_tag = \"<pop>\" in response_str\n",
    "        has_area_tag = \"<area>\" in response_str\n",
    "        \n",
    "        print(f\"\\nXML Tags: <response>={has_response_tag}, <pop>={has_pop_tag}, <area>={has_area_tag}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Handle invocation errors\n",
    "        failed_invocations += 1\n",
    "        \n",
    "        # Store the error information\n",
    "        agent_responses[city_key] = {\n",
    "            'query': query,\n",
    "            'response': None,\n",
    "            'session_id': session_id,\n",
    "            'error': str(e),\n",
    "            'status': 'failed'\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n‚úó Invocation failed: {str(e)}\")\n",
    "        print(\"Continuing with next test case...\")\n",
    "\n",
    "# Display summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Invocation Summary\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTotal test cases: {len(session_id_list)}\")\n",
    "print(f\"Successful invocations: {successful_invocations}\")\n",
    "print(f\"Failed invocations: {failed_invocations}\")\n",
    "\n",
    "if successful_invocations > 0:\n",
    "    # Calculate average latency for successful invocations\n",
    "    latencies = [r['latency_seconds'] for r in agent_responses.values() if r['status'] == 'success']\n",
    "    avg_latency = sum(latencies) / len(latencies)\n",
    "    print(f\"Average latency: {avg_latency:.2f} seconds\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Results by Test Case\")\n",
    "print(\"=\"*60)\n",
    "for city_key, result in agent_responses.items():\n",
    "    status_icon = \"‚úì\" if result['status'] == 'success' else \"‚úó\"\n",
    "    if result['status'] == 'success':\n",
    "        print(f\"\\n{status_icon} {city_key}\")\n",
    "        print(f\"   Session ID: {result['session_id']}\")\n",
    "        print(f\"   Latency: {result['latency_seconds']:.2f}s\")\n",
    "    else:\n",
    "        print(f\"\\n{status_icon} {city_key}\")\n",
    "        print(f\"   Error: {result.get('error', 'Unknown error')}\")\n",
    "\n",
    "if successful_invocations == len(session_id_list):\n",
    "    print(f\"\\n‚úì All {successful_invocations} invocations completed successfully!\")\n",
    "    print(\"\\nAgent responses are stored in 'agent_responses' dictionary.\")\n",
    "    print(\"Session IDs are stored in 'session_ids' dictionary for span retrieval.\")\n",
    "elif successful_invocations > 0:\n",
    "    print(f\"\\n‚ö† {successful_invocations} of {len(session_id_list)} invocations succeeded.\")\n",
    "    print(\"You may proceed with evaluation using the successful invocations.\")\n",
    "else:\n",
    "    print(f\"\\n‚úó All invocations failed. Please check the agent deployment and try again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait for CloudWatch Log Propagation\n",
    "\n",
    "After invoking the agent, we need to wait for the execution traces to propagate to CloudWatch Logs before we can retrieve them for evaluation.\n",
    "\n",
    "#### Why Wait?\n",
    "\n",
    "CloudWatch Logs operates with **eventual consistency**, meaning:\n",
    "\n",
    "- **Log Ingestion Delay**: Logs are batched and sent to CloudWatch asynchronously\n",
    "- **Index Propagation**: After ingestion, logs need time to be indexed and become queryable\n",
    "- **Cross-Region Latency**: If using cross-region inference, additional latency may occur\n",
    "\n",
    "#### Recommended Wait Time\n",
    "\n",
    "A **30-second wait** is typically sufficient for:\n",
    "\n",
    "| Factor | Typical Delay |\n",
    "|--------|---------------|\n",
    "| Log batching and transmission | 5-10 seconds |\n",
    "| CloudWatch ingestion | 5-10 seconds |\n",
    "| Index propagation | 5-15 seconds |\n",
    "| **Total** | **15-35 seconds** |\n",
    "\n",
    "#### What Happens During the Wait\n",
    "\n",
    "While we wait, AgentCore Runtime is:\n",
    "\n",
    "1. **Collecting Spans**: Gathering all execution trace data from the agent invocations\n",
    "2. **Formatting Logs**: Converting spans to CloudWatch-compatible log format\n",
    "3. **Transmitting Data**: Sending log batches to CloudWatch Logs service\n",
    "4. **Indexing**: CloudWatch indexes the logs for efficient querying\n",
    "\n",
    "After the wait completes, we'll be able to retrieve session spans using the CloudWatch Logs API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: AgentCore Evaluations\n",
    "\n",
    "Now that we've invoked the agent and generated execution traces, we can run evaluations using the **AgentCore Evaluations API** via the starter toolkit.\n",
    "\n",
    "### Using the Evaluation Class\n",
    "\n",
    "The `bedrock-agentcore-starter-toolkit` provides an `Evaluation` class that simplifies the evaluation process by:\n",
    "\n",
    "- **Automatic log retrieval**: Fetches session spans from CloudWatch internally\n",
    "- **Built-in evaluators**: Access to pre-configured evaluators like `Builtin.Helpfulness` and `Builtin.ToolSelectionAccuracy`\n",
    "- **Simple result access**: Clean methods to get successful and failed evaluation results\n",
    "\n",
    "### Built-in Evaluators\n",
    "\n",
    "| Evaluator | Description |\n",
    "|-----------|-------------|\n",
    "| `Builtin.Helpfulness` | Assesses whether the agent's response is helpful and addresses the user's query |\n",
    "| `Builtin.ToolSelectionAccuracy` | Evaluates whether the agent selected appropriate tools for the task |\n",
    "\n",
    "### Evaluation Output\n",
    "\n",
    "Each evaluation returns:\n",
    "\n",
    "- **value**: Numeric score (0.0 - 1.0) indicating evaluation result\n",
    "- **label**: Categorical label (e.g., \"PASS\", \"FAIL\")\n",
    "- **explanation**: Detailed reasoning for the evaluation result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting 30 seconds for CloudWatch log propagation...\n",
      "Done waiting.\n",
      "\n",
      "Running AgentCore Evaluations\n",
      "============================================================\n",
      "Agent ID: citysearch-U6S1xN3zuf\n",
      "Sessions to evaluate: 5\n",
      "============================================================\n",
      "\n",
      "[New York, NY]\n",
      "------------------------------------------------------------\n",
      "Session ID: eval-session-5c8d51fb-d526-4d68-b531-f2af5d3c2331\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">Evaluating session:</span> eval-session-<span style=\"color: #ffff00; text-decoration-color: #ffff00\">5c8d51fb-d526-4d68-b531-f2af5d3c2331</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[36mEvaluating session:\u001b[0m eval-session-\u001b[93m5c8d51fb-d526-4d68-b531-f2af5d3c2331\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Mode:</span> All traces <span style=\"font-weight: bold\">(</span>most recent <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span> spans<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mMode:\u001b[0m All traces \u001b[1m(\u001b[0mmost recent \u001b[1;36m1000\u001b[0m spans\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Evaluators:</span> Builtin.Helpfulness, Builtin.ToolSelectionAccuracy\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mEvaluators:\u001b[0m Builtin.Helpfulness, Builtin.ToolSelectionAccuracy\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/justmul/Desktop/evals/.venv/lib/python3.13/site-packages/rich/live.py:260: UserWarning: install \"ipywidgets\"\n",
       "for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/justmul/Desktop/evals/.venv/lib/python3.13/site-packages/rich/live.py:260: UserWarning: install \"ipywidgets\"\n",
       "for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Successful evaluations: 2\n",
      "  Failed evaluations: 0\n",
      "\n",
      "  üìä Builtin.Helpfulness\n",
      "     Score: 0.83\n",
      "     Label: Very Helpful\n",
      "     Explanation: The user's goal is straightforward: obtain the population and area of New York, NY. The assistant's response directly addresses both parts of this req...\n",
      "\n",
      "  üìä Builtin.ToolSelectionAccuracy\n",
      "     Score: 1.00\n",
      "     Label: Yes\n",
      "     Explanation: The user asked for two specific pieces of information about New York, NY: population and area. The assistant performed a web search with the topic 'cu...\n",
      "\n",
      "[Los Angeles, CA]\n",
      "------------------------------------------------------------\n",
      "Session ID: eval-session-968acf9f-cc68-472c-b889-0b97dc5baacc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">Evaluating session:</span> eval-session-<span style=\"color: #ffff00; text-decoration-color: #ffff00\">968acf9f-cc68-472c-b889-0b97dc5baacc</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[36mEvaluating session:\u001b[0m eval-session-\u001b[93m968acf9f-cc68-472c-b889-0b97dc5baacc\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Mode:</span> All traces <span style=\"font-weight: bold\">(</span>most recent <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span> spans<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mMode:\u001b[0m All traces \u001b[1m(\u001b[0mmost recent \u001b[1;36m1000\u001b[0m spans\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Evaluators:</span> Builtin.Helpfulness, Builtin.ToolSelectionAccuracy\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mEvaluators:\u001b[0m Builtin.Helpfulness, Builtin.ToolSelectionAccuracy\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Successful evaluations: 2\n",
      "  Failed evaluations: 0\n",
      "\n",
      "  üìä Builtin.Helpfulness\n",
      "     Score: 0.83\n",
      "     Label: Very Helpful\n",
      "     Explanation: The user's goal is straightforward: obtain the population and area of Los Angeles, CA. The assistant's response directly addresses both pieces of info...\n",
      "\n",
      "  üìä Builtin.ToolSelectionAccuracy\n",
      "     Score: 1.00\n",
      "     Label: Yes\n",
      "     Explanation: The user asks a straightforward factual question about two specific pieces of information regarding Los Angeles, CA: its population and area. The AI a...\n",
      "\n",
      "[Chicago, IL]\n",
      "------------------------------------------------------------\n",
      "Session ID: eval-session-37bd25d6-30dc-4aa2-9528-4a1fa4a9f845\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">Evaluating session:</span> eval-session-<span style=\"color: #ffff00; text-decoration-color: #ffff00\">37bd25d6-30dc-4aa2-9528-4a1fa4a9f845</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[36mEvaluating session:\u001b[0m eval-session-\u001b[93m37bd25d6-30dc-4aa2-9528-4a1fa4a9f845\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Mode:</span> All traces <span style=\"font-weight: bold\">(</span>most recent <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span> spans<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mMode:\u001b[0m All traces \u001b[1m(\u001b[0mmost recent \u001b[1;36m1000\u001b[0m spans\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Evaluators:</span> Builtin.Helpfulness, Builtin.ToolSelectionAccuracy\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mEvaluators:\u001b[0m Builtin.Helpfulness, Builtin.ToolSelectionAccuracy\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Successful evaluations: 4\n",
      "  Failed evaluations: 0\n",
      "\n",
      "  üìä Builtin.Helpfulness\n",
      "     Score: 0.83\n",
      "     Label: Very Helpful\n",
      "     Explanation: The user's goal is straightforward: obtain the population and area of Chicago, IL. The assistant's response directly addresses this goal by providing ...\n",
      "\n",
      "  üìä Builtin.ToolSelectionAccuracy\n",
      "     Score: 1.00\n",
      "     Label: Yes\n",
      "     Explanation: The user asked a straightforward factual question: 'What is the population and area of Chicago, IL?' This requires two specific pieces of information:...\n",
      "\n",
      "  üìä Builtin.ToolSelectionAccuracy\n",
      "     Score: 0.00\n",
      "     Label: No\n",
      "     Explanation: The user asked for the population and area of Chicago, IL. The assistant performed a web search which returned multiple results containing the request...\n",
      "\n",
      "  üìä Builtin.ToolSelectionAccuracy\n",
      "     Score: 1.00\n",
      "     Label: Yes\n",
      "     Explanation: The user asked for the population and area of Chicago, IL. The assistant performed a web search that returned multiple sources with relevant informati...\n",
      "\n",
      "[Houston, TX]\n",
      "------------------------------------------------------------\n",
      "Session ID: eval-session-900c5e48-9b66-42be-b87f-25041888489a\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">Evaluating session:</span> eval-session-<span style=\"color: #ffff00; text-decoration-color: #ffff00\">900c5e48-9b66-42be-b87f-25041888489a</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[36mEvaluating session:\u001b[0m eval-session-\u001b[93m900c5e48-9b66-42be-b87f-25041888489a\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Mode:</span> All traces <span style=\"font-weight: bold\">(</span>most recent <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span> spans<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mMode:\u001b[0m All traces \u001b[1m(\u001b[0mmost recent \u001b[1;36m1000\u001b[0m spans\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Evaluators:</span> Builtin.Helpfulness, Builtin.ToolSelectionAccuracy\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mEvaluators:\u001b[0m Builtin.Helpfulness, Builtin.ToolSelectionAccuracy\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Successful evaluations: 2\n",
      "  Failed evaluations: 0\n",
      "\n",
      "  üìä Builtin.Helpfulness\n",
      "     Score: 0.83\n",
      "     Label: Very Helpful\n",
      "     Explanation: The user's goal is straightforward: obtain the population and area of Houston, TX. The assistant's response directly addresses both pieces of informat...\n",
      "\n",
      "  üìä Builtin.ToolSelectionAccuracy\n",
      "     Score: 1.00\n",
      "     Label: Yes\n",
      "     Explanation: The user asked a straightforward factual question about Houston, TX's population and area. The assistant performed a web search with the query 'Housto...\n",
      "\n",
      "[Phoenix, AZ]\n",
      "------------------------------------------------------------\n",
      "Session ID: eval-session-efb4e1d8-227a-4630-b0cc-be893fa5d06a\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">Evaluating session:</span> eval-session-<span style=\"color: #ffff00; text-decoration-color: #ffff00\">efb4e1d8-227a-4630-b0cc-be893fa5d06a</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[36mEvaluating session:\u001b[0m eval-session-\u001b[93mefb4e1d8-227a-4630-b0cc-be893fa5d06a\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Mode:</span> All traces <span style=\"font-weight: bold\">(</span>most recent <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span> spans<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mMode:\u001b[0m All traces \u001b[1m(\u001b[0mmost recent \u001b[1;36m1000\u001b[0m spans\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Evaluators:</span> Builtin.Helpfulness, Builtin.ToolSelectionAccuracy\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mEvaluators:\u001b[0m Builtin.Helpfulness, Builtin.ToolSelectionAccuracy\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Successful evaluations: 5\n",
      "  Failed evaluations: 0\n",
      "\n",
      "  üìä Builtin.Helpfulness\n",
      "     Score: 0.83\n",
      "     Label: Very Helpful\n",
      "     Explanation: The user's goal is straightforward: obtain the population and area of Phoenix, AZ. The assistant's response directly addresses this request by providi...\n",
      "\n",
      "  üìä Builtin.ToolSelectionAccuracy\n",
      "     Score: 1.00\n",
      "     Label: Yes\n",
      "     Explanation: The user asks a straightforward factual question about Phoenix, AZ's population and area. This is the first interaction in the conversation, and the a...\n",
      "\n",
      "  üìä Builtin.ToolSelectionAccuracy\n",
      "     Score: 1.00\n",
      "     Label: Yes\n",
      "     Explanation: The user asked for specific information about Phoenix, AZ: its population and area. The assistant performed a web search that returned several results...\n",
      "\n",
      "  üìä Builtin.ToolSelectionAccuracy\n",
      "     Score: 1.00\n",
      "     Label: Yes\n",
      "     Explanation: The user asked for the population and area of Phoenix, AZ. The assistant first performed a web search which returned several relevant results, includi...\n",
      "\n",
      "  üìä Builtin.ToolSelectionAccuracy\n",
      "     Score: 1.00\n",
      "     Label: Yes\n",
      "     Explanation: The user asked for the population and area of Phoenix, AZ. The assistant performed a web search that returned several relevant links. After attempting...\n",
      "\n",
      "============================================================\n",
      "Evaluation Summary\n",
      "============================================================\n",
      "Sessions evaluated successfully: 5/5\n",
      "\n",
      "Average Helpfulness Score: 0.83\n",
      "Average Tool Selection Accuracy: 0.90\n"
     ]
    }
   ],
   "source": [
    "from bedrock_agentcore_starter_toolkit import Evaluation\n",
    "import time\n",
    "\n",
    "# Initialize the evaluation client\n",
    "eval_client = Evaluation()\n",
    "\n",
    "# Extract the runtime ID from the agent ARN\n",
    "# ARN format: arn:aws:bedrock-agentcore:{region}:{account}:runtime/{runtime-id}\n",
    "agent_id = citysearch_agent_arn.split('/')[-1]\n",
    "\n",
    "print(\"Running AgentCore Evaluations\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Agent ID: {agent_id}\")\n",
    "print(f\"Sessions to evaluate: {len(session_ids)}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Store all evaluation results\n",
    "all_results = []\n",
    "\n",
    "# Evaluate each session\n",
    "for city_key, session_id in session_ids.items():\n",
    "    print(f\"\\n[{city_key}]\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Session ID: {session_id}\")\n",
    "    \n",
    "    try:\n",
    "        # Run evaluation using the starter toolkit\n",
    "        results = eval_client.run(\n",
    "            agent_id=agent_id,\n",
    "            session_id=session_id,\n",
    "            evaluators=[\"Builtin.Helpfulness\", \"Builtin.ToolSelectionAccuracy\"]\n",
    "        )\n",
    "        \n",
    "        # Get successful and failed results\n",
    "        successful = results.get_successful_results()\n",
    "        failed = results.get_failed_results()\n",
    "        \n",
    "        print(f\"  Successful evaluations: {len(successful)}\")\n",
    "        print(f\"  Failed evaluations: {len(failed)}\")\n",
    "        \n",
    "        # Display results for each evaluator\n",
    "        for result in successful:\n",
    "            print(f\"\\n  üìä {result.evaluator_name}\")\n",
    "            print(f\"     Score: {result.value:.2f}\")\n",
    "            print(f\"     Label: {result.label}\")\n",
    "            if result.explanation:\n",
    "                # Truncate long explanations\n",
    "                explanation = result.explanation[:150] + \"...\" if len(result.explanation) > 150 else result.explanation\n",
    "                print(f\"     Explanation: {explanation}\")\n",
    "        \n",
    "        # Store results\n",
    "        all_results.append({\n",
    "            'city_key': city_key,\n",
    "            'session_id': session_id,\n",
    "            'successful': successful,\n",
    "            'failed': failed\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚úó Error: {str(e)}\")\n",
    "        all_results.append({\n",
    "            'city_key': city_key,\n",
    "            'session_id': session_id,\n",
    "            'error': str(e)\n",
    "        })\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Evaluation Summary\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "successful_evals = sum(1 for r in all_results if 'successful' in r and r['successful'])\n",
    "print(f\"Sessions evaluated successfully: {successful_evals}/{len(session_ids)}\")\n",
    "\n",
    "# Calculate average scores if we have results\n",
    "helpfulness_scores = []\n",
    "tool_accuracy_scores = []\n",
    "\n",
    "for r in all_results:\n",
    "    if 'successful' in r:\n",
    "        for eval_result in r['successful']:\n",
    "            if eval_result.evaluator_name == \"Builtin.Helpfulness\":\n",
    "                helpfulness_scores.append(eval_result.value)\n",
    "            elif eval_result.evaluator_name == \"Builtin.ToolSelectionAccuracy\":\n",
    "                tool_accuracy_scores.append(eval_result.value)\n",
    "\n",
    "if helpfulness_scores:\n",
    "    print(f\"\\nAverage Helpfulness Score: {sum(helpfulness_scores)/len(helpfulness_scores):.2f}\")\n",
    "if tool_accuracy_scores:\n",
    "    print(f\"Average Tool Selection Accuracy: {sum(tool_accuracy_scores)/len(tool_accuracy_scores):.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Results Analysis\n",
    "\n",
    "In this section, we'll analyze the evaluation results to understand our agent's performance:\n",
    "\n",
    "1. **Calculate average scores**: Compute mean scores across all test cases\n",
    "2. **Interpret results**: Understand what the scores mean\n",
    "3. **Identify improvements**: Determine areas for agent enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results Analysis\n",
      "============================================================\n",
      "\n",
      "All Evaluation Results:\n",
      "------------------------------------------------------------\n",
      "           City                     Evaluator  Score        Label\n",
      "   New York, NY           Builtin.Helpfulness   0.83 Very Helpful\n",
      "   New York, NY Builtin.ToolSelectionAccuracy   1.00          Yes\n",
      "Los Angeles, CA           Builtin.Helpfulness   0.83 Very Helpful\n",
      "Los Angeles, CA Builtin.ToolSelectionAccuracy   1.00          Yes\n",
      "    Chicago, IL           Builtin.Helpfulness   0.83 Very Helpful\n",
      "    Chicago, IL Builtin.ToolSelectionAccuracy   1.00          Yes\n",
      "    Chicago, IL Builtin.ToolSelectionAccuracy   0.00           No\n",
      "    Chicago, IL Builtin.ToolSelectionAccuracy   1.00          Yes\n",
      "    Houston, TX           Builtin.Helpfulness   0.83 Very Helpful\n",
      "    Houston, TX Builtin.ToolSelectionAccuracy   1.00          Yes\n",
      "    Phoenix, AZ           Builtin.Helpfulness   0.83 Very Helpful\n",
      "    Phoenix, AZ Builtin.ToolSelectionAccuracy   1.00          Yes\n",
      "    Phoenix, AZ Builtin.ToolSelectionAccuracy   1.00          Yes\n",
      "    Phoenix, AZ Builtin.ToolSelectionAccuracy   1.00          Yes\n",
      "    Phoenix, AZ Builtin.ToolSelectionAccuracy   1.00          Yes\n",
      "\n",
      "============================================================\n",
      "Scores by Evaluator:\n",
      "------------------------------------------------------------\n",
      "                               Average   Min   Max  Count\n",
      "Evaluator                                                \n",
      "Builtin.Helpfulness               0.83  0.83  0.83      5\n",
      "Builtin.ToolSelectionAccuracy     0.90  0.00  1.00     10\n",
      "\n",
      "============================================================\n",
      "Overall Average Score: 0.877\n",
      "============================================================\n",
      "\n",
      "Score Interpretation:\n",
      "------------------------------------------------------------\n",
      "‚úì Good performance with room for improvement.\n"
     ]
    }
   ],
   "source": [
    "# Results Analysis - Updated for starter toolkit output\n",
    "# Analyzes the evaluation results stored in all_results\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Evaluation Results Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Build a list of result records for analysis\n",
    "result_records = []\n",
    "for r in all_results:\n",
    "    if 'successful' in r and r['successful']:\n",
    "        for eval_result in r['successful']:\n",
    "            result_records.append({\n",
    "                'City': r['city_key'],\n",
    "                'Evaluator': eval_result.evaluator_name,\n",
    "                'Score': eval_result.value,\n",
    "                'Label': eval_result.label,\n",
    "                'Explanation': eval_result.explanation[:100] + \"...\" if eval_result.explanation and len(eval_result.explanation) > 100 else eval_result.explanation\n",
    "            })\n",
    "\n",
    "if not result_records:\n",
    "    print(\"\\n‚ö† No successful evaluation results to analyze.\")\n",
    "else:\n",
    "    # Create DataFrame for analysis\n",
    "    results_df = pd.DataFrame(result_records)\n",
    "    \n",
    "    print(\"\\nAll Evaluation Results:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(results_df[['City', 'Evaluator', 'Score', 'Label']].to_string(index=False))\n",
    "    \n",
    "    # Calculate averages by evaluator\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Scores by Evaluator:\")\n",
    "    print(\"-\" * 60)\n",
    "    avg_by_evaluator = results_df.groupby('Evaluator')['Score'].agg(['mean', 'min', 'max', 'count'])\n",
    "    avg_by_evaluator.columns = ['Average', 'Min', 'Max', 'Count']\n",
    "    print(avg_by_evaluator.round(3).to_string())\n",
    "    \n",
    "    # Overall average\n",
    "    overall_avg = results_df['Score'].mean()\n",
    "    print(f\"\\n\" + \"=\" * 60)\n",
    "    print(f\"Overall Average Score: {overall_avg:.3f}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Interpretation\n",
    "    print(\"\\nScore Interpretation:\")\n",
    "    print(\"-\" * 60)\n",
    "    if overall_avg >= 0.9:\n",
    "        print(\"‚úì Excellent performance! The agent is working very well.\")\n",
    "    elif overall_avg >= 0.7:\n",
    "        print(\"‚úì Good performance with room for improvement.\")\n",
    "    elif overall_avg >= 0.5:\n",
    "        print(\"‚ö† Fair performance - consider refining the system prompt.\")\n",
    "    else:\n",
    "        print(\"‚ö† Performance needs improvement - review agent configuration.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: Cleanup\n",
    "\n",
    "After completing the evaluation, it's important to clean up deployed resources to avoid unnecessary AWS charges. This section covers:\n",
    "\n",
    "1. **Destroy the deployed agent**: Remove the agent from AgentCore Runtime\n",
    "2. **Verify deletion**: Confirm the agent has been removed\n",
    "3. **Additional cleanup reminders**: Resources that may need manual cleanup\n",
    "\n",
    "### Important\n",
    "\n",
    "Always run the cleanup cells when you're done with the workshop to avoid ongoing charges for:\n",
    "- AgentCore Runtime compute resources\n",
    "- ECR container storage\n",
    "- CloudWatch log storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üóëÔ∏è Destroying Bedrock AgentCore resources\n",
      "Starting destroy operation for agent: citysearch (dry_run=False, delete_ecr_repo=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Destroying Deployed Agent\n",
      "============================================================\n",
      "\n",
      "Agent to destroy: citysearch\n",
      "Agent ARN: arn:aws:bedrock-agentcore:us-east-1:616455080294:runtime/citysearch-U6S1xN3zuf\n",
      "\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEFAULT endpoint will be automatically deleted with agent\n",
      "Deleted AgentCore agent: arn:aws:bedrock-agentcore:us-east-1:616455080294:runtime/citysearch-U6S1xN3zuf\n",
      "Checking ECR repository: bedrock-agentcore-citysearch in region: us-east-1\n",
      "Deleted 3 ECR images from bedrock-agentcore-citysearch\n",
      "Deleted CodeBuild project: bedrock-agentcore-citysearch-builder\n",
      "Deleted S3 artifact: citysearch/deployment.zip\n",
      "Deleted S3 artifact: citysearch/source.zip\n",
      "Deleted inline policy CodeBuildExecutionPolicy from role AmazonBedrockAgentCoreSDKCodeBuild-us-east-1-672e22fb7a\n",
      "Deleted CodeBuild IAM role: AmazonBedrockAgentCoreSDKCodeBuild-us-east-1-672e22fb7a\n",
      "Deleted IAM role: AmazonBedrockAgentCoreSDKRuntime-us-east-1-672e22fb7a\n",
      "Removed agent configuration: citysearch\n",
      "Cleared default agent (no agents remaining)\n",
      "Removed configuration file: /Users/justmul/Desktop/evals/sample-gen-ai-evaluations-workshop/05-framework-specific-evaluations/05-04-AgentCore-Runtime-Evals/.bedrock_agentcore.yaml\n",
      "Destroy operation completed. Resources removed: 9, Warnings: 0, Errors: 0\n",
      "Destroy completed. Removed 9 resources\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö† Agent destruction is commented out for safety.\n",
      "\n",
      "To destroy the agent, uncomment the destroy lines above and re-run this cell.\n",
      "\n",
      "Alternatively, you can destroy from the command line:\n",
      "  agentcore destroy --agent-name citysearch\n"
     ]
    }
   ],
   "source": [
    "# Destroy the deployed agent\n",
    "# This removes the agent from AgentCore Runtime\n",
    "#\n",
    "# WARNING: This action is irreversible. The agent will need to be\n",
    "# re-deployed if you want to use it again.\n",
    "\n",
    "print(\"Destroying Deployed Agent\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nAgent to destroy: {agent_name}\")\n",
    "print(f\"Agent ARN: {citysearch_agent_arn}\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Uncomment the following lines to actually destroy the agent:\n",
    "# print(\"Destroying agent...\")\n",
    "# destroy_result = agentcore_runtime.destroy()\n",
    "# print(f\"\\n‚úì Agent destroyed successfully\")\n",
    "# print(f\"\\nDestroy result: {destroy_result}\")\n",
    "\n",
    "print(\"\\n‚ö† Agent destruction is commented out for safety.\")\n",
    "print(\"\\nTo destroy the agent, uncomment the destroy lines above and re-run this cell.\")\n",
    "print(\"\\nAlternatively, you can destroy from the command line:\")\n",
    "print(f\"  agentcore destroy --agent-name {agent_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration not found\n",
      "Call .configure() first to set up your agent\n",
      "Example: runtime.configure(entrypoint='my_agent.py')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying Agent Status\n",
      "============================================================\n",
      "\n",
      "Status check result: Must configure first. Call .configure() first.\n",
      "\n",
      "This may indicate the agent has been deleted.\n"
     ]
    }
   ],
   "source": [
    "# Verify agent deletion\n",
    "# This cell checks if the agent has been successfully removed\n",
    "\n",
    "print(\"Verifying Agent Status\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    status_response = agentcore_runtime.status()\n",
    "    status = status_response.endpoint.get('status', 'UNKNOWN')\n",
    "    print(f\"\\nAgent status: {status}\")\n",
    "    \n",
    "    if status == 'READY':\n",
    "        print(\"\\n‚ö† Agent is still deployed.\")\n",
    "        print(\"  Run the destroy cell above to remove it.\")\n",
    "    elif status in ['DELETING', 'DELETED']:\n",
    "        print(\"\\n‚úì Agent is being deleted or has been deleted.\")\n",
    "except Exception as e:\n",
    "    if 'ResourceNotFoundException' in str(type(e).__name__) or 'not found' in str(e).lower():\n",
    "        print(\"\\n‚úì Agent not found - deletion confirmed!\")\n",
    "    else:\n",
    "        print(f\"\\nStatus check result: {str(e)}\")\n",
    "        print(\"\\nThis may indicate the agent has been deleted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Cleanup Reminders\n",
    "\n",
    "After destroying the agent, you may want to clean up these additional resources:\n",
    "\n",
    "| Resource | Location | Action |\n",
    "|----------|----------|--------|\n",
    "| ECR Repository | AWS Console > ECR | Delete the container image repository |\n",
    "| CloudWatch Logs | AWS Console > CloudWatch > Log Groups | Delete log groups starting with `/aws/bedrock-agentcore/` |\n",
    "| IAM Roles | AWS Console > IAM > Roles | Delete auto-created execution roles |\n",
    "| Local Files | This directory | Delete `citysearch.py`, `.bedrock_agentcore.yaml`, `Dockerfile` |\n",
    "\n",
    "### Verify in AWS Console\n",
    "\n",
    "To confirm all resources are cleaned up:\n",
    "\n",
    "1. **AgentCore Runtime**: Check that no agents are listed\n",
    "2. **ECR**: Verify the repository is deleted\n",
    "3. **CloudWatch**: Confirm log groups are removed\n",
    "4. **IAM**: Check for orphaned roles with `bedrock-agentcore` in the name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Congratulations! You've completed the AgentCore Runtime Evaluations workshop module. In this notebook, you learned how to:\n",
    "\n",
    "1. ‚úì **Create a Strands Agent** with web search capabilities and XML output format\n",
    "2. ‚úì **Deploy to AgentCore Runtime** using the starter toolkit\n",
    "3. ‚úì **Invoke the deployed agent** via the `invoke_agent_runtime` API\n",
    "4. ‚úì **Retrieve session spans** from CloudWatch logs\n",
    "5. ‚úì **Run AgentCore Evaluations** with built-in evaluators\n",
    "6. ‚úì **Analyze evaluation results** to understand agent performance\n",
    "7. ‚úì **Clean up resources** to avoid unnecessary charges\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- **AgentCore Runtime** provides managed infrastructure for deploying AI agents with built-in observability\n",
    "- **AgentCore Evaluations** offers standardized evaluation through the `evaluate()` API\n",
    "- **Built-in evaluators** like `Builtin.Helpfulness` and `Builtin.ToolSelectionAccuracy` provide objective assessment\n",
    "- **Session spans** from CloudWatch logs enable evaluation of real agent behavior\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Explore additional built-in evaluators in the AgentCore Evaluations documentation\n",
    "- Create custom evaluators for domain-specific assessment\n",
    "- Integrate evaluations into your CI/CD pipeline for continuous agent quality monitoring\n",
    "- Review the other workshop modules for more evaluation techniques"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
